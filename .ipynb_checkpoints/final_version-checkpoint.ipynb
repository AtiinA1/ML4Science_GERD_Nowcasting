{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb97fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rac\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from NN_versions import *\n",
    "import random\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb996f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix randomness \n",
    "np.random.seed(675)\n",
    "tf.random.set_seed(675)\n",
    "random.seed(675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541e6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries that will be subject to our study\n",
    "iso = [\n",
    "    \"USA\",  # United States\n",
    "    \"CHN\",  # China\n",
    "    \"JPN\",  # Japan\n",
    "    \"DEU\",  # Germany\n",
    "    \"KOR\",  # South Korea\n",
    "    \"FRA\",  # France\n",
    "    \"GBR\",  # United Kingdom\n",
    "    \"CAN\",  # Canada\n",
    "    \"CHE\"   # Switzerland\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_R_D_expenditure_data(iso):\n",
    "    \"\"\"\n",
    "    Load and preprocess R&D expenditure data.\n",
    "\n",
    "    This function reads a CSV file containing R&D expenditure data, filters and preprocesses it to create a DataFrame\n",
    "    suitable for analysis. It also calculates the difference between consecutive R&D expenditure values for future use.\n",
    "\n",
    "    Parameters:\n",
    "        iso (list of str): List of ISO country codes to filter data by.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the following columns:\n",
    "            - 'ISO': ISO country code.\n",
    "            - 'year': Year of the data.\n",
    "            - 'v-1': R&D expenditure for the previous year.\n",
    "            - 'v-2': R&D expenditure for the year before the previous year.\n",
    "            - 'v': The difference between consecutive R&D expenditure values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loading the dataframe with all the R&D expenditure\n",
    "    df = pd.read_csv('./data/DP_LIVE_08052023154811337.csv')\n",
    "    \n",
    "    # Filter on the measure, time, and location\n",
    "    df_GERD = df[(df['MEASURE']=='PC_GDP') &\n",
    "                 (df['TIME'] >= 2003)]\n",
    "    df_GERD = df_GERD[df_GERD['LOCATION'].isin(iso)][['LOCATION','TIME', 'Value']]\n",
    "    df_GERD = df_GERD.sort_values(by=['LOCATION', 'TIME'])\n",
    "    \n",
    "    # Then, we will shift Our window in the 'Value' column, we use this since we want to predict R&D expenditures with previous \n",
    "    # values as features\n",
    "    df_GERD['v-1'] = df_GERD.groupby('LOCATION')['Value'].shift(1)\n",
    "    df_GERD['v-2'] = df_GERD.groupby('LOCATION')['Value'].shift(2)\n",
    "\n",
    "    # Drop rows that do not have complete data for the previous two years.\n",
    "    df_GERD = df_GERD.dropna(subset=['v-1', 'v-2']).reset_index(drop=True)\n",
    "\n",
    "    df_GERD.rename(columns={'LOCATION': 'ISO', 'TIME': 'year', 'Value': 'v'}, inplace=True)\n",
    "    df_GERD = df_GERD[['ISO', 'year', 'v-1', 'v-2', 'v']]\n",
    "    \n",
    "    # Here we adopt the approach of predicting the difference between 2 consecutive values of R&D expenditures rather than predicting\n",
    "    # the actual value, this will be useful next when we want to predict R&D expenditures on a quarterly basis.\n",
    "    df_GERD[\"v\"] = df_GERD[\"v\"] - df_GERD[\"v-1\"]\n",
    "    \n",
    "    return df_GERD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf4ca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO</th>\n",
       "      <th>year</th>\n",
       "      <th>v-1</th>\n",
       "      <th>v-2</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.997333</td>\n",
       "      <td>1.967807</td>\n",
       "      <td>-0.026090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>1.997333</td>\n",
       "      <td>-0.028245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.039421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.903578</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.855778</td>\n",
       "      <td>1.903578</td>\n",
       "      <td>0.061638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>USA</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.853501</td>\n",
       "      <td>2.786995</td>\n",
       "      <td>0.050823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.904324</td>\n",
       "      <td>2.853501</td>\n",
       "      <td>0.105778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>USA</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.010102</td>\n",
       "      <td>2.904324</td>\n",
       "      <td>0.160385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>3.010102</td>\n",
       "      <td>0.297284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>-0.010725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ISO  year       v-1       v-2         v\n",
       "0    CAN  2005  1.997333  1.967807 -0.026090\n",
       "1    CAN  2006  1.971243  1.997333 -0.028245\n",
       "2    CAN  2007  1.942999  1.971243 -0.039421\n",
       "3    CAN  2008  1.903578  1.942999 -0.047800\n",
       "4    CAN  2009  1.855778  1.903578  0.061638\n",
       "..   ...   ...       ...       ...       ...\n",
       "132  USA  2017  2.853501  2.786995  0.050823\n",
       "133  USA  2018  2.904324  2.853501  0.105778\n",
       "134  USA  2019  3.010102  2.904324  0.160385\n",
       "135  USA  2020  3.170487  3.010102  0.297284\n",
       "136  USA  2021  3.467771  3.170487 -0.010725\n",
       "\n",
       "[137 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading R&D expanditures values \n",
    "merged_df_R_D = load_R_D_expenditure_data(iso)\n",
    "\n",
    "#Keeping a copy of the initial dataframe\n",
    "first_merged = merged_df_R_D.copy()\n",
    "\n",
    "merged_df_R_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c1e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_indices(df, n_folds):\n",
    "    \"\"\"\n",
    "    Generates indices for cross-validation.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame to perform cross-validation on.\n",
    "    n_folds (int): Number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains two arrays, the first for training indices and the second for test indices.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    indices = [(train_index, test_index) for train_index, test_index in kf.split(df)]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea66be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler function for training neural networks.\n",
    "\n",
    "    This scheduler function adjusts the learning rate based on the training epoch. It keeps the learning rate constant for\n",
    "    the first 20 epochs and then applies an exponential decay with a decay rate of tf.math.exp(-0.1).\n",
    "\n",
    "    Parameters:\n",
    "        epoch (int): The current training epoch.\n",
    "        lr (float): The current learning rate.\n",
    "\n",
    "    Returns:\n",
    "        float: The adjusted learning rate for the current epoch.\n",
    "    \"\"\"\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94db9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_optimized(X_train, y_train, input_shape,initial_rate=0.001,batch_size = 8,epochs=80):\n",
    "    \"\"\"\n",
    "    Create and train a more complex neural network model for Natural Language Processing (NLP) tasks.\n",
    "\n",
    "    This function defines a multi-layer neural network model with several hidden layers, ReLU activation functions,\n",
    "    and uses mean squared error as the loss function. It also includes a learning rate scheduler callback to adjust\n",
    "    the learning rate during training.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Input training data.\n",
    "        y_train (numpy.ndarray): Target training data.\n",
    "        input_shape (int): The shape of the input data.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.models.Sequential: The trained neural network model.\n",
    "    \"\"\"\n",
    "    # More complex neural network model\n",
    "    model = Sequential([\n",
    "        Dense(2048, input_shape=(input_shape,)),\n",
    "        Activation('relu'),\n",
    "        Dense(1024),\n",
    "        Activation('relu'),\n",
    "        Dense(512),\n",
    "        Activation('relu'),\n",
    "        Dense(256),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        Activation('relu'),\n",
    "        Dense(64),\n",
    "        Activation('relu'),\n",
    "        Dense(32),\n",
    "        Activation('relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the model with an initial learning rate\n",
    "    initial_learning_rate = initial_rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Learning rate scheduler callback\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "    # Fit the model with the learning rate scheduler\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[lr_scheduler], validation_split=0.2)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error on the test set\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4970ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_yearly_basis(df, n_folds, is_google_trends_only=False):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a yearly basis using cross-validation.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with yearly data using cross-validation. It splits\n",
    "    the data into `n_folds` folds and calculates the average percentage difference between true and predicted R&D expenditure\n",
    "    values for each fold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data.\n",
    "        n_folds (int): The number of folds for cross-validation.\n",
    "        is_google_trends_only (bool, optional): Indicates whether only Google Trends data is used as input features. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fold = 0\n",
    "    avg_percentages_diffs = []\n",
    "\n",
    "    # Loop through each fold of cross-validation\n",
    "    for (train_index, test_index) in cross_validation_indices(df, n_folds):\n",
    "        \n",
    "        # Split the data into training and test sets for the current fold\n",
    "        train_df = df.iloc[train_index]\n",
    "        train_df = train_df[:]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # Prepare input data and target data\n",
    "        X_train = train_df.drop(['v', 'year'], axis=1)\n",
    "        y_train = train_df['v']\n",
    "        X_test = test_df.drop(['v', 'year'], axis=1)\n",
    "        previous_R_D_values = X_test[\"v-1\"]\n",
    "        \n",
    "        if is_google_trends_only:\n",
    "            # Optionally remove the \"v-1\" column if using Google Trends data only\n",
    "            X_train = X_train.drop(axis=1, columns=[\"v-1\"])\n",
    "            X_test = X_test.drop(axis=1, columns=[\"v-1\"])\n",
    "        \n",
    "        input_shape = X_train.shape[1]\n",
    "        y_test = test_df['v']\n",
    "        \n",
    "        # Train an NLP model\n",
    "        model = NN_optimized(X_train, y_train, input_shape)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate true and predicted R&D expenditure values\n",
    "        R_D_true_values = previous_R_D_values + y_test\n",
    "        R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "        \n",
    "        # Calculate the average percentage difference for the current fold\n",
    "        avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "        print(f\"the average percentage diff for the {fold}th fold is : {avg_percentage_diff}%\")\n",
    "        \n",
    "        # Store the average percentage difference for this fold\n",
    "        avg_percentages_diffs.append(avg_percentage_diff)\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate the overall average percentage difference across all folds\n",
    "    avg_percentage_diff_folds = sum(avg_percentages_diffs) / n_folds \n",
    "    print(f\"the average percentage diff for this training is : {avg_percentage_diff_folds}%\")\n",
    "    return avg_percentage_diff_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23490576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_yearly_basis_select_parameters(df, is_google_trends_only=False,initial_rate=0.001,batch_size=20,epochs=80,f=NN_optimized):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a yearly basis using a fixed 80-20 train-test split.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with yearly data using a fixed 80-20 train-test split.\n",
    "    It calculates the average percentage difference between true and predicted R&D expenditure values for the test set.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data.\n",
    "        is_google_trends_only (bool, optional): Indicates whether only Google Trends data is used as input features. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        float: The average percentage difference for the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the data into training (80%) and test (20%) sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Prepare input data and target data for training\n",
    "    X_train = train_df.drop(['v', 'year'], axis=1)\n",
    "    y_train = train_df['v']\n",
    "    \n",
    "    # Prepare input data and target data for testing\n",
    "    X_test = test_df.drop(['v', 'year'], axis=1)\n",
    "    previous_R_D_values = test_df[\"v-1\"]\n",
    "    \n",
    "    if is_google_trends_only:\n",
    "        # Optionally remove the \"v-1\" column if using Google Trends data only\n",
    "        X_train = X_train.drop(axis=1, columns=[\"v-1\"])\n",
    "        X_test = X_test.drop(axis=1, columns=[\"v-1\"])\n",
    "    \n",
    "    input_shape = X_train.shape[1]\n",
    "    y_test = test_df['v']\n",
    "    \n",
    "    # Train an NLP model\n",
    "    model = f(X_train, y_train, input_shape,initial_rate,batch_size,epochs=epochs)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate true and predicted R&D expenditure values\n",
    "    R_D_true_values = previous_R_D_values + y_test\n",
    "    R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "    \n",
    "    # Calculate the average percentage difference for the test set\n",
    "    avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "    print(f\"The average percentage diff for the test set is: {avg_percentage_diff}%\")\n",
    "    \n",
    "    return avg_percentage_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6709f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rac\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From C:\\Users\\rac\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 0.0167 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0133 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0112 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.0113 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0116 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.0111 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0107 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0108 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0108 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0108 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0107 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0105 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0106 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0105 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0107 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0105 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0106 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0106 - val_loss: 0.0110 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0106 - val_loss: 0.0108 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0107 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0105 - val_loss: 0.0113 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0109 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0105 - val_loss: 0.0108 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0113 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0114 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0104 - val_loss: 0.0116 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0114 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0114 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0115 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 9.0953e-06\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "the average percentage diff for the 0th fold is : 3.718905863917172%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 4s 62ms/step - loss: 0.0155 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0141 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0145 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0136 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0144 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0135 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0133 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0133 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0137 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0134 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0134 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0135 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0139 - val_loss: 0.0108 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0114 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0118 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0134 - val_loss: 0.0109 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0134 - val_loss: 0.0108 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0135 - val_loss: 0.0123 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0112 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0104 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0133 - val_loss: 0.0107 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0113 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0132 - val_loss: 0.0109 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0107 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0109 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0131 - val_loss: 0.0107 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0107 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0107 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.4724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "the average percentage diff for the 1th fold is : 2.292672582898359%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 3s 48ms/step - loss: 0.0158 - val_loss: 0.0190 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0130 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0122 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0123 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0122 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0123 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0104 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0107 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0122 - val_loss: 0.0098 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0102 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0123 - val_loss: 0.0100 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0109 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0109 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0122 - val_loss: 0.0101 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0106 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0104 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0107 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0104 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0104 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 6.7206e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0105 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0105 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "the average percentage diff for the 2th fold is : 2.960573749743461%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 3s 70ms/step - loss: 0.0119 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0084 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0092 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0092 - val_loss: 0.0202 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0082 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0075 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0079 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0078 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0076 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0075 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0074 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0076 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0074 - val_loss: 0.0108 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0074 - val_loss: 0.0108 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0106 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0112 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0109 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0104 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0112 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0108 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0110 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0110 - lr: 1.8268e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "the average percentage diff for the 3th fold is : 3.7960484214277823%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 42ms/step - loss: 0.0175 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0282 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0175 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0185 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0127 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0127 - val_loss: 0.0168 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0127 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0127 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0126 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0181 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0128 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0165 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0161 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0172 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0161 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0163 - lr: 4.9659e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0166 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0166 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0173 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0165 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0165 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 2.4788e-06\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BE72D367A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "the average percentage diff for the 4th fold is : 1.8717530153540762%\n",
      "the average percentage diff for this training is : 2.9279907266681695%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9279907266681695"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_train = merged_df_R_D.drop(columns = [\"ISO\"])\n",
    "train_and_evaluate_yearly_basis(merged_df_train,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5b134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile(month):\n",
    "    \"\"\"\n",
    "    Determine the quartile (quarter) of a given month.\n",
    "\n",
    "    This function takes an integer representing a month (1 to 12) and returns the corresponding quartile based on the calendar year:\n",
    "    - 1: January to March\n",
    "    - 2: April to June\n",
    "    - 3: July to September\n",
    "    - 4: October to December\n",
    "\n",
    "    Parameters:\n",
    "        month (int): An integer representing a month (1 to 12).\n",
    "\n",
    "    Returns:\n",
    "        int: The quartile (quarter) to which the given month belongs.\n",
    "    \"\"\"\n",
    "    if 1 <= month <= 3:\n",
    "        return 1  # January to March\n",
    "    elif 4 <= month <= 6:\n",
    "        return 2  # April to June\n",
    "    elif 7 <= month <= 9:\n",
    "        return 3  # July to September\n",
    "    else:\n",
    "        return 4  # October to December\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de024e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading google trends data\n",
    "google_trends_data1 = pd.read_csv(\"google_trends_data_1\")\n",
    "google_trends_data2 = pd.read_csv(\"google_trends_data_2\")\n",
    "google_trends_data3 = pd.read_csv(\"google_trends_data_3\")\n",
    "google_trends_data4 = pd.read_csv(\"google_trends_data_4\")\n",
    "google_trends_data5 = pd.read_csv(\"google_trends_data_5\")\n",
    "google_trends_data6 = pd.read_csv(\"google_trends_data_6\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7addc80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ISO</th>\n",
       "      <th>quartile</th>\n",
       "      <th>Aerospace &amp; Defense</th>\n",
       "      <th>Chemicals Industry</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Computers &amp; Electronics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Fuel Economy</th>\n",
       "      <th>Biological Sciences</th>\n",
       "      <th>...</th>\n",
       "      <th>Jobs &amp; Education</th>\n",
       "      <th>Crime &amp; Justice</th>\n",
       "      <th>Social Services</th>\n",
       "      <th>Business News</th>\n",
       "      <th>Health News</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Social Issues &amp; Advocacy</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Ecology &amp; Environment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>85.666667</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>74.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>CHE</td>\n",
       "      <td>1</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>90.666667</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2021</td>\n",
       "      <td>KOR</td>\n",
       "      <td>4</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>83.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>35.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>44.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  ISO  quartile  Aerospace & Defense  Chemicals Industry  \\\n",
       "0    2006  CAN         1            91.333333           94.333333   \n",
       "1    2006  CAN         2            74.333333           86.333333   \n",
       "2    2006  CAN         3            82.000000           81.000000   \n",
       "3    2006  CAN         4            65.333333           83.666667   \n",
       "4    2006  CHE         1            79.666667           92.000000   \n",
       "..    ...  ...       ...                  ...                 ...   \n",
       "571  2021  KOR         4            76.666667           87.666667   \n",
       "572  2021  USA         1            29.000000           69.333333   \n",
       "573  2021  USA         2            39.333333           84.333333   \n",
       "574  2021  USA         3            31.000000           76.333333   \n",
       "575  2021  USA         4            28.666667           61.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech  Computers & Electronics  Automotive Industry  \\\n",
       "0                    96.333333                92.000000            82.333333   \n",
       "1                    86.666667                76.333333            82.000000   \n",
       "2                    79.666667                72.666667            83.333333   \n",
       "3                    78.000000                80.000000            78.000000   \n",
       "4                    92.000000                89.000000            79.000000   \n",
       "..                         ...                      ...                  ...   \n",
       "571                  82.333333                92.333333            23.000000   \n",
       "572                  27.000000                30.333333            30.666667   \n",
       "573                  28.333333                33.000000            28.000000   \n",
       "574                  29.000000                33.000000            27.000000   \n",
       "575                  33.333333                29.333333            22.333333   \n",
       "\n",
       "     Fuel Economy  Biological Sciences  ...  Jobs & Education  \\\n",
       "0       19.000000            87.666667  ...         85.666667   \n",
       "1       21.666667            83.666667  ...         87.000000   \n",
       "2       58.666667            69.333333  ...         81.000000   \n",
       "3       20.000000            89.000000  ...         82.333333   \n",
       "4       48.000000            92.666667  ...         90.666667   \n",
       "..            ...                  ...  ...               ...   \n",
       "571     69.000000            83.000000  ...         89.000000   \n",
       "572     22.000000            50.333333  ...         64.000000   \n",
       "573     18.666667            55.666667  ...         68.666667   \n",
       "574     15.333333            55.666667  ...         61.000000   \n",
       "575     14.333333            44.666667  ...         52.333333   \n",
       "\n",
       "     Crime & Justice  Social Services  Business News  Health News   Politics  \\\n",
       "0          92.666667        57.333333      91.000000    15.333333  94.666667   \n",
       "1          85.000000        50.333333      78.000000    17.333333  82.000000   \n",
       "2          81.333333        47.000000      62.666667    12.000000  70.666667   \n",
       "3          89.000000        50.666667      83.666667    21.000000  84.666667   \n",
       "4          91.333333        66.333333      95.666667    26.666667  80.666667   \n",
       "..               ...              ...            ...          ...        ...   \n",
       "571        85.333333        87.000000      73.333333    56.000000  88.000000   \n",
       "572        42.666667        44.000000      28.333333     8.333333  50.333333   \n",
       "573        88.333333        74.333333      30.333333     5.000000  59.666667   \n",
       "574        70.333333        49.333333      24.333333     7.333333  51.666667   \n",
       "575        51.666667        45.000000      22.000000    40.333333  44.333333   \n",
       "\n",
       "     Social Issues & Advocacy  Real Estate  Astronomy  Ecology & Environment  \n",
       "0                   86.666667    66.666667  91.000000              86.000000  \n",
       "1                   83.333333    48.666667  79.666667              79.000000  \n",
       "2                   86.000000    39.666667  76.666667              56.000000  \n",
       "3                   68.000000    49.333333  73.333333              74.333333  \n",
       "4                   92.000000    72.666667  95.666667              65.000000  \n",
       "..                        ...          ...        ...                    ...  \n",
       "571                 84.666667    63.666667  81.333333              83.666667  \n",
       "572                 59.666667    18.666667  27.666667              35.666667  \n",
       "573                 64.666667    20.000000  28.666667              34.000000  \n",
       "574                 67.666667    19.333333  28.000000              44.666667  \n",
       "575                 54.000000    22.000000  21.666667              30.333333  \n",
       "\n",
       "[576 rows x 95 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the dataframes\n",
    "merged_data_google_trends = pd.merge(google_trends_data1, google_trends_data2, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data3, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data4, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data5, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data6, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "\n",
    "#Replacing each month with its corresponding quartile of the year\n",
    "merged_data_google_trends[\"month\"] = merged_data_google_trends[\"month\"].apply(lambda x : quartile(x))\n",
    "merged_data_google_trends.rename(columns={'month': 'quartile'}, inplace=True)\n",
    "merged_data_google_trends = merged_data_google_trends.drop(columns = [\"date\"])\n",
    "\n",
    "#Add a year to every row, so that google trends data match the actual predicted value of R&D expanditures\n",
    "merged_data_google_trends[\"year\"] = merged_data_google_trends[\"year\"] +1\n",
    "\n",
    "#Average over all values for months within a quartile\n",
    "merged_data_google_trends = merged_data_google_trends.groupby([\"year\",\"Country\",\"quartile\"]).mean()\n",
    "merged_data_google_trends = merged_data_google_trends.reset_index()\n",
    "\n",
    "#replace country names with appropriate ISO encoding\n",
    "replacements = {\n",
    "    'CA': 'CAN', 'CH': 'CHE', 'CN': 'CHN', 'DE': 'DEU', 'FR': 'FRA', \n",
    "    'GB': 'GBR', 'JP': 'JPN', 'KR': 'KOR', 'US': 'USA', 'RU': 'RUS',\n",
    "    'IT': 'ITA', 'AU': 'AUS', 'ES': 'ESP', 'NL': 'NLD', 'SE': 'SWE', \n",
    "    'FI': 'FIN', 'BE': 'BEL', 'TW': 'TWN', 'SG': 'SGP', 'AT': 'AUT', \n",
    "    'DK': 'DNK', 'NO': 'NOR', 'PL': 'POL', 'TR': 'TUR', 'PT': 'PRT', \n",
    "    'IE': 'IRL', 'CZ': 'CZE'\n",
    "}\n",
    "\n",
    "merged_data_google_trends['Country'] = merged_data_google_trends['Country'].replace(replacements, regex=True)\n",
    "merged_data_google_trends.rename(columns={'Country': 'ISO'}, inplace=True)\n",
    "\n",
    "merged_data_google_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e3ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_uncorrelated_features(combined_data_quartiles, merged_df_R_D, correlation_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Filter features based on their correlation with a target variable.\n",
    "\n",
    "    This function filters the features in the `combined_data_quartiles` DataFrame based on their correlation with the target variable 'v'\n",
    "    from the `merged_df_R_D` DataFrame. Features with an absolute correlation coefficient greater than or equal to the specified\n",
    "    `correlation_threshold` are retained.\n",
    "\n",
    "    Parameters:\n",
    "        combined_data_quartiles (pandas.DataFrame): The DataFrame containing features for filtering.\n",
    "        merged_df_R_D (pandas.DataFrame): The DataFrame containing the target variable 'v'.\n",
    "        correlation_threshold (float, optional): The minimum absolute correlation coefficient for feature retention.\n",
    "            Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of feature names that meet the correlation threshold.\n",
    "    \"\"\"\n",
    "    R_D_values = pd.DataFrame(merged_df_R_D[[\"ISO\", \"year\", \"v\"]])\n",
    "\n",
    "    # Join features (X_train) and target (y_train) to compute correlations\n",
    "    # This ensures that the indices are aligned\n",
    "    data = pd.merge(combined_data_quartiles, R_D_values, on=['ISO', 'year'], how='inner')\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    data = data.drop(axis=1, columns=[\"ISO\", \"year\"])\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    # Get the absolute correlation values with the target variable\n",
    "    feature_correlation = correlation_matrix['v'].abs().sort_values(ascending=False)\n",
    "\n",
    "    # Drop the target variable correlation with itself\n",
    "    feature_correlation = feature_correlation.drop(labels=['v'])\n",
    "\n",
    "    # Keep only features with correlation above or equal to the threshold\n",
    "    features_kept = []\n",
    "    for feature, corr in feature_correlation.items():\n",
    "        if correlation_threshold <= corr:\n",
    "            features_kept.append(feature)\n",
    "    \n",
    "    return features_kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82ec1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Web Apps & Online Tools', 'Business Finance', 'Pharmaceutical Manufacturing', 'Data Management_y', 'Venture Capital', 'Pharmaceuticals & Biotech', 'Genetics', 'Automotive Industry', 'Nanobiotechnology', 'Software Utilities', 'Oil & Gas', 'Renewable Energy', 'Renewable Energy (Subcategory of Energy & Utilities)', 'Risk Management', 'Environmental Science', 'Artificial Intelligence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web Apps &amp; Online Tools</th>\n",
       "      <th>Business Finance</th>\n",
       "      <th>Pharmaceutical Manufacturing</th>\n",
       "      <th>Data Management_y</th>\n",
       "      <th>Venture Capital</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Nanobiotechnology</th>\n",
       "      <th>Software Utilities</th>\n",
       "      <th>Oil &amp; Gas</th>\n",
       "      <th>Renewable Energy</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)</th>\n",
       "      <th>Risk Management</th>\n",
       "      <th>Environmental Science</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <th>ISO</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.666667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>55.666667</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>USA</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>52.666667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>47.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Web Apps & Online Tools  Business Finance  Pharmaceutical Manufacturing  \\\n",
       "0                  68.333333         94.666667                     94.000000   \n",
       "1                  67.666667         75.666667                     78.000000   \n",
       "2                  75.000000         82.000000                     74.000000   \n",
       "3                  67.666667         74.333333                     81.333333   \n",
       "4                  74.333333         83.333333                     83.000000   \n",
       "..                       ...               ...                           ...   \n",
       "571                55.666667         59.000000                     57.000000   \n",
       "572                55.333333         65.333333                     61.666667   \n",
       "573                57.000000         71.000000                     52.666667   \n",
       "574                52.666667         75.000000                     55.000000   \n",
       "575                47.333333         63.000000                     51.000000   \n",
       "\n",
       "     Data Management_y  Venture Capital  Pharmaceuticals & Biotech   Genetics  \\\n",
       "0            85.000000        51.666667                  96.333333  86.333333   \n",
       "1            75.000000        46.333333                  86.666667  70.000000   \n",
       "2            66.333333        35.000000                  79.666667  64.333333   \n",
       "3            78.333333        46.000000                  78.000000  85.000000   \n",
       "4            95.000000        44.666667                  83.333333  84.000000   \n",
       "..                 ...              ...                        ...        ...   \n",
       "571          51.666667        18.333333                  24.333333  34.666667   \n",
       "572          53.000000        18.000000                  27.000000  37.000000   \n",
       "573          54.000000        15.000000                  28.333333  31.000000   \n",
       "574          53.000000        15.000000                  29.000000  27.333333   \n",
       "575          48.333333        15.000000                  33.333333  29.333333   \n",
       "\n",
       "     Automotive Industry  Nanobiotechnology  Software Utilities  Oil & Gas  \\\n",
       "0              82.333333          97.333333           95.000000  92.333333   \n",
       "1              82.000000          83.000000           78.000000  88.333333   \n",
       "2              83.333333          74.666667           77.333333  76.000000   \n",
       "3              78.000000          81.000000           82.333333  80.333333   \n",
       "4              77.333333          77.000000           76.666667  82.666667   \n",
       "..                   ...                ...                 ...        ...   \n",
       "571            41.333333          33.333333           51.666667  37.333333   \n",
       "572            30.666667          34.333333           53.666667  36.000000   \n",
       "573            28.000000          41.666667           54.666667  39.666667   \n",
       "574            27.000000          39.333333           53.333333  36.000000   \n",
       "575            22.333333          34.000000           42.666667  34.333333   \n",
       "\n",
       "     Renewable Energy  Renewable Energy (Subcategory of Energy & Utilities)  \\\n",
       "0           92.000000                                          92.000000      \n",
       "1           87.000000                                          87.000000      \n",
       "2           76.000000                                          75.666667      \n",
       "3           80.000000                                          80.000000      \n",
       "4           83.333333                                          83.000000      \n",
       "..                ...                                                ...      \n",
       "571         36.666667                                          36.333333      \n",
       "572         36.000000                                          36.000000      \n",
       "573         39.666667                                          39.666667      \n",
       "574         36.000000                                          35.666667      \n",
       "575         34.333333                                          36.000000      \n",
       "\n",
       "     Risk Management  Environmental Science  Artificial Intelligence  ISO  \\\n",
       "0          93.333333              57.000000                93.666667  CAN   \n",
       "1          81.666667              44.000000                74.333333  CAN   \n",
       "2          69.000000              37.333333                65.000000  CAN   \n",
       "3          73.333333              54.000000                81.333333  CAN   \n",
       "4          79.333333              51.666667                75.333333  CAN   \n",
       "..               ...                    ...                      ...  ...   \n",
       "571        31.000000              47.000000                48.333333  USA   \n",
       "572        31.000000              49.666667                46.000000  USA   \n",
       "573        31.000000              57.333333                48.000000  USA   \n",
       "574        29.333333              57.000000                45.000000  USA   \n",
       "575        25.000000              31.000000                38.333333  USA   \n",
       "\n",
       "     year  \n",
       "0    2006  \n",
       "1    2006  \n",
       "2    2006  \n",
       "3    2006  \n",
       "4    2007  \n",
       "..    ...  \n",
       "571  2020  \n",
       "572  2021  \n",
       "573  2021  \n",
       "574  2021  \n",
       "575  2021  \n",
       "\n",
       "[576 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine data of quartiles in order to use it for a yearly prediction basis\n",
    "combined_data_quartiles = merged_data_google_trends.groupby(['ISO', 'year', 'quartile']).mean()\n",
    "combined_data_quartiles = combined_data_quartiles.reset_index()\n",
    "combined_data_quartiles = combined_data_quartiles.drop(columns=[\"quartile\"])\n",
    "\n",
    "#Keeping this copy for feature selection afterwards\n",
    "full_combined_data_quartiles = combined_data_quartiles.copy()\n",
    "\n",
    "#Keep only features with a minimum threshold of correlation with the output\n",
    "features_kept = filter_uncorrelated_features(combined_data_quartiles,merged_df_R_D,correlation_threshold=0.12)\n",
    "print(features_kept)\n",
    "\n",
    "combined_data_quartiles = combined_data_quartiles.loc[:,features_kept+[\"ISO\",\"year\"]]\n",
    "combined_data_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f8e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>v-1</th>\n",
       "      <th>v</th>\n",
       "      <th>Web Apps &amp; Online Tools</th>\n",
       "      <th>Business Finance</th>\n",
       "      <th>Pharmaceutical Manufacturing</th>\n",
       "      <th>Data Management_y</th>\n",
       "      <th>Venture Capital</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Nanobiotechnology</th>\n",
       "      <th>Software Utilities</th>\n",
       "      <th>Oil &amp; Gas</th>\n",
       "      <th>Renewable Energy</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)</th>\n",
       "      <th>Risk Management</th>\n",
       "      <th>Environmental Science</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>93.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>74.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>81.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.039421</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>75.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>0.297284</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year       v-1         v  Web Apps & Online Tools  Business Finance  \\\n",
       "0    2006  1.971243 -0.028245                68.333333         94.666667   \n",
       "1    2006  1.971243 -0.028245                67.666667         75.666667   \n",
       "2    2006  1.971243 -0.028245                75.000000         82.000000   \n",
       "3    2006  1.971243 -0.028245                67.666667         74.333333   \n",
       "4    2007  1.942999 -0.039421                74.333333         83.333333   \n",
       "..    ...       ...       ...                      ...               ...   \n",
       "507  2020  3.170487  0.297284                55.666667         59.000000   \n",
       "508  2021  3.467771 -0.010725                55.333333         65.333333   \n",
       "509  2021  3.467771 -0.010725                57.000000         71.000000   \n",
       "510  2021  3.467771 -0.010725                52.666667         75.000000   \n",
       "511  2021  3.467771 -0.010725                47.333333         63.000000   \n",
       "\n",
       "     Pharmaceutical Manufacturing  Data Management_y  Venture Capital  \\\n",
       "0                       94.000000          85.000000        51.666667   \n",
       "1                       78.000000          75.000000        46.333333   \n",
       "2                       74.000000          66.333333        35.000000   \n",
       "3                       81.333333          78.333333        46.000000   \n",
       "4                       83.000000          95.000000        44.666667   \n",
       "..                            ...                ...              ...   \n",
       "507                     57.000000          51.666667        18.333333   \n",
       "508                     61.666667          53.000000        18.000000   \n",
       "509                     52.666667          54.000000        15.000000   \n",
       "510                     55.000000          53.000000        15.000000   \n",
       "511                     51.000000          48.333333        15.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech   Genetics  Automotive Industry  \\\n",
       "0                    96.333333  86.333333            82.333333   \n",
       "1                    86.666667  70.000000            82.000000   \n",
       "2                    79.666667  64.333333            83.333333   \n",
       "3                    78.000000  85.000000            78.000000   \n",
       "4                    83.333333  84.000000            77.333333   \n",
       "..                         ...        ...                  ...   \n",
       "507                  24.333333  34.666667            41.333333   \n",
       "508                  27.000000  37.000000            30.666667   \n",
       "509                  28.333333  31.000000            28.000000   \n",
       "510                  29.000000  27.333333            27.000000   \n",
       "511                  33.333333  29.333333            22.333333   \n",
       "\n",
       "     Nanobiotechnology  Software Utilities  Oil & Gas  Renewable Energy  \\\n",
       "0            97.333333           95.000000  92.333333         92.000000   \n",
       "1            83.000000           78.000000  88.333333         87.000000   \n",
       "2            74.666667           77.333333  76.000000         76.000000   \n",
       "3            81.000000           82.333333  80.333333         80.000000   \n",
       "4            77.000000           76.666667  82.666667         83.333333   \n",
       "..                 ...                 ...        ...               ...   \n",
       "507          33.333333           51.666667  37.333333         36.666667   \n",
       "508          34.333333           53.666667  36.000000         36.000000   \n",
       "509          41.666667           54.666667  39.666667         39.666667   \n",
       "510          39.333333           53.333333  36.000000         36.000000   \n",
       "511          34.000000           42.666667  34.333333         34.333333   \n",
       "\n",
       "     Renewable Energy (Subcategory of Energy & Utilities)  Risk Management  \\\n",
       "0                                            92.000000           93.333333   \n",
       "1                                            87.000000           81.666667   \n",
       "2                                            75.666667           69.000000   \n",
       "3                                            80.000000           73.333333   \n",
       "4                                            83.000000           79.333333   \n",
       "..                                                 ...                 ...   \n",
       "507                                          36.333333           31.000000   \n",
       "508                                          36.000000           31.000000   \n",
       "509                                          39.666667           31.000000   \n",
       "510                                          35.666667           29.333333   \n",
       "511                                          36.000000           25.000000   \n",
       "\n",
       "     Environmental Science  Artificial Intelligence  \n",
       "0                57.000000                93.666667  \n",
       "1                44.000000                74.333333  \n",
       "2                37.333333                65.000000  \n",
       "3                54.000000                81.333333  \n",
       "4                51.666667                75.333333  \n",
       "..                     ...                      ...  \n",
       "507              47.000000                48.333333  \n",
       "508              49.666667                46.000000  \n",
       "509              57.333333                48.000000  \n",
       "510              57.000000                45.000000  \n",
       "511              31.000000                38.333333  \n",
       "\n",
       "[512 rows x 19 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging Google Trends data and R&D expenditure values\n",
    "# In this merge, 'v-2' corresponds to the R&D expenditure value from 2 years ago,\n",
    "# 'v-1' corresponds to the R&D expenditure of the previous year,\n",
    "# and 'v' represents the difference we aim to predict between the current year\n",
    "# and the previous year's R&D expenditure value.\n",
    "\n",
    "google_trends_data = pd.merge(first_merged, combined_data_quartiles, on=['ISO', 'year'], how='inner')\n",
    "google_trends_data = google_trends_data.drop(axis =1 ,columns=[\"ISO\",\"v-2\"])\n",
    "google_trends_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1785a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "41/41 [==============================] - 3s 24ms/step - loss: 3.5549 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0253 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0150 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0132 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0134 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0183 - val_loss: 0.0337 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0213 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0234 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0138 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0101 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0123 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0116 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0167 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0112 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0112 - val_loss: 0.0187 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0089 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0087 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0142 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0096 - val_loss: 0.0162 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0103 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0079 - val_loss: 0.0108 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0077 - val_loss: 0.0106 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0082 - val_loss: 0.0098 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0074 - val_loss: 0.0093 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0068 - val_loss: 0.0103 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0068 - val_loss: 0.0116 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0067 - val_loss: 0.0118 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0110 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0100 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0058 - val_loss: 0.0100 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0101 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0055 - val_loss: 0.0104 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0102 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0055 - val_loss: 0.0114 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0058 - val_loss: 0.0120 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0113 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0053 - val_loss: 0.0100 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0106 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0106 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0104 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0104 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0106 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0106 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0108 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0108 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0111 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0114 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0109 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0111 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0108 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0108 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0109 - lr: 2.4788e-06\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BE4BB304A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "the average percentage diff for the 0th fold is : 2.528584735673178%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 3s 26ms/step - loss: 4.2572 - val_loss: 0.0623 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.1910 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0292 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0462 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0674 - val_loss: 0.0931 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0823 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0235 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0105 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0189 - val_loss: 0.0283 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0647 - val_loss: 0.0270 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0196 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0113 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0099 - val_loss: 0.0179 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0138 - val_loss: 0.0192 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0140 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0114 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0098 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0104 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0118 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0097 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0111 - val_loss: 0.0096 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0093 - val_loss: 0.0103 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0078 - val_loss: 0.0160 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0076 - val_loss: 0.0111 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0076 - val_loss: 0.0181 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0096 - val_loss: 0.0188 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0078 - val_loss: 0.0118 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0072 - val_loss: 0.0104 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0067 - val_loss: 0.0114 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0069 - val_loss: 0.0109 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0069 - val_loss: 0.0138 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0066 - val_loss: 0.0109 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0061 - val_loss: 0.0129 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0062 - val_loss: 0.0131 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0061 - val_loss: 0.0127 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0126 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0063 - val_loss: 0.0106 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0130 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0125 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0117 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0110 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0059 - val_loss: 0.0109 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0110 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0055 - val_loss: 0.0109 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0115 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0111 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0054 - val_loss: 0.0115 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0055 - val_loss: 0.0112 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0056 - val_loss: 0.0112 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0054 - val_loss: 0.0118 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0053 - val_loss: 0.0112 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0054 - val_loss: 0.0118 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0053 - val_loss: 0.0112 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0053 - val_loss: 0.0111 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0053 - val_loss: 0.0116 - lr: 3.0197e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0114 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0053 - val_loss: 0.0114 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0052 - val_loss: 0.0115 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0052 - val_loss: 0.0115 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0052 - val_loss: 0.0119 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0052 - val_loss: 0.0116 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0052 - val_loss: 0.0114 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0113 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0116 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0117 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0114 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0113 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0114 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0113 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0115 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0114 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0115 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0113 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0115 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0051 - val_loss: 0.0115 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0114 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0051 - val_loss: 0.0114 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0114 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0115 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "the average percentage diff for the 1th fold is : 2.7238019489366314%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 20ms/step - loss: 7.4379 - val_loss: 0.0205 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.5759 - val_loss: 0.1830 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.1052 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0101 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0118 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0101 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0100 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0165 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0098 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0103 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0095 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0110 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0091 - val_loss: 0.0307 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0119 - val_loss: 0.0142 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0145 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0138 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0093 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0130 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0084 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0086 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0094 - val_loss: 0.0117 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0084 - val_loss: 0.0140 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0077 - val_loss: 0.0130 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0077 - val_loss: 0.0152 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0099 - val_loss: 0.0126 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0087 - val_loss: 0.0143 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0085 - val_loss: 0.0109 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0076 - val_loss: 0.0111 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0076 - val_loss: 0.0120 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0072 - val_loss: 0.0111 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0078 - val_loss: 0.0112 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0070 - val_loss: 0.0111 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0068 - val_loss: 0.0120 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0069 - val_loss: 0.0124 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0066 - val_loss: 0.0131 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0115 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0071 - val_loss: 0.0123 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0095 - val_loss: 0.0123 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0073 - val_loss: 0.0109 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0064 - val_loss: 0.0111 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0121 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0067 - val_loss: 0.0114 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0122 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0065 - val_loss: 0.0112 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0112 - lr: 8.2085e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0064 - val_loss: 0.0111 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0064 - val_loss: 0.0117 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0116 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0061 - val_loss: 0.0115 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0121 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0118 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0128 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0065 - val_loss: 0.0114 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0061 - val_loss: 0.0123 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0060 - val_loss: 0.0114 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0122 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0125 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0116 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0115 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0061 - val_loss: 0.0115 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0119 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0118 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0119 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0117 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0120 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0115 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0117 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0116 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0117 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0119 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0117 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0059 - val_loss: 0.0117 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0118 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0117 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0117 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "the average percentage diff for the 2th fold is : 2.1147936236819143%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 21ms/step - loss: 2.2770 - val_loss: 0.0451 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.1433 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0276 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0159 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0361 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0154 - val_loss: 0.0258 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0227 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0140 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0221 - val_loss: 0.0264 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0146 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0140 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0111 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0113 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0105 - val_loss: 0.0197 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0100 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0105 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0082 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0164 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0087 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0101 - val_loss: 0.0196 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0091 - val_loss: 0.0093 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0079 - val_loss: 0.0101 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0081 - val_loss: 0.0093 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0076 - val_loss: 0.0099 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0086 - val_loss: 0.0131 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0080 - val_loss: 0.0116 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0073 - val_loss: 0.0112 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0073 - val_loss: 0.0107 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0068 - val_loss: 0.0094 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0074 - val_loss: 0.0116 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0070 - val_loss: 0.0114 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0068 - val_loss: 0.0094 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0070 - val_loss: 0.0111 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0068 - val_loss: 0.0102 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0120 - lr: 2.2313e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0107 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0068 - val_loss: 0.0101 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0069 - val_loss: 0.0105 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0100 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0064 - val_loss: 0.0104 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0064 - val_loss: 0.0097 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0063 - val_loss: 0.0096 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0063 - val_loss: 0.0102 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0065 - val_loss: 0.0094 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0063 - val_loss: 0.0100 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0100 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0109 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0063 - val_loss: 0.0095 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0062 - val_loss: 0.0096 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0102 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0119 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0062 - val_loss: 0.0113 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0061 - val_loss: 0.0102 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0109 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0101 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0106 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0060 - val_loss: 0.0103 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0100 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0061 - val_loss: 0.0103 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0060 - val_loss: 0.0103 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0105 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0105 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0103 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0104 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0106 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0103 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0060 - val_loss: 0.0104 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0104 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0104 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0059 - val_loss: 0.0102 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0059 - val_loss: 0.0102 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0102 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0059 - val_loss: 0.0102 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0103 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "the average percentage diff for the 3th fold is : 2.580476084828995%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 20ms/step - loss: 3.1490 - val_loss: 0.0183 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0125 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0478 - val_loss: 0.0454 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0323 - val_loss: 0.0420 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0708 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0139 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0112 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0163 - val_loss: 0.0191 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0099 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0170 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0087 - val_loss: 0.0194 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0087 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0087 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0087 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0081 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0086 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0076 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0081 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0070 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0076 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0069 - val_loss: 0.0106 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0115 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0070 - val_loss: 0.0107 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0066 - val_loss: 0.0102 - lr: 6.0653e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0066 - val_loss: 0.0116 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0067 - val_loss: 0.0105 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0119 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0060 - val_loss: 0.0116 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0067 - val_loss: 0.0132 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0059 - val_loss: 0.0106 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0067 - val_loss: 0.0114 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0110 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0056 - val_loss: 0.0106 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0108 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0107 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0115 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0110 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0057 - val_loss: 0.0105 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0058 - val_loss: 0.0108 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0106 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0106 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0107 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0113 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0109 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0050 - val_loss: 0.0111 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0114 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0111 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0111 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "the average percentage diff for the 4th fold is : 2.7677102970629925%\n",
      "the average percentage diff for this training is : 2.5430733380367423%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5430733380367423"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_yearly_basis(google_trends_data,5,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12333006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cdb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d12b49f",
   "metadata": {},
   "source": [
    "## Choices of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f0d76",
   "metadata": {},
   "source": [
    "### 1 -  NN width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8896fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for NN_width 64\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 135.2762 - val_loss: 52.3174 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.0109 - val_loss: 25.0755 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2545 - val_loss: 18.8960 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9605 - val_loss: 13.6294 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6776 - val_loss: 8.1977 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.7580 - val_loss: 7.2201 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.4392 - val_loss: 5.1353 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.5820 - val_loss: 4.3992 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.1494 - val_loss: 3.9936 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.7406 - val_loss: 3.7684 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.4494 - val_loss: 3.5184 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3193 - val_loss: 3.1755 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.0610 - val_loss: 3.0006 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9840 - val_loss: 3.0225 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8374 - val_loss: 2.6992 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.6895 - val_loss: 2.7503 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9566 - val_loss: 2.3559 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5938 - val_loss: 2.4718 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4107 - val_loss: 2.6141 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5298 - val_loss: 2.1319 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4196 - val_loss: 2.0078 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1816 - val_loss: 2.0137 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1105 - val_loss: 2.0768 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1408 - val_loss: 1.8548 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1294 - val_loss: 1.8632 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0768 - val_loss: 1.7640 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0292 - val_loss: 1.7132 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0517 - val_loss: 1.7066 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9876 - val_loss: 1.7142 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9698 - val_loss: 1.7244 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9444 - val_loss: 1.6743 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9415 - val_loss: 1.6321 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9312 - val_loss: 1.6145 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9282 - val_loss: 1.6140 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9235 - val_loss: 1.6433 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9329 - val_loss: 1.5767 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8849 - val_loss: 1.5757 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8830 - val_loss: 1.5624 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8753 - val_loss: 1.5532 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8699 - val_loss: 1.5468 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8651 - val_loss: 1.5393 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8574 - val_loss: 1.5334 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8511 - val_loss: 1.5344 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8498 - val_loss: 1.5272 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8452 - val_loss: 1.5175 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8430 - val_loss: 1.5134 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8455 - val_loss: 1.5122 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8571 - val_loss: 1.5140 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8394 - val_loss: 1.5075 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8351 - val_loss: 1.5080 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8312 - val_loss: 1.4990 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8341 - val_loss: 1.5049 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8353 - val_loss: 1.4971 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8284 - val_loss: 1.4974 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8247 - val_loss: 1.4946 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8240 - val_loss: 1.4942 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8249 - val_loss: 1.4928 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8207 - val_loss: 1.4947 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8216 - val_loss: 1.4937 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8201 - val_loss: 1.4897 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8204 - val_loss: 1.4876 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8188 - val_loss: 1.4875 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8175 - val_loss: 1.4867 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8170 - val_loss: 1.4855 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8165 - val_loss: 1.4852 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8160 - val_loss: 1.4840 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8158 - val_loss: 1.4831 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8150 - val_loss: 1.4833 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8153 - val_loss: 1.4834 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8152 - val_loss: 1.4812 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8146 - val_loss: 1.4816 - lr: 6.0967e-06\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8137 - val_loss: 1.4809 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8140 - val_loss: 1.4804 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8135 - val_loss: 1.4801 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8135 - val_loss: 1.4807 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8129 - val_loss: 1.4804 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8127 - val_loss: 1.4803 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8125 - val_loss: 1.4798 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8123 - val_loss: 1.4798 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8123 - val_loss: 1.4794 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 38.168275748093166%\n",
      "Evaluating for NN_width 128\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 22.0638 - val_loss: 8.2424 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.2917 - val_loss: 2.6744 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.6969 - val_loss: 2.7392 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9691 - val_loss: 1.5950 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5521 - val_loss: 1.3821 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1352 - val_loss: 1.0334 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9688 - val_loss: 0.9707 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9097 - val_loss: 1.0745 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8186 - val_loss: 0.8710 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7385 - val_loss: 0.7716 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.5365 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6699 - val_loss: 0.5142 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4942 - val_loss: 1.0395 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5245 - val_loss: 0.6396 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.3738 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3910 - val_loss: 0.3724 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3343 - val_loss: 0.3289 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2744 - val_loss: 0.2770 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2478 - val_loss: 0.2690 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2829 - val_loss: 0.4922 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2569 - val_loss: 0.2675 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2383 - val_loss: 0.4065 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2720 - val_loss: 0.2185 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1785 - val_loss: 0.2612 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.1925 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1536 - val_loss: 0.2392 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1478 - val_loss: 0.1802 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1353 - val_loss: 0.1947 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1450 - val_loss: 0.1985 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1315 - val_loss: 0.2211 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1394 - val_loss: 0.1686 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1291 - val_loss: 0.1653 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1243 - val_loss: 0.1859 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1255 - val_loss: 0.1566 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1260 - val_loss: 0.1637 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1201 - val_loss: 0.1611 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1085 - val_loss: 0.1753 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1084 - val_loss: 0.1817 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1083 - val_loss: 0.1633 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1018 - val_loss: 0.1603 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1036 - val_loss: 0.1519 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1032 - val_loss: 0.1554 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1059 - val_loss: 0.1632 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1070 - val_loss: 0.1551 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1042 - val_loss: 0.1572 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.1508 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0967 - val_loss: 0.1609 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1012 - val_loss: 0.1511 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0970 - val_loss: 0.1561 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0963 - val_loss: 0.1500 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.1517 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0951 - val_loss: 0.1505 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0960 - val_loss: 0.1560 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0954 - val_loss: 0.1512 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0941 - val_loss: 0.1506 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0936 - val_loss: 0.1513 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1505 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0942 - val_loss: 0.1498 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0934 - val_loss: 0.1507 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.1496 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.1496 - lr: 1.6573e-05\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0931 - val_loss: 0.1515 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0932 - val_loss: 0.1497 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.1503 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0928 - val_loss: 0.1493 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0926 - val_loss: 0.1492 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0923 - val_loss: 0.1492 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0922 - val_loss: 0.1492 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0921 - val_loss: 0.1492 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0919 - val_loss: 0.1489 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0922 - val_loss: 0.1498 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0918 - val_loss: 0.1489 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0918 - val_loss: 0.1489 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1495 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0917 - val_loss: 0.1498 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0919 - val_loss: 0.1497 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0918 - val_loss: 0.1487 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0916 - val_loss: 0.1490 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.1491 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0915 - val_loss: 0.1493 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 12.231363222308804%\n",
      "Evaluating for NN_width 256\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 21.7281 - val_loss: 6.6082 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.8163 - val_loss: 3.3353 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4295 - val_loss: 1.2198 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0261 - val_loss: 0.9060 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7958 - val_loss: 0.8252 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7775 - val_loss: 0.6895 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5618 - val_loss: 0.5772 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4305 - val_loss: 0.4526 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3772 - val_loss: 0.4573 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - val_loss: 0.3737 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3405 - val_loss: 0.4098 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3286 - val_loss: 0.6467 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.3588 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2559 - val_loss: 0.3386 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2040 - val_loss: 0.4707 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2397 - val_loss: 0.2619 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2101 - val_loss: 0.4287 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3738 - val_loss: 0.3015 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2314 - val_loss: 0.2527 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1544 - val_loss: 0.2238 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1425 - val_loss: 0.2100 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1255 - val_loss: 0.2422 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1108 - val_loss: 0.1882 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1503 - val_loss: 0.2510 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1217 - val_loss: 0.1732 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1056 - val_loss: 0.2771 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1382 - val_loss: 0.3455 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0893 - val_loss: 0.1663 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0755 - val_loss: 0.1682 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0749 - val_loss: 0.1704 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0751 - val_loss: 0.1742 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0701 - val_loss: 0.1747 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0715 - val_loss: 0.1727 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.1623 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0656 - val_loss: 0.1629 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0640 - val_loss: 0.1577 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.1687 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.1617 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0704 - val_loss: 0.1633 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.1609 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.1688 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0667 - val_loss: 0.1624 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0590 - val_loss: 0.1541 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0592 - val_loss: 0.1623 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0596 - val_loss: 0.1565 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.1542 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0570 - val_loss: 0.1576 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0582 - val_loss: 0.1550 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0568 - val_loss: 0.1530 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0567 - val_loss: 0.1537 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0570 - val_loss: 0.1588 - lr: 4.5049e-05\n",
      "Epoch 52/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0568 - val_loss: 0.1532 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.1541 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0560 - val_loss: 0.1561 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0555 - val_loss: 0.1536 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0568 - val_loss: 0.1560 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.1515 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0559 - val_loss: 0.1516 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0550 - val_loss: 0.1509 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.1516 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0560 - val_loss: 0.1518 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0551 - val_loss: 0.1517 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.1519 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0550 - val_loss: 0.1521 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.1514 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.1516 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0545 - val_loss: 0.1520 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0548 - val_loss: 0.1513 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0543 - val_loss: 0.1515 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.1523 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0545 - val_loss: 0.1515 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.1516 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0543 - val_loss: 0.1516 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.1517 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0541 - val_loss: 0.1519 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.1514 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.1511 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.1511 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.1511 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0540 - val_loss: 0.1514 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 13.90015310097521%\n",
      "Evaluating for NN_width 512\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 2273.9531 - val_loss: 89.3344 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 224.0442 - val_loss: 211.3852 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 92.5673 - val_loss: 66.4392 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 65.8549 - val_loss: 53.7130 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 49.1040 - val_loss: 44.7645 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.1739 - val_loss: 35.5792 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.6757 - val_loss: 30.2224 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.0779 - val_loss: 24.8216 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.0502 - val_loss: 20.4918 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.5261 - val_loss: 17.2792 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2542 - val_loss: 14.4762 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6349 - val_loss: 12.1951 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.5310 - val_loss: 10.3965 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.8044 - val_loss: 9.7788 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5355 - val_loss: 8.0728 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6348 - val_loss: 7.8798 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8864 - val_loss: 7.2511 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.9491 - val_loss: 6.0776 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.2857 - val_loss: 5.3770 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.7654 - val_loss: 5.3661 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.4168 - val_loss: 4.8270 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.9969 - val_loss: 4.6512 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.8600 - val_loss: 4.2567 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.6192 - val_loss: 4.4009 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.4412 - val_loss: 4.1475 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.3233 - val_loss: 4.1756 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.2115 - val_loss: 3.9191 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.1363 - val_loss: 3.8571 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.0560 - val_loss: 3.8077 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.9835 - val_loss: 3.8395 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8948 - val_loss: 3.7112 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8506 - val_loss: 3.6649 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.7890 - val_loss: 3.6457 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.7532 - val_loss: 3.5928 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.6913 - val_loss: 3.6676 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.7328 - val_loss: 3.5489 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.6404 - val_loss: 3.5130 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.6110 - val_loss: 3.5536 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5870 - val_loss: 3.5402 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5488 - val_loss: 3.4503 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5443 - val_loss: 3.4221 - lr: 1.2246e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.5212 - val_loss: 3.4512 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.5173 - val_loss: 3.4342 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.4853 - val_loss: 3.4417 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4793 - val_loss: 3.4201 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4644 - val_loss: 3.3892 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4612 - val_loss: 3.4229 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.4424 - val_loss: 3.3692 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.4438 - val_loss: 3.3503 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4463 - val_loss: 3.4033 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.4147 - val_loss: 3.3775 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4062 - val_loss: 3.3650 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4050 - val_loss: 3.3728 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3939 - val_loss: 3.3362 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3886 - val_loss: 3.3288 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3880 - val_loss: 3.3137 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3801 - val_loss: 3.3198 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3805 - val_loss: 3.3369 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3761 - val_loss: 3.3097 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3683 - val_loss: 3.3181 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3676 - val_loss: 3.3341 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3628 - val_loss: 3.3355 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3595 - val_loss: 3.3297 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3574 - val_loss: 3.3199 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3564 - val_loss: 3.3153 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.3533 - val_loss: 3.3200 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3516 - val_loss: 3.3182 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3505 - val_loss: 3.3261 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3487 - val_loss: 3.3267 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3470 - val_loss: 3.3215 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3462 - val_loss: 3.3177 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3445 - val_loss: 3.3186 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3435 - val_loss: 3.3229 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3427 - val_loss: 3.3229 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3422 - val_loss: 3.3171 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3410 - val_loss: 3.3163 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.3403 - val_loss: 3.3159 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.3397 - val_loss: 3.3149 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3395 - val_loss: 3.3137 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.3385 - val_loss: 3.3143 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 57.788342056239564%\n",
      "Evaluating for NN_width 1024\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 34.0375 - val_loss: 7.1162 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.4013 - val_loss: 2.7852 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4585 - val_loss: 0.3295 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2619 - val_loss: 0.1331 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1213 - val_loss: 0.1073 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1092 - val_loss: 0.1888 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.0951 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0651 - val_loss: 0.1540 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0601 - val_loss: 0.0676 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0596 - val_loss: 0.0803 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.0618 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0334 - val_loss: 0.0550 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0703 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.1222 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.0491 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0789 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.0661 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0575 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0550 - val_loss: 0.0635 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0787 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0337 - val_loss: 0.0392 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0413 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0409 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0462 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0373 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0430 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0451 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0527 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0375 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0403 - lr: 3.3287e-04\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0378 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0372 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0392 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0454 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0375 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0378 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0414 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0367 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0378 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0370 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0366 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0371 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0374 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0373 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0383 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0383 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0378 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0374 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0377 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0376 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0368 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0386 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0372 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0367 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0373 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0371 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0370 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0372 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0370 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0371 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0371 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0372 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0369 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0372 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0368 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0370 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0369 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0370 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0368 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0373 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0368 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0371 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0368 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0369 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0370 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0370 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0371 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0368 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0368 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 4.263116838329683%\n",
      "Evaluating for NN_width 2048\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 75.4790 - val_loss: 4.7662 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6108 - val_loss: 3.0582 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4118 - val_loss: 0.3960 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3159 - val_loss: 0.3762 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1970 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0598 - val_loss: 0.0634 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0476 - val_loss: 0.0578 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.0384 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0616 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.0318 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0310 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0340 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0261 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0364 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0315 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0262 - lr: 9.0484e-04\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0222 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0206 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0241 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0204 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0328 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0200 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0216 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0197 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0203 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0212 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0236 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0220 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0200 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0198 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0193 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0196 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0196 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0196 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0191 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0205 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0219 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0220 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0208 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0192 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0190 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0189 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0191 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0197 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0199 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0190 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0196 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0196 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0191 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0191 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0197 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0191 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0205 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0192 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0193 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0197 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0193 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0194 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0195 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0195 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0194 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0195 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0194 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0196 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0193 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0194 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0193 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0195 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0194 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0192 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0194 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0194 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0194 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0195 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 4.312300784700652%\n",
      "Evaluating for NN_width 4096\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 221.9070 - val_loss: 60.4320 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.1197 - val_loss: 13.6114 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.3309 - val_loss: 0.4178 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.1956 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1559 - val_loss: 0.0850 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0878 - val_loss: 0.0853 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0476 - val_loss: 0.0564 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.0720 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0377 - val_loss: 0.0452 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0308 - val_loss: 0.0520 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0377 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0346 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0303 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0273 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0422 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0265 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0217 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0212 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0204 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0211 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0196 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0204 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0195 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0190 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0215 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0183 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0182 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0177 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0181 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0179 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0176 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0176 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0174 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0174 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0172 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0173 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0172 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0174 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0171 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0171 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0174 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0172 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0170 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0173 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0172 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0173 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0169 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0170 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0169 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0173 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0168 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0170 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0169 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0170 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0169 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0170 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0168 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0170 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0168 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0168 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0169 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0169 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0168 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0168 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0169 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0168 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0168 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0169 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0168 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 3.749810034828154%\n",
      "Evaluating for NN_width 8192\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 306.5572 - val_loss: 62.8562 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.9300 - val_loss: 16.7119 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.3114 - val_loss: 0.5066 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7986 - val_loss: 0.1813 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1783 - val_loss: 0.0594 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0653 - val_loss: 0.0521 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0350 - val_loss: 0.0324 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0321 - val_loss: 0.0297 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0208 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0196 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0275 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0184 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0381 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0137 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0142 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0129 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0124 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0122 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0125 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0145 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0119 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0118 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0126 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0117 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0118 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0119 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0116 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0116 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0119 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0116 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0114 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0114 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0114 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0114 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0114 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0114 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0116 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0113 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0124 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0113 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0114 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0113 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0113 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0114 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0112 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0113 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0113 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0113 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0113 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0113 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0112 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0113 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 5.5166e-06\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 3.0053441924676734%\n",
      "Evaluating for NN_width 16384\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 14ms/step - loss: 707.9196 - val_loss: 224.1094 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 59.4876 - val_loss: 38.0453 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 11.5880 - val_loss: 8.8109 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2.6998 - val_loss: 0.3353 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3393 - val_loss: 0.1763 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0978 - val_loss: 0.0560 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0468 - val_loss: 0.0339 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0180 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0176 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0309 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0186 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0156 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0115 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0146 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0107 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0136 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0108 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0135 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0107 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0110 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0105 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0104 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0101 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0104 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0102 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0100 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0102 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0105 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0103 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0100 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0098 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0099 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0098 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0098 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0098 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0098 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0097 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 1.4996e-05\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 2.7975289696271446%\n",
      "Evaluating for NN_width 32768\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 14ms/step - loss: 1264.1361 - val_loss: 117.5199 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 67.5823 - val_loss: 10.4221 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5.0818 - val_loss: 2.3423 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.9921 - val_loss: 0.2137 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1572 - val_loss: 0.0770 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0636 - val_loss: 0.0419 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0337 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0130 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0168 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0108 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0111 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0106 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0103 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0101 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0103 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0113 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0099 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0099 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0101 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0097 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0105 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0100 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0097 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0101 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0096 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0098 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0097 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0096 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0095 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0097 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0094 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0096 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0093 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0095 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0096 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0094 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0093 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0093 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0093 - lr: 4.0762e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0092 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0092 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0092 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.6989721939280655%\n"
     ]
    }
   ],
   "source": [
    "NN_widths = [64,128,256,512,1024,2048,4096,8192,16384,32768]\n",
    "\n",
    "# List to store average percentage differences for each width\n",
    "avg_percentages_diffs_NN_widths = []\n",
    "\n",
    "\n",
    "#Evaluating for Width 64\n",
    "print(\"Evaluating for NN_width 64\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_64)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 128\n",
    "print(\"Evaluating for NN_width 128\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_128)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 256\n",
    "print(\"Evaluating for NN_width 256\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_256)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 512\n",
    "print(\"Evaluating for NN_width 512\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_512)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 1024\n",
    "print(\"Evaluating for NN_width 1024\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_1024)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 2048\n",
    "print(\"Evaluating for NN_width 2048\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_2048)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 4096\n",
    "print(\"Evaluating for NN_width 4096\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_4096)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 8192\n",
    "print(\"Evaluating for NN_width 8192\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_8192)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 16384\n",
    "print(\"Evaluating for NN_width 16384\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_16384)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 32768\n",
    "print(\"Evaluating for NN_width 32768\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_32768)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84d277a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(NN_widths, avg_percentages_diffs_NN_widths, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. NN_width')\n",
    "plt.xlabel('NN_width')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154a6cf",
   "metadata": {},
   "source": [
    "### 1- NN depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40fe7f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for NN_depth 1\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 669.6566 - val_loss: 208.8083 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 57.5528 - val_loss: 34.6888 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1788 - val_loss: 8.5172 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.7585 - val_loss: 0.7267 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4525 - val_loss: 0.1904 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1871 - val_loss: 0.1324 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0814 - val_loss: 0.0578 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0537 - val_loss: 0.0376 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0387 - val_loss: 0.0269 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0174 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0126 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0104 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0103 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0102 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0121 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0100 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0097 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0098 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0094 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0096 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0093 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0093 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0094 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0093 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0098 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0097 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0096 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0092 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0093 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0092 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0096 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0092 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0094 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0092 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0091 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0092 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0092 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0092 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 6.0967e-06\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The average percentage diff for the test set is: 2.928058119372653%\n",
      "Evaluating for NN_depth 3\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 26ms/step - loss: 295.9350 - val_loss: 2.0826 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 2.6936 - val_loss: 0.2319 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2054 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0273 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0208 - val_loss: 0.0245 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0179 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0142 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0110 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0101 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0083 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0098 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0091 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0079 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0079 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0078 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0078 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0080 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0078 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0080 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0076 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.6573e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.5203023679965146%\n",
      "Evaluating for NN_depth 5\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 22.0494 - val_loss: 1.9185 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.6551 - val_loss: 0.0321 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1168 - val_loss: 0.0208 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0283 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0205 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0195 - val_loss: 0.0181 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0086 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0241 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0083 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0092 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0084 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0086 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0078 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0142 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0083 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0086 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0079 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0079 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0133 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0117 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0080 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0104 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0082 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0110 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0094 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0086 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0085 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0081 - lr: 4.9787e-05\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0080 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0078 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.4342922057326914%\n",
      "Evaluating for NN_depth 7\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 27ms/step - loss: 17.3452 - val_loss: 0.3541 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.5467 - val_loss: 0.6499 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3230 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0351 - val_loss: 0.0687 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0267 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0152 - val_loss: 0.0945 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0464 - val_loss: 0.0710 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0310 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0483 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0220 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0352 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0201 - val_loss: 0.0142 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0512 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1076 - val_loss: 0.0489 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0663 - val_loss: 0.0313 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0092 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0099 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0132 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0096 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0189 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0093 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0124 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0091 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0117 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0187 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0107 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0105 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0085 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0088 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0086 - lr: 1.4957e-04\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0141 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0087 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0090 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0085 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0085 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0085 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0091 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0085 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.514220297324141%\n",
      "Evaluating for NN_depth 8\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 40ms/step - loss: 9.5261 - val_loss: 0.0825 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1102 - val_loss: 0.0561 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0329 - val_loss: 0.0297 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0365 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0233 - val_loss: 0.0606 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0362 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0237 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0186 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0164 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0202 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0241 - val_loss: 0.0483 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0142 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0087 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0215 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0094 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0152 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0088 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0098 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0113 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0089 - lr: 4.0657e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0116 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0158 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0188 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0118 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0084 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0085 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0102 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0086 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0137 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0099 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0083 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0098 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0086 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0089 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0085 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0085 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0083 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.4386011026173646%\n",
      "Evaluating for NN_depth 9\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 27ms/step - loss: 0.3441 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0157 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0137 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0132 - val_loss: 0.0142 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0123 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.9439337511327133%\n",
      "Evaluating for NN_depth 10\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 0.0974 - val_loss: 0.0162 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0159 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0154 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0136 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0142 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3460e-06\n",
      "Epoch 78/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.956774216923971%\n",
      "Evaluating for NN_depth 11\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 28ms/step - loss: 0.4791 - val_loss: 0.0153 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0139 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0137 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0141 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0125 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0123 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 1.0052e-05\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.9389436588331956%\n"
     ]
    }
   ],
   "source": [
    "NN_depths = [1,3,5,7,8,9,10,11]\n",
    "\n",
    "# List to store average percentage differences for each depth\n",
    "avg_percentages_diffs_NN_depths = []\n",
    "\n",
    "\n",
    "#Evaluating for Depth 1\n",
    "print(\"Evaluating for NN_depth 1\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_1)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 3\n",
    "print(\"Evaluating for NN_depth 3\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_3)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 5\n",
    "print(\"Evaluating for NN_depth 5\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_5)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 7\n",
    "print(\"Evaluating for NN_depth 7\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_7)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 8\n",
    "print(\"Evaluating for NN_depth 8\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_8)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 9\n",
    "print(\"Evaluating for NN_depth 9\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_9)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 10\n",
    "print(\"Evaluating for NN_depth 10\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_10)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 11\n",
    "print(\"Evaluating for NN_depth 11\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_11)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f323d544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(NN_depths, avg_percentages_diffs_NN_depths, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. NN_depth')\n",
    "plt.xlabel('NN_depth')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac2fe2",
   "metadata": {},
   "source": [
    "### 1 - correlation threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ea97d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for threshold : 0.03\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 27ms/step - loss: 42.1096 - val_loss: 0.0253 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3592 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0307 - val_loss: 0.0640 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0461 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0397 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1890 - val_loss: 0.1541 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0640 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0171 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0184 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0437 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5651 - val_loss: 0.0606 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1617 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0351 - val_loss: 0.0162 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0101 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0101 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0093 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0089 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0088 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0090 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0090 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0127 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0125 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0087 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0090 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0088 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0104 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0094 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.0093 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0085 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0090 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0102 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0086 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0102 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0085 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0086 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0089 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0085 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0088 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0085 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0086 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0087 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0085 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 6.7379e-06\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.3927783196596755%\n",
      "Testing performance for threshold : 0.1\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 12.2612 - val_loss: 0.1061 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1309 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0304 - val_loss: 0.0320 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0231 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0352 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0218 - val_loss: 0.0159 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0235 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0082 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0127 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0154 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0094 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0087 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0082 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0094 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0081 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0079 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0161 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0088 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0078 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0079 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0076 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0075 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0134 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0124 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0075 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0102 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0076 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0095 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0075 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0053 - val_loss: 0.0076 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0078 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0076 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0075 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0074 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0074 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0076 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0074 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0076 - lr: 2.0242e-05\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0075 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0075 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0074 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0075 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0074 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0075 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.4832720065922644%\n",
      "Testing performance for threshold : 0.12\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 3.7495 - val_loss: 1.8570 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.9327 - val_loss: 0.3335 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1268 - val_loss: 0.0199 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0180 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0199 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0169 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0157 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0094 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0102 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0119 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0105 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0166 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0083 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0095 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0105 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0108 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0096 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0160 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0096 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0095 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0081 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0080 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0132 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0080 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0088 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0087 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0079 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0081 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0081 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.424628850438424%\n",
      "Testing performance for threshold : 0.16\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 6.1702 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1538 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0255 - val_loss: 0.0187 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0162 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0168 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0199 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0278 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0190 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0239 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0186 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0186 - val_loss: 0.0091 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0106 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0086 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0109 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0095 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0108 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0103 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0114 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0104 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0095 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0143 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0116 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0090 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0089 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 1.8268e-04\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0114 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0103 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0128 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0119 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0086 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0101 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0089 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0088 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0085 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0087 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0086 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0092 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0094 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0093 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0086 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0085 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0086 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0086 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0089 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0088 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0086 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.3609253085197346%\n",
      "Testing performance for threshold : 0.2\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 30ms/step - loss: 3.7098 - val_loss: 0.6373 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0901 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0361 - val_loss: 0.1149 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0263 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0268 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0265 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0497 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0446 - val_loss: 0.0433 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0319 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0221 - val_loss: 0.0296 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0173 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0207 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0187 - val_loss: 0.0321 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0087 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0092 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0094 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0084 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0085 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0164 - lr: 5.4881e-04\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0086 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0084 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0131 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0133 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0101 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0105 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0089 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0120 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0099 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0086 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0086 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0086 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0112 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0086 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0101 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0084 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0090 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0092 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0085 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0093 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0084 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0085 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0085 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0085 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0084 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.6055646656122096%\n"
     ]
    }
   ],
   "source": [
    "# List of correlation thresholds to test\n",
    "correlation_thresholds = [0.03, 0.1, 0.12, 0.16, 0.2]\n",
    "\n",
    "# List to store average percentage differences for each threshold\n",
    "avg_percentages_diffs = []\n",
    "\n",
    "# Loop through each correlation threshold\n",
    "for correlation_threshold in correlation_thresholds:\n",
    "    print(f\"Testing performance for threshold : {correlation_threshold}\")\n",
    "    \n",
    "    # Keep only features with a minimum threshold of correlation with the output\n",
    "    features_kept_test = filter_uncorrelated_features(full_combined_data_quartiles, merged_df_R_D, correlation_threshold=correlation_threshold)\n",
    "\n",
    "    # Create a DataFrame with selected features and additional columns \"ISO\" and \"year\"\n",
    "    combined_data_quartiles_test = full_combined_data_quartiles.loc[:, features_kept_test + [\"ISO\", \"year\"]]\n",
    "\n",
    "    # Merge the selected features with Google Trends data based on \"ISO\" and \"year\"\n",
    "    google_trends_data_test = pd.merge(first_merged, combined_data_quartiles_test, on=['ISO', 'year'], how='inner')\n",
    "\n",
    "    # Drop columns \"ISO\" and \"v-2\" from the merged DataFrame\n",
    "    google_trends_data_test = google_trends_data_test.drop(axis=1, columns=[\"ISO\", \"v-2\"])\n",
    "\n",
    "    # Train and evaluate the model with the selected data and calculate the average percentage difference\n",
    "    avg_percentage_diff = train_and_evaluate_yearly_basis_select_parameters(google_trends_data_test, True)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs.append(avg_percentage_diff)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31894ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(correlation_thresholds, avg_percentages_diffs, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. Correlation Thresholds')\n",
    "plt.xlabel('Correlation Threshold')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a129b",
   "metadata": {},
   "source": [
    "### 2 - initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdcf3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for initial_rate : 1e-05\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 30ms/step - loss: 2.5015 - val_loss: 0.0658 - lr: 1.0000e-05\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0778 - val_loss: 0.0417 - lr: 1.0000e-05\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0375 - val_loss: 0.0261 - lr: 1.0000e-05\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0187 - lr: 1.0000e-05\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0160 - lr: 1.0000e-05\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0123 - val_loss: 0.0152 - lr: 1.0000e-05\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0133 - lr: 1.0000e-05\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0126 - lr: 1.0000e-05\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0124 - lr: 1.0000e-05\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0116 - lr: 1.0000e-05\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0070 - val_loss: 0.0113 - lr: 1.0000e-05\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0114 - lr: 1.0000e-05\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0115 - lr: 1.0000e-05\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0113 - lr: 1.0000e-05\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0112 - lr: 1.0000e-05\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0107 - lr: 1.0000e-05\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0104 - lr: 1.0000e-05\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 1.0000e-05\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0104 - lr: 1.0000e-05\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0046 - val_loss: 0.0103 - lr: 9.0484e-06\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0103 - lr: 8.1873e-06\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0043 - val_loss: 0.0102 - lr: 7.4082e-06\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0044 - val_loss: 0.0100 - lr: 6.7032e-06\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0100 - lr: 6.0653e-06\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0101 - lr: 5.4881e-06\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0101 - lr: 4.9659e-06\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0100 - lr: 4.4933e-06\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0098 - lr: 4.0657e-06\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0099 - lr: 3.6788e-06\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0099 - lr: 3.3287e-06\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0098 - lr: 3.0119e-06\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0037 - val_loss: 0.0098 - lr: 2.7253e-06\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0098 - lr: 2.4660e-06\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0036 - val_loss: 0.0098 - lr: 2.2313e-06\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0098 - lr: 2.0190e-06\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0098 - lr: 1.8268e-06\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0035 - val_loss: 0.0098 - lr: 1.6530e-06\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0034 - val_loss: 0.0098 - lr: 1.4957e-06\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0034 - val_loss: 0.0098 - lr: 1.3534e-06\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0034 - val_loss: 0.0098 - lr: 1.2246e-06\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0098 - lr: 1.1080e-06\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0098 - lr: 1.0026e-06\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0097 - lr: 9.0718e-07\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0097 - lr: 8.2085e-07\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0097 - lr: 7.4274e-07\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 6.7206e-07\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 6.0810e-07\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 5.5023e-07\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 4.9787e-07\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 4.5049e-07\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 4.0762e-07\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 3.6883e-07\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 3.3373e-07\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 3.0197e-07\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 2.7324e-07\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 2.4724e-07\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 2.2371e-07\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 2.0242e-07\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.8316e-07\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.6573e-07\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.4996e-07\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.3569e-07\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.2277e-07\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.1109e-07\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0097 - lr: 1.0052e-07\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 9.0953e-08\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 8.2297e-08\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 7.4466e-08\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 6.7379e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 6.0967e-08\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 5.5166e-08\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 4.9916e-08\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 4.5166e-08\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 4.0868e-08\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 3.6979e-08\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 3.3460e-08\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 3.0276e-08\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 2.7394e-08\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0097 - lr: 2.4788e-08\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 2.485924903466018%\n",
      "Testing performance for initial_rate : 0.0001\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 0.5545 - val_loss: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0108 - lr: 9.0484e-05\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0094 - lr: 8.1873e-05\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0080 - lr: 7.4082e-05\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.0067 - lr: 6.7032e-05\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0030 - val_loss: 0.0077 - lr: 6.0653e-05\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0071 - lr: 5.4881e-05\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0031 - val_loss: 0.0073 - lr: 4.9659e-05\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0062 - lr: 4.4933e-05\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0064 - lr: 4.0657e-05\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0064 - lr: 3.6788e-05\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0023 - val_loss: 0.0064 - lr: 3.3287e-05\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0064 - lr: 3.0119e-05\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0065 - lr: 2.7253e-05\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.0062 - lr: 2.4660e-05\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0063 - lr: 2.2313e-05\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0063 - lr: 2.0190e-05\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0062 - lr: 1.8268e-05\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0062 - lr: 1.6530e-05\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0062 - lr: 1.4957e-05\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0061 - lr: 1.3534e-05\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0062 - lr: 1.2246e-05\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0063 - lr: 1.1080e-05\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0064 - lr: 1.0026e-05\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0062 - lr: 9.0718e-06\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0061 - lr: 8.2085e-06\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0063 - lr: 7.4274e-06\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0061 - lr: 6.7206e-06\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 6.0810e-06\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 5.5023e-06\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 4.9787e-06\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 4.5049e-06\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 4.0762e-06\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 3.6883e-06\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 3.3373e-06\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 3.0197e-06\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 2.7324e-06\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0062 - lr: 2.4724e-06\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 2.2371e-06\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 2.0242e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 1.8316e-06\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0061 - lr: 1.6573e-06\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 1.4996e-06\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 1.3569e-06\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 1.2277e-06\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 1.1109e-06\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 1.0052e-06\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 9.0953e-07\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 8.2298e-07\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 7.4466e-07\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 6.7380e-07\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 6.0968e-07\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 5.5166e-07\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 4.9916e-07\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 4.5166e-07\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 4.0868e-07\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 3.6979e-07\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 3.3460e-07\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 3.0276e-07\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 2.7394e-07\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0061 - lr: 2.4788e-07\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.124651994476471%\n",
      "Testing performance for initial_rate : 0.01\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 28ms/step - loss: 158856.4062 - val_loss: 68.3065 - lr: 0.0100\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 15.9820 - val_loss: 0.1716 - lr: 0.0100\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.6497 - val_loss: 0.0755 - lr: 0.0100\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0309 - val_loss: 0.0130 - lr: 0.0100\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0111 - lr: 0.0100\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0112 - lr: 0.0100\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0123 - lr: 0.0100\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0143 - lr: 0.0100\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0246 - val_loss: 0.0123 - lr: 0.0100\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0150 - lr: 0.0100\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0106 - lr: 0.0100\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0120 - lr: 0.0100\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0101 - lr: 0.0100\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0105 - lr: 0.0100\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0119 - lr: 0.0100\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0142 - val_loss: 0.0224 - lr: 0.0100\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 0.0097 - lr: 0.0100\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 2044s 128s/step - loss: 0.0093 - val_loss: 0.0095 - lr: 0.0100\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0092 - lr: 0.0100\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0103 - lr: 0.0100\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0108 - lr: 0.0090\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0100 - lr: 0.0082\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 0.0090 - val_loss: 0.0090 - lr: 0.0074\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0142 - val_loss: 0.0095 - lr: 0.0067\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0100 - lr: 0.0061\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0119 - lr: 0.0055\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0093 - lr: 0.0050\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0095 - lr: 0.0045\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0090 - lr: 0.0041\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0088 - lr: 0.0037\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0088 - lr: 0.0033\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0089 - lr: 0.0030\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 0.0080 - val_loss: 0.0088 - lr: 0.0027\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0079 - val_loss: 0.0088 - lr: 0.0025\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.0079 - val_loss: 0.0096 - lr: 0.0022\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.0084 - val_loss: 0.0098 - lr: 0.0020\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0085 - val_loss: 0.0090 - lr: 0.0018\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0082 - val_loss: 0.0088 - lr: 0.0017\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 0.0015\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0088 - lr: 0.0014\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 0.0012\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0089 - lr: 0.0011\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0088 - lr: 9.0718e-04\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0088 - lr: 8.2085e-04\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.0089 - lr: 7.4274e-04\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 6.7206e-04\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 6.0810e-04\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 5.5023e-04\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 4.9787e-04\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 4.5049e-04\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 4.0762e-04\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 3.6883e-04\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 3.3373e-04\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 3.0197e-04\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.7324e-04\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.4724e-04\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.2371e-04\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.0242e-04\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.8316e-04\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.6573e-04\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.4996e-04\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.3569e-04\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.2277e-04\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.1109e-04\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.0052e-04\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 9.0953e-05\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 8.2298e-05\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 7.4466e-05\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 6.7380e-05\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 6.0968e-05\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 5.5166e-05\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 4.9916e-05\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 4.5166e-05\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 4.0868e-05\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0087 - lr: 3.6979e-05\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 3.3460e-05\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 3.0276e-05\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.7394e-05\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.4788e-05\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 2.863493770080086%\n",
      "Testing performance for initial_rate : 0.05\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 30ms/step - loss: 732126838784.0000 - val_loss: 8604372.0000 - lr: 0.0500\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1144147.6250 - val_loss: 772255.7500 - lr: 0.0500\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 264206.5625 - val_loss: 355200.5000 - lr: 0.0500\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 210714.6719 - val_loss: 57112.5000 - lr: 0.0500\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 8914.9043 - val_loss: 499.7693 - lr: 0.0500\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 1675.3175 - val_loss: 404.5745 - lr: 0.0500\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 565.8784 - val_loss: 152.1830 - lr: 0.0500\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 46.1886 - val_loss: 11.6391 - lr: 0.0500\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 5.2067 - val_loss: 5.2088 - lr: 0.0500\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 2.3299 - val_loss: 1.9128 - lr: 0.0500\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.2186 - val_loss: 0.6413 - lr: 0.0500\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.7711 - val_loss: 1.0878 - lr: 0.0500\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.9564 - val_loss: 0.7337 - lr: 0.0500\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.9839 - val_loss: 0.6085 - lr: 0.0500\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.1683 - val_loss: 0.5980 - lr: 0.0500\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6910 - val_loss: 0.6517 - lr: 0.0500\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6376 - val_loss: 0.7360 - lr: 0.0500\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.8713 - val_loss: 0.6144 - lr: 0.0500\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6626 - val_loss: 0.6220 - lr: 0.0500\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.7273 - val_loss: 0.5905 - lr: 0.0500\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.1426 - val_loss: 1.4075 - lr: 0.0452\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.8176 - val_loss: 0.8264 - lr: 0.0409\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 1.0961 - val_loss: 0.7342 - lr: 0.0370\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6822 - val_loss: 0.5261 - lr: 0.0335\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6144 - val_loss: 0.5052 - lr: 0.0303\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6270 - val_loss: 0.6252 - lr: 0.0274\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.6355 - val_loss: 0.5158 - lr: 0.0248\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.5623 - val_loss: 0.5246 - lr: 0.0225\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5641 - val_loss: 0.7493 - lr: 0.0203\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5749 - val_loss: 0.4916 - lr: 0.0184\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5377 - val_loss: 0.4811 - lr: 0.0166\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.6182 - val_loss: 0.4752 - lr: 0.0151\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5558 - val_loss: 0.5379 - lr: 0.0136\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5567 - val_loss: 0.4651 - lr: 0.0123\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5109 - val_loss: 0.5910 - lr: 0.0112\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5615 - val_loss: 0.5634 - lr: 0.0101\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5347 - val_loss: 0.4798 - lr: 0.0091\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4938 - val_loss: 0.4633 - lr: 0.0083\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4993 - val_loss: 0.4562 - lr: 0.0075\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5111 - val_loss: 0.4560 - lr: 0.0068\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5069 - val_loss: 0.4506 - lr: 0.0061\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5028 - val_loss: 0.4512 - lr: 0.0055\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4952 - val_loss: 0.4628 - lr: 0.0050\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4814 - val_loss: 0.4711 - lr: 0.0045\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4872 - val_loss: 0.4468 - lr: 0.0041\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4875 - val_loss: 0.4466 - lr: 0.0037\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4849 - val_loss: 0.4430 - lr: 0.0034\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4947 - val_loss: 0.4423 - lr: 0.0030\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4926 - val_loss: 0.4413 - lr: 0.0028\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4735 - val_loss: 0.4461 - lr: 0.0025\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4738 - val_loss: 0.4402 - lr: 0.0023\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4768 - val_loss: 0.4522 - lr: 0.0020\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4787 - val_loss: 0.4438 - lr: 0.0018\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4765 - val_loss: 0.4517 - lr: 0.0017\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4780 - val_loss: 0.4451 - lr: 0.0015\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4806 - val_loss: 0.4453 - lr: 0.0014\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4683 - val_loss: 0.4399 - lr: 0.0012\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.4677 - val_loss: 0.4365 - lr: 0.0011\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4673 - val_loss: 0.4380 - lr: 0.0010\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4695 - val_loss: 0.4384 - lr: 9.1578e-04\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4704 - val_loss: 0.4365 - lr: 8.2863e-04\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4681 - val_loss: 0.4354 - lr: 7.4978e-04\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.4686 - val_loss: 0.4382 - lr: 6.7843e-04\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4665 - val_loss: 0.4355 - lr: 6.1387e-04\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4691 - val_loss: 0.4360 - lr: 5.5545e-04\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4646 - val_loss: 0.4344 - lr: 5.0259e-04\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4660 - val_loss: 0.4348 - lr: 4.5476e-04\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4651 - val_loss: 0.4346 - lr: 4.1149e-04\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4658 - val_loss: 0.4350 - lr: 3.7233e-04\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4647 - val_loss: 0.4351 - lr: 3.3690e-04\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4650 - val_loss: 0.4339 - lr: 3.0484e-04\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4649 - val_loss: 0.4342 - lr: 2.7583e-04\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4645 - val_loss: 0.4340 - lr: 2.4958e-04\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4643 - val_loss: 0.4336 - lr: 2.2583e-04\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4637 - val_loss: 0.4339 - lr: 2.0434e-04\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4635 - val_loss: 0.4333 - lr: 1.8489e-04\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4642 - val_loss: 0.4335 - lr: 1.6730e-04\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4633 - val_loss: 0.4335 - lr: 1.5138e-04\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4638 - val_loss: 0.4332 - lr: 1.3697e-04\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4632 - val_loss: 0.4332 - lr: 1.2394e-04\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The average percentage diff for the test set is: 15.828452405086608%\n"
     ]
    }
   ],
   "source": [
    "# List of initial_rates for NN optimization to test\n",
    "initial_rates = [0.00001,0.0001,0.01,0.05]\n",
    "\n",
    "# List to store average percentage differences for each initial_rate\n",
    "avg_percentages_diffs_initial_rates = []\n",
    "\n",
    "# Loop through each initial_rate\n",
    "for initial_rate in initial_rates:\n",
    "    print(f\"Testing performance for initial_rate : {initial_rate}\")\n",
    "    avg_percentages_diffs_initial_rate = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,initial_rate=initial_rate)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_initial_rates.append(avg_percentages_diffs_initial_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f9d17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "203a4e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(initial_rates, avg_percentages_diffs_initial_rates, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. Initial rates')\n",
    "plt.xlabel('Initial rates')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e984d0",
   "metadata": {},
   "source": [
    "### 3 - Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7471c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for batch_size : 7\n",
      "Epoch 1/80\n",
      "47/47 [==============================] - 3s 21ms/step - loss: 4.3233 - val_loss: 0.0290 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0235 - val_loss: 0.0188 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0171 - val_loss: 0.0966 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0397 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0205 - val_loss: 0.0368 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0197 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0138 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0265 - val_loss: 0.0438 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0128 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0167 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0261 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0105 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0089 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0115 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0145 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0130 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0097 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0078 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0086 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0089 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0078 - val_loss: 0.0111 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0084 - val_loss: 0.0084 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0075 - val_loss: 0.0083 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0074 - val_loss: 0.0081 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0073 - val_loss: 0.0086 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0070 - val_loss: 0.0082 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0067 - val_loss: 0.0087 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0070 - val_loss: 0.0093 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0076 - val_loss: 0.0080 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0082 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0063 - val_loss: 0.0095 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0064 - val_loss: 0.0079 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0063 - val_loss: 0.0079 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0062 - val_loss: 0.0085 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0059 - val_loss: 0.0082 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 6.7379e-06\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 2.358830045315702%\n",
      "Testing performance for batch_size : 8\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 3s 36ms/step - loss: 2.1975 - val_loss: 0.0928 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0455 - val_loss: 0.0497 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0131 - val_loss: 0.0191 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0175 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0112 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0182 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0129 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0164 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0123 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0160 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0243 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0133 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0148 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0093 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0118 - val_loss: 0.0209 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0118 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0096 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0084 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0080 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0075 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0081 - val_loss: 0.0099 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0101 - val_loss: 0.0078 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0065 - val_loss: 0.0079 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0068 - val_loss: 0.0080 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0076 - val_loss: 0.0122 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0078 - val_loss: 0.0076 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0060 - val_loss: 0.0076 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0062 - val_loss: 0.0077 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0056 - val_loss: 0.0098 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0058 - val_loss: 0.0074 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0050 - val_loss: 0.0084 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0055 - val_loss: 0.0074 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0072 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0049 - val_loss: 0.0069 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0045 - val_loss: 0.0067 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0045 - val_loss: 0.0081 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0046 - val_loss: 0.0069 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0070 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0041 - val_loss: 0.0083 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0042 - val_loss: 0.0072 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0043 - val_loss: 0.0073 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0041 - val_loss: 0.0068 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0040 - val_loss: 0.0069 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0041 - val_loss: 0.0072 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0040 - val_loss: 0.0067 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - val_loss: 0.0070 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0039 - val_loss: 0.0069 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0039 - val_loss: 0.0070 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - val_loss: 0.0070 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0040 - val_loss: 0.0069 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0039 - val_loss: 0.0068 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0039 - val_loss: 0.0068 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0069 - lr: 2.0242e-05\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 0.0069 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0069 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0038 - val_loss: 0.0068 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 0.0068 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0036 - val_loss: 0.0068 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 2.2357294853882603%\n",
      "Testing performance for batch_size : 10\n",
      "Epoch 1/80\n",
      "33/33 [==============================] - 2s 25ms/step - loss: 3.8355 - val_loss: 0.0404 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.1023 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0186 - val_loss: 0.0423 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0229 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0208 - val_loss: 0.1695 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.1365 - val_loss: 0.0771 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0304 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0126 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0098 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0121 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0110 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0115 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0127 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0182 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0161 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0154 - val_loss: 0.0176 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0150 - val_loss: 0.0417 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0156 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0099 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0074 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0118 - val_loss: 0.0130 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0086 - val_loss: 0.0092 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0088 - val_loss: 0.0123 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0083 - val_loss: 0.0090 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0078 - val_loss: 0.0103 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0073 - val_loss: 0.0082 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0067 - val_loss: 0.0090 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0067 - val_loss: 0.0106 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0088 - val_loss: 0.0128 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0075 - val_loss: 0.0085 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0092 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0095 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0059 - val_loss: 0.0102 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0098 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0094 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0081 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0081 - lr: 6.0810e-05\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0080 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0078 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0080 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0079 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0076 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0077 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0077 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0077 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 2.3574454587528373%\n",
      "Testing performance for batch_size : 15\n",
      "Epoch 1/80\n",
      "22/22 [==============================] - 2s 27ms/step - loss: 3.7569 - val_loss: 0.4534 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0954 - val_loss: 0.0179 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0375 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0343 - val_loss: 0.0513 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0478 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1084 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0171 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0204 - val_loss: 0.0203 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0307 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0305 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0368 - val_loss: 0.0529 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0684 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0274 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0358 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0492 - val_loss: 0.0571 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0630 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0156 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0082 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0079 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0089 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0080 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0066 - val_loss: 0.0088 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0121 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0081 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0081 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0116 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0077 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0092 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0078 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0077 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0078 - lr: 1.8268e-04\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0088 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0078 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0077 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0077 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0081 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0076 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.350767170928812%\n",
      "Testing performance for batch_size : 25\n",
      "Epoch 1/80\n",
      "14/14 [==============================] - 2s 31ms/step - loss: 4.5775 - val_loss: 4.7019 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.9661 - val_loss: 0.2690 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2552 - val_loss: 0.1431 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0719 - val_loss: 0.0365 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0242 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0182 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0110 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0116 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0102 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0147 - val_loss: 0.1226 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0408 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0225 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0082 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0142 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0089 - val_loss: 0.0151 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.0098 - val_loss: 0.0091 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0076 - val_loss: 0.0086 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0074 - val_loss: 0.0086 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0070 - val_loss: 0.0091 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0151 - lr: 5.4881e-04\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0085 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0087 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0113 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0083 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0087 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0134 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0104 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0091 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0083 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0109 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0094 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0090 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0092 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0103 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0124 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0091 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0087 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.0087 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0072 - val_loss: 0.0086 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "The average percentage diff for the test set is: 2.5551514856371984%\n",
      "Testing performance for batch_size : 35\n",
      "Epoch 1/80\n",
      "10/10 [==============================] - 2s 58ms/step - loss: 13.2258 - val_loss: 0.3558 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5598 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1667 - val_loss: 0.1993 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1415 - val_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0625 - val_loss: 0.0813 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.1677 - val_loss: 0.2494 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.3108 - val_loss: 0.4904 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1615 - val_loss: 0.0788 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0445 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0178 - val_loss: 0.0540 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0404 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0242 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0119 - val_loss: 0.0330 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0264 - val_loss: 0.0746 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0368 - val_loss: 0.0394 - lr: 0.0010\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0332 - val_loss: 0.0924 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0330 - val_loss: 0.0661 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0322 - val_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0264 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0352 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0348 - val_loss: 0.0269 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0224 - val_loss: 0.0088 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0201 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0183 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0125 - val_loss: 0.0120 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0093 - val_loss: 0.0088 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0104 - val_loss: 0.0084 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0105 - val_loss: 0.0081 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0097 - val_loss: 0.0080 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0072 - val_loss: 0.0080 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0078 - val_loss: 0.0081 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0071 - val_loss: 0.0080 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0071 - val_loss: 0.0081 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0070 - val_loss: 0.0083 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0074 - val_loss: 0.0090 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0083 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0076 - val_loss: 0.0082 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0080 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0068 - val_loss: 0.0096 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0077 - val_loss: 0.0112 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.0133 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0089 - val_loss: 0.0095 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0082 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0081 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0080 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0081 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0082 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.0081 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0068 - val_loss: 0.0080 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0080 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The average percentage diff for the test set is: 2.6015021408264873%\n",
      "Testing performance for batch_size : 45\n",
      "Epoch 1/80\n",
      "8/8 [==============================] - 2s 52ms/step - loss: 33.7609 - val_loss: 0.9475 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9284 - val_loss: 0.2424 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2660 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0789 - val_loss: 0.0491 - lr: 0.0010\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0441 - val_loss: 0.0537 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0238 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0098 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0087 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0268 - val_loss: 0.1796 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0593 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0317 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0185 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0174 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0090 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0087 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0152 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0106 - val_loss: 0.0149 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0093 - val_loss: 0.0087 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0086 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0085 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0085 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0099 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0083 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0090 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0082 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0082 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0067 - val_loss: 0.0102 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0088 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0092 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0082 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 3.6979e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 2.658210536838216%\n"
     ]
    }
   ],
   "source": [
    "# List of batch sizes to test\n",
    "batch_sizes = [7,8,10,15,25,35,45]\n",
    "\n",
    "# List to store average percentage differences for each batch size\n",
    "avg_percentages_diffs_batch_sizes = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing performance for batch_size : {batch_size}\")\n",
    "    avg_percentages_diffs_batch_size = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,batch_size=batch_size)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_batch_sizes.append(avg_percentages_diffs_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(batch_sizes, avg_percentages_diffs_batch_sizes, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. Batch sizes')\n",
    "plt.xlabel('Batch sizes')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f52712",
   "metadata": {},
   "source": [
    "### 4 - Number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "405e2ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for epochs : 5\n",
      "Epoch 1/5\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 3.6277 - val_loss: 0.6007 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2634 - val_loss: 0.0397 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0910 - val_loss: 0.3548 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1760 - val_loss: 0.0569 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.1039 - val_loss: 0.0626 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 9.897520758587685%\n",
      "Testing performance for epochs : 10\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 4.7263 - val_loss: 0.0372 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4155 - val_loss: 0.0770 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2137 - val_loss: 0.3011 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0723 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0184 - val_loss: 0.2468 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.3010 - val_loss: 0.0965 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0360 - val_loss: 0.0203 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0195 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0239 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0161 - val_loss: 0.0108 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 3.098809372621001%\n",
      "Testing performance for epochs : 20\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 2s 48ms/step - loss: 4.5059 - val_loss: 0.2731 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1478 - val_loss: 0.3226 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0823 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1610 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0382 - val_loss: 0.0870 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.3207 - val_loss: 0.3987 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2259 - val_loss: 0.3019 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0660 - val_loss: 0.0187 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0287 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0154 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0093 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.6430884142945503%\n",
      "Testing performance for epochs : 40\n",
      "Epoch 1/40\n",
      "17/17 [==============================] - 2s 36ms/step - loss: 4.7136 - val_loss: 0.2495 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1420 - val_loss: 0.1228 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0522 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0140 - val_loss: 0.0506 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0252 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0211 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0457 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0857 - val_loss: 0.0189 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0264 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0097 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0100 - lr: 9.0484e-04\n",
      "Epoch 22/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0084 - lr: 8.1873e-04\n",
      "Epoch 23/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 0.0153 - lr: 7.4082e-04\n",
      "Epoch 24/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0088 - lr: 6.7032e-04\n",
      "Epoch 25/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0081 - lr: 6.0653e-04\n",
      "Epoch 26/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0174 - lr: 5.4881e-04\n",
      "Epoch 27/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0082 - lr: 4.9659e-04\n",
      "Epoch 28/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0090 - lr: 4.4933e-04\n",
      "Epoch 29/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0097 - lr: 4.0657e-04\n",
      "Epoch 30/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0083 - lr: 3.6788e-04\n",
      "Epoch 31/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0104 - lr: 3.3287e-04\n",
      "Epoch 32/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0142 - lr: 3.0119e-04\n",
      "Epoch 33/40\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0084 - lr: 2.7253e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0087 - lr: 2.4660e-04\n",
      "Epoch 35/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0078 - lr: 2.2313e-04\n",
      "Epoch 36/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0077 - lr: 2.0190e-04\n",
      "Epoch 37/40\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0076 - lr: 1.8268e-04\n",
      "Epoch 38/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 1.6530e-04\n",
      "Epoch 39/40\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0067 - val_loss: 0.0076 - lr: 1.4957e-04\n",
      "Epoch 40/40\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0119 - lr: 1.3534e-04\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 3.525619881249199%\n",
      "Testing performance for epochs : 60\n",
      "Epoch 1/60\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 2.4234 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0209 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0276 - val_loss: 0.1218 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0588 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0123 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0234 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0220 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0087 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0098 - lr: 9.0484e-04\n",
      "Epoch 22/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0092 - lr: 8.1873e-04\n",
      "Epoch 23/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0097 - lr: 7.4082e-04\n",
      "Epoch 24/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0092 - lr: 6.7032e-04\n",
      "Epoch 25/60\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0143 - lr: 5.4881e-04\n",
      "Epoch 27/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0093 - lr: 4.9659e-04\n",
      "Epoch 28/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0088 - lr: 4.4933e-04\n",
      "Epoch 29/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0145 - lr: 4.0657e-04\n",
      "Epoch 30/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0146 - lr: 3.6788e-04\n",
      "Epoch 31/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0099 - lr: 3.3287e-04\n",
      "Epoch 32/60\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0099 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0085 - lr: 2.7253e-04\n",
      "Epoch 34/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0099 - lr: 2.4660e-04\n",
      "Epoch 35/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 2.2313e-04\n",
      "Epoch 36/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0087 - lr: 2.0190e-04\n",
      "Epoch 37/60\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.8268e-04\n",
      "Epoch 38/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/60\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 1.4957e-04\n",
      "Epoch 40/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0097 - lr: 1.3534e-04\n",
      "Epoch 41/60\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0087 - lr: 1.2246e-04\n",
      "Epoch 42/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0094 - lr: 1.1080e-04\n",
      "Epoch 43/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0084 - lr: 1.0026e-04\n",
      "Epoch 44/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 7.4274e-05\n",
      "Epoch 47/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 6.7206e-05\n",
      "Epoch 48/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/60\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0090 - lr: 5.5023e-05\n",
      "Epoch 50/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 4.9787e-05\n",
      "Epoch 51/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 4.5049e-05\n",
      "Epoch 52/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0089 - lr: 4.0762e-05\n",
      "Epoch 53/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 3.6883e-05\n",
      "Epoch 54/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 3.0197e-05\n",
      "Epoch 56/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 2.7324e-05\n",
      "Epoch 57/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.2371e-05\n",
      "Epoch 59/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 1.8316e-05\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.5494699473622933%\n",
      "Testing performance for epochs : 80\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 37ms/step - loss: 5.0622 - val_loss: 0.1504 - lr: 0.0010\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0839 - val_loss: 0.1010 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1534 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0503 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0242 - val_loss: 0.1133 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0499 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0286 - val_loss: 0.0297 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0253 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0203 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0575 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0215 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0085 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0192 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0084 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0123 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0084 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.0090 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0092 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0109 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0195 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0150 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0090 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0071 - val_loss: 0.0105 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0091 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0114 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0114 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0080 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0101 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0086 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0080 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0080 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0083 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0082 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0059 - val_loss: 0.0079 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 5.5166e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.394501018337633%\n",
      "Testing performance for epochs : 100\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 2s 28ms/step - loss: 13.5383 - val_loss: 1.2802 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5870 - val_loss: 0.4887 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3195 - val_loss: 0.1142 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0933 - val_loss: 0.1017 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0456 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0356 - val_loss: 0.0545 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0306 - val_loss: 0.0396 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0329 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0280 - val_loss: 0.0211 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0343 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0242 - val_loss: 0.0182 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0388 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0085 - lr: 9.0484e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0204 - lr: 8.1873e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0080 - lr: 7.4082e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0092 - lr: 6.7032e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0080 - lr: 6.0653e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0087 - lr: 5.4881e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0078 - lr: 4.9659e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0091 - lr: 4.4933e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0101 - lr: 4.0657e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0089 - lr: 3.6788e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0165 - lr: 3.3287e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0082 - lr: 3.0119e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0077 - lr: 2.7253e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 2.4660e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0074 - lr: 2.2313e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0075 - lr: 2.0190e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 1.8268e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0114 - lr: 1.6530e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0106 - lr: 1.4957e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0076 - lr: 1.3534e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0095 - lr: 1.2246e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0076 - lr: 1.1080e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0097 - lr: 1.0026e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0091 - lr: 9.0718e-05\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 8.2085e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 7.4274e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 6.7206e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 6.0810e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 5.5023e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0072 - lr: 4.9787e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 4.5049e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 4.0762e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0072 - lr: 3.6883e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0071 - lr: 3.3373e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0074 - lr: 3.0197e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 2.7324e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 2.4724e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 2.2371e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0074 - lr: 2.0242e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 1.8316e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0072 - lr: 1.6573e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 1.4996e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0072 - lr: 1.3569e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.2277e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0071 - lr: 1.1109e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.0052e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0072 - lr: 9.0953e-06\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 8.2298e-06\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0072 - lr: 7.4466e-06\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 6.7379e-06\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 6.0967e-06\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 5.5166e-06\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 4.9916e-06\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0072 - lr: 4.5166e-06\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 4.0868e-06\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 3.6979e-06\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 3.3460e-06\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 3.0276e-06\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 2.7394e-06\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 2.4788e-06\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 2.2429e-06\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 2.0294e-06\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.8363e-06\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.6616e-06\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.5034e-06\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.3604e-06\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.2309e-06\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 1.1138e-06\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0048 - val_loss: 0.0072 - lr: 1.0078e-06\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 9.1188e-07\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 8.2511e-07\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 7.4659e-07\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 6.7554e-07\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 6.1125e-07\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 5.5308e-07\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 5.0045e-07\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 4.5283e-07\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 4.0974e-07\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 3.7074e-07\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0071 - lr: 3.3546e-07\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.4292149144935853%\n",
      "Testing performance for epochs : 120\n",
      "Epoch 1/120\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 4.0569 - val_loss: 0.0508 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1154 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0447 - val_loss: 0.1297 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0512 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0726 - val_loss: 0.1356 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0515 - val_loss: 0.0481 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0334 - val_loss: 0.0454 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0256 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0259 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0212 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0402 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0120 - lr: 8.1873e-04\n",
      "Epoch 23/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0109 - lr: 7.4082e-04\n",
      "Epoch 24/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0144 - lr: 6.7032e-04\n",
      "Epoch 25/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0136 - lr: 5.4881e-04\n",
      "Epoch 27/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0091 - lr: 4.9659e-04\n",
      "Epoch 28/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0104 - lr: 4.4933e-04\n",
      "Epoch 29/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0099 - lr: 4.0657e-04\n",
      "Epoch 30/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0118 - val_loss: 0.0106 - lr: 3.6788e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0119 - lr: 3.3287e-04\n",
      "Epoch 32/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0185 - lr: 3.0119e-04\n",
      "Epoch 33/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0107 - lr: 2.7253e-04\n",
      "Epoch 34/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.0099 - lr: 2.4660e-04\n",
      "Epoch 35/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0083 - lr: 2.2313e-04\n",
      "Epoch 36/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.0190e-04\n",
      "Epoch 37/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 1.8268e-04\n",
      "Epoch 38/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0086 - lr: 1.6530e-04\n",
      "Epoch 39/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0082 - lr: 1.4957e-04\n",
      "Epoch 40/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0139 - lr: 1.3534e-04\n",
      "Epoch 41/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0085 - lr: 1.2246e-04\n",
      "Epoch 42/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 1.1080e-04\n",
      "Epoch 43/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0088 - lr: 1.0026e-04\n",
      "Epoch 44/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0082 - lr: 9.0718e-05\n",
      "Epoch 45/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 8.2085e-05\n",
      "Epoch 46/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 7.4274e-05\n",
      "Epoch 47/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 6.7206e-05\n",
      "Epoch 48/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 6.0810e-05\n",
      "Epoch 49/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0085 - lr: 4.9787e-05\n",
      "Epoch 51/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 4.5049e-05\n",
      "Epoch 52/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 4.0762e-05\n",
      "Epoch 53/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 3.6883e-05\n",
      "Epoch 54/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 3.3373e-05\n",
      "Epoch 55/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 3.0197e-05\n",
      "Epoch 56/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.7324e-05\n",
      "Epoch 57/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 2.4724e-05\n",
      "Epoch 58/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 2.2371e-05\n",
      "Epoch 59/120\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 2.0242e-05\n",
      "Epoch 60/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 1.8316e-05\n",
      "Epoch 61/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 1.6573e-05\n",
      "Epoch 62/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 1.4996e-05\n",
      "Epoch 63/120\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 1.3569e-05\n",
      "Epoch 64/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 1.2277e-05\n",
      "Epoch 65/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 1.1109e-05\n",
      "Epoch 66/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 1.0052e-05\n",
      "Epoch 67/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 9.0953e-06\n",
      "Epoch 68/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 8.2298e-06\n",
      "Epoch 69/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 7.4466e-06\n",
      "Epoch 70/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 6.7379e-06\n",
      "Epoch 71/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.0967e-06\n",
      "Epoch 72/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 5.5166e-06\n",
      "Epoch 73/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 4.9916e-06\n",
      "Epoch 74/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 4.5166e-06\n",
      "Epoch 75/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 4.0868e-06\n",
      "Epoch 76/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.6979e-06\n",
      "Epoch 77/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.3460e-06\n",
      "Epoch 78/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.0276e-06\n",
      "Epoch 79/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.7394e-06\n",
      "Epoch 80/120\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.4788e-06\n",
      "Epoch 81/120\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.2429e-06\n",
      "Epoch 82/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.0294e-06\n",
      "Epoch 83/120\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.8363e-06\n",
      "Epoch 84/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.6616e-06\n",
      "Epoch 85/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.5034e-06\n",
      "Epoch 86/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.3604e-06\n",
      "Epoch 87/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.2309e-06\n",
      "Epoch 88/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.1138e-06\n",
      "Epoch 89/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.0078e-06\n",
      "Epoch 90/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 9.1188e-07\n",
      "Epoch 91/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 8.2511e-07\n",
      "Epoch 92/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 7.4659e-07\n",
      "Epoch 93/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.7554e-07\n",
      "Epoch 94/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.1125e-07\n",
      "Epoch 95/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 5.5308e-07\n",
      "Epoch 96/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 5.0045e-07\n",
      "Epoch 97/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 4.5283e-07\n",
      "Epoch 98/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 4.0974e-07\n",
      "Epoch 99/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.7074e-07\n",
      "Epoch 100/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.3546e-07\n",
      "Epoch 101/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 3.0354e-07\n",
      "Epoch 102/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.7465e-07\n",
      "Epoch 103/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.4852e-07\n",
      "Epoch 104/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.2487e-07\n",
      "Epoch 105/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.0347e-07\n",
      "Epoch 106/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.8411e-07\n",
      "Epoch 107/120\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.6659e-07\n",
      "Epoch 108/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.5073e-07\n",
      "Epoch 109/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.3639e-07\n",
      "Epoch 110/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.2341e-07\n",
      "Epoch 111/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.1167e-07\n",
      "Epoch 112/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.0104e-07\n",
      "Epoch 113/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 9.1424e-08\n",
      "Epoch 114/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 8.2724e-08\n",
      "Epoch 115/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 7.4852e-08\n",
      "Epoch 116/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.7729e-08\n",
      "Epoch 117/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.1284e-08\n",
      "Epoch 118/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 5.5452e-08\n",
      "Epoch 119/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 5.0175e-08\n",
      "Epoch 120/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 4.5400e-08\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "The average percentage diff for the test set is: 2.48331527019212%\n",
      "Testing performance for epochs : 140\n",
      "Epoch 1/140\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 7.1471 - val_loss: 0.0373 - lr: 0.0010\n",
      "Epoch 2/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0820 - val_loss: 0.1582 - lr: 0.0010\n",
      "Epoch 3/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0736 - val_loss: 0.1550 - lr: 0.0010\n",
      "Epoch 4/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0348 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 5/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 6/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0604 - lr: 0.0010\n",
      "Epoch 7/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0379 - val_loss: 0.0616 - lr: 0.0010\n",
      "Epoch 8/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0329 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 9/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0441 - lr: 0.0010\n",
      "Epoch 10/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0219 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 11/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 12/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0447 - lr: 0.0010\n",
      "Epoch 13/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0207 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 14/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 15/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0163 - val_loss: 0.0794 - lr: 0.0010\n",
      "Epoch 16/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0518 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 17/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 18/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 19/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 20/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 21/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0088 - lr: 9.0484e-04\n",
      "Epoch 22/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0187 - lr: 8.1873e-04\n",
      "Epoch 23/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0082 - lr: 7.4082e-04\n",
      "Epoch 24/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0128 - lr: 6.7032e-04\n",
      "Epoch 25/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0081 - lr: 6.0653e-04\n",
      "Epoch 26/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0084 - lr: 5.4881e-04\n",
      "Epoch 27/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0096 - lr: 4.9659e-04\n",
      "Epoch 28/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0104 - lr: 4.4933e-04\n",
      "Epoch 29/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 4.0657e-04\n",
      "Epoch 30/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0090 - lr: 3.6788e-04\n",
      "Epoch 31/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0190 - lr: 3.3287e-04\n",
      "Epoch 32/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0154 - lr: 3.0119e-04\n",
      "Epoch 33/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0089 - lr: 2.7253e-04\n",
      "Epoch 34/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0078 - lr: 2.4660e-04\n",
      "Epoch 35/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 2.2313e-04\n",
      "Epoch 36/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 2.0190e-04\n",
      "Epoch 37/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 1.8268e-04\n",
      "Epoch 38/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0099 - lr: 1.6530e-04\n",
      "Epoch 39/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0082 - val_loss: 0.0084 - lr: 1.4957e-04\n",
      "Epoch 40/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0111 - lr: 1.3534e-04\n",
      "Epoch 41/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0100 - lr: 1.2246e-04\n",
      "Epoch 42/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0076 - lr: 1.1080e-04\n",
      "Epoch 43/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0098 - lr: 1.0026e-04\n",
      "Epoch 44/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 8.2085e-05\n",
      "Epoch 46/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0076 - lr: 7.4274e-05\n",
      "Epoch 47/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 6.7206e-05\n",
      "Epoch 48/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 6.0810e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0086 - lr: 5.5023e-05\n",
      "Epoch 50/140\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0081 - lr: 4.9787e-05\n",
      "Epoch 51/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0077 - lr: 4.5049e-05\n",
      "Epoch 52/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 4.0762e-05\n",
      "Epoch 53/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0076 - lr: 3.6883e-05\n",
      "Epoch 54/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0076 - lr: 3.3373e-05\n",
      "Epoch 55/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 3.0197e-05\n",
      "Epoch 56/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 2.7324e-05\n",
      "Epoch 57/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 2.4724e-05\n",
      "Epoch 58/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.0242e-05\n",
      "Epoch 60/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.8316e-05\n",
      "Epoch 61/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.6573e-05\n",
      "Epoch 62/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 1.4996e-05\n",
      "Epoch 63/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.3569e-05\n",
      "Epoch 64/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.0052e-05\n",
      "Epoch 67/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 9.0953e-06\n",
      "Epoch 68/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2298e-06\n",
      "Epoch 69/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.4466e-06\n",
      "Epoch 70/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.7379e-06\n",
      "Epoch 71/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.9916e-06\n",
      "Epoch 74/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "Epoch 81/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.2429e-06\n",
      "Epoch 82/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.0294e-06\n",
      "Epoch 83/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.8363e-06\n",
      "Epoch 84/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.6616e-06\n",
      "Epoch 85/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.5034e-06\n",
      "Epoch 86/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.3604e-06\n",
      "Epoch 87/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2309e-06\n",
      "Epoch 88/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.1138e-06\n",
      "Epoch 89/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.0078e-06\n",
      "Epoch 90/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 9.1188e-07\n",
      "Epoch 91/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2511e-07\n",
      "Epoch 92/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.4659e-07\n",
      "Epoch 93/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.7554e-07\n",
      "Epoch 94/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.1125e-07\n",
      "Epoch 95/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.5308e-07\n",
      "Epoch 96/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.0045e-07\n",
      "Epoch 97/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.5283e-07\n",
      "Epoch 98/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.0974e-07\n",
      "Epoch 99/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.7074e-07\n",
      "Epoch 100/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.3546e-07\n",
      "Epoch 101/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.0354e-07\n",
      "Epoch 102/140\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.7465e-07\n",
      "Epoch 103/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.4852e-07\n",
      "Epoch 104/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.2487e-07\n",
      "Epoch 105/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.0347e-07\n",
      "Epoch 106/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.8411e-07\n",
      "Epoch 107/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.6659e-07\n",
      "Epoch 108/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.5073e-07\n",
      "Epoch 109/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.3639e-07\n",
      "Epoch 110/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2341e-07\n",
      "Epoch 111/140\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.1167e-07\n",
      "Epoch 112/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.0104e-07\n",
      "Epoch 113/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 9.1424e-08\n",
      "Epoch 114/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2724e-08\n",
      "Epoch 115/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.4852e-08\n",
      "Epoch 116/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.7729e-08\n",
      "Epoch 117/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.1284e-08\n",
      "Epoch 118/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.5452e-08\n",
      "Epoch 119/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.0175e-08\n",
      "Epoch 120/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.5400e-08\n",
      "Epoch 121/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.1080e-08\n",
      "Epoch 122/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.7170e-08\n",
      "Epoch 123/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.3633e-08\n",
      "Epoch 124/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.0433e-08\n",
      "Epoch 125/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.7536e-08\n",
      "Epoch 126/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.4916e-08\n",
      "Epoch 127/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.2545e-08\n",
      "Epoch 128/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.0400e-08\n",
      "Epoch 129/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.8458e-08\n",
      "Epoch 130/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.6702e-08\n",
      "Epoch 131/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.5112e-08\n",
      "Epoch 132/140\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.3674e-08\n",
      "Epoch 133/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2373e-08\n",
      "Epoch 134/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.1195e-08\n",
      "Epoch 135/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.0130e-08\n",
      "Epoch 136/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 9.1661e-09\n",
      "Epoch 137/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2938e-09\n",
      "Epoch 138/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.5046e-09\n",
      "Epoch 139/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.7904e-09\n",
      "Epoch 140/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.1442e-09\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The average percentage diff for the test set is: 2.4841209318576807%\n",
      "Testing performance for epochs : 150\n",
      "Epoch 1/150\n",
      "17/17 [==============================] - 2s 30ms/step - loss: 5.3853 - val_loss: 1.0417 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.2303 - val_loss: 0.0431 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0288 - val_loss: 0.0410 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0141 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0104 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0142 - val_loss: 0.0688 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0375 - val_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0172 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0198 - val_loss: 0.0380 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0179 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0103 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0136 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0120 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0163 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0159 - val_loss: 0.0662 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0529 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0155 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0320 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0110 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0084 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0087 - val_loss: 0.0090 - lr: 9.0484e-04\n",
      "Epoch 22/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0113 - lr: 8.1873e-04\n",
      "Epoch 23/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.0099 - lr: 7.4082e-04\n",
      "Epoch 24/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0098 - val_loss: 0.0144 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0084 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0099 - lr: 5.4881e-04\n",
      "Epoch 27/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0097 - lr: 4.9659e-04\n",
      "Epoch 28/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0115 - lr: 4.4933e-04\n",
      "Epoch 29/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0086 - lr: 4.0657e-04\n",
      "Epoch 30/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0112 - lr: 3.6788e-04\n",
      "Epoch 31/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0142 - lr: 3.3287e-04\n",
      "Epoch 32/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0157 - lr: 3.0119e-04\n",
      "Epoch 33/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0105 - lr: 2.7253e-04\n",
      "Epoch 34/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0085 - lr: 2.4660e-04\n",
      "Epoch 35/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/150\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 2.0190e-04\n",
      "Epoch 37/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 1.8268e-04\n",
      "Epoch 38/150\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 1.6530e-04\n",
      "Epoch 39/150\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0078 - val_loss: 0.0080 - lr: 1.4957e-04\n",
      "Epoch 40/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0086 - val_loss: 0.0123 - lr: 1.3534e-04\n",
      "Epoch 41/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0094 - lr: 1.2246e-04\n",
      "Epoch 42/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0079 - lr: 1.1080e-04\n",
      "Epoch 43/150\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.0096 - lr: 1.0026e-04\n",
      "Epoch 44/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 9.0718e-05\n",
      "Epoch 45/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 8.2085e-05\n",
      "Epoch 46/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0059 - val_loss: 0.0079 - lr: 7.4274e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0057 - val_loss: 0.0081 - lr: 6.0810e-05\n",
      "Epoch 49/150\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0056 - val_loss: 0.0087 - lr: 5.5023e-05\n",
      "Epoch 50/150\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 4.9787e-05\n",
      "Epoch 51/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 4.5049e-05\n",
      "Epoch 52/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0056 - val_loss: 0.0081 - lr: 4.0762e-05\n",
      "Epoch 53/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.6883e-05\n",
      "Epoch 54/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.3373e-05\n",
      "Epoch 55/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 3.0197e-05\n",
      "Epoch 56/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 2.7324e-05\n",
      "Epoch 57/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0081 - lr: 2.4724e-05\n",
      "Epoch 58/150\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 2.2371e-05\n",
      "Epoch 59/150\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0082 - lr: 2.0242e-05\n",
      "Epoch 60/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 1.8316e-05\n",
      "Epoch 61/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.6573e-05\n",
      "Epoch 62/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 1.4996e-05\n",
      "Epoch 63/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.3569e-05\n",
      "Epoch 64/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.2277e-05\n",
      "Epoch 65/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.1109e-05\n",
      "Epoch 66/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.0052e-05\n",
      "Epoch 67/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 9.0953e-06\n",
      "Epoch 68/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 8.2298e-06\n",
      "Epoch 69/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 7.4466e-06\n",
      "Epoch 70/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 6.7379e-06\n",
      "Epoch 71/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 6.0967e-06\n",
      "Epoch 72/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 5.5166e-06\n",
      "Epoch 73/150\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.9916e-06\n",
      "Epoch 74/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.5166e-06\n",
      "Epoch 75/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 4.0868e-06\n",
      "Epoch 76/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 3.6979e-06\n",
      "Epoch 77/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 3.3460e-06\n",
      "Epoch 78/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 3.0276e-06\n",
      "Epoch 79/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 2.7394e-06\n",
      "Epoch 80/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.4788e-06\n",
      "Epoch 81/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 2.2429e-06\n",
      "Epoch 82/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.0294e-06\n",
      "Epoch 83/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.8363e-06\n",
      "Epoch 84/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.6616e-06\n",
      "Epoch 85/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.5034e-06\n",
      "Epoch 86/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.3604e-06\n",
      "Epoch 87/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.2309e-06\n",
      "Epoch 88/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.1138e-06\n",
      "Epoch 89/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.0078e-06\n",
      "Epoch 90/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 9.1188e-07\n",
      "Epoch 91/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 8.2511e-07\n",
      "Epoch 92/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 7.4659e-07\n",
      "Epoch 93/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.7554e-07\n",
      "Epoch 94/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.1125e-07\n",
      "Epoch 95/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.5308e-07\n",
      "Epoch 96/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.0045e-07\n",
      "Epoch 97/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.5283e-07\n",
      "Epoch 98/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.0974e-07\n",
      "Epoch 99/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.7074e-07\n",
      "Epoch 100/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.3546e-07\n",
      "Epoch 101/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.0354e-07\n",
      "Epoch 102/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.7465e-07\n",
      "Epoch 103/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.4852e-07\n",
      "Epoch 104/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.2487e-07\n",
      "Epoch 105/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.0347e-07\n",
      "Epoch 106/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.8411e-07\n",
      "Epoch 107/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.6659e-07\n",
      "Epoch 108/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.5073e-07\n",
      "Epoch 109/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.3639e-07\n",
      "Epoch 110/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.2341e-07\n",
      "Epoch 111/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.1167e-07\n",
      "Epoch 112/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.0104e-07\n",
      "Epoch 113/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 9.1424e-08\n",
      "Epoch 114/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 8.2724e-08\n",
      "Epoch 115/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 7.4852e-08\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.7729e-08\n",
      "Epoch 117/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.1284e-08\n",
      "Epoch 118/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.5452e-08\n",
      "Epoch 119/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.0175e-08\n",
      "Epoch 120/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.5400e-08\n",
      "Epoch 121/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.1080e-08\n",
      "Epoch 122/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.7170e-08\n",
      "Epoch 123/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.3633e-08\n",
      "Epoch 124/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.0433e-08\n",
      "Epoch 125/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.7536e-08\n",
      "Epoch 126/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.4916e-08\n",
      "Epoch 127/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.2545e-08\n",
      "Epoch 128/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.0400e-08\n",
      "Epoch 129/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.8458e-08\n",
      "Epoch 130/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.6702e-08\n",
      "Epoch 131/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.5112e-08\n",
      "Epoch 132/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.3674e-08\n",
      "Epoch 133/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.2373e-08\n",
      "Epoch 134/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.1195e-08\n",
      "Epoch 135/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 1.0130e-08\n",
      "Epoch 136/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 9.1661e-09\n",
      "Epoch 137/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 8.2938e-09\n",
      "Epoch 138/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 7.5046e-09\n",
      "Epoch 139/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.7904e-09\n",
      "Epoch 140/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 6.1442e-09\n",
      "Epoch 141/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.5595e-09\n",
      "Epoch 142/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 5.0305e-09\n",
      "Epoch 143/150\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.5518e-09\n",
      "Epoch 144/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 4.1186e-09\n",
      "Epoch 145/150\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.7267e-09\n",
      "Epoch 146/150\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.3720e-09\n",
      "Epoch 147/150\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 3.0511e-09\n",
      "Epoch 148/150\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.7608e-09\n",
      "Epoch 149/150\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.4981e-09\n",
      "Epoch 150/150\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.2603e-09\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The average percentage diff for the test set is: 2.3413012334870733%\n"
     ]
    }
   ],
   "source": [
    "# List of number of epochs to test\n",
    "epochs = [5,10,20,40,60,80,100,120,140,150]\n",
    "\n",
    "# List to store average percentage differences for each number of epochs\n",
    "avg_percentages_diffs_epochs = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(f\"Testing performance for epochs : {epoch}\")\n",
    "    avg_percentages_diffs_epoch = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,epochs=epoch)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_epochs.append(avg_percentages_diffs_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f068762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAHWCAYAAADNbgu+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABudElEQVR4nO3dd1xT1/sH8E8IELaAgoIiIKAobrRuqbtqHVWLs6L2a63Vuq3aat2z1boVrV9trdZaV9fPgbtaB+5Rdx0VUVyAgEIg5/fH/SYSAU0gIST5vF8vXpqTm3ufJyHJw7nnnCsTQggQERER5ZONqQMgIiIi88ZigoiIiAqExQQREREVCIsJIiIiKhAWE0RERFQgLCaIiIioQFhMEBERUYGwmCAiIqICYTFBREREBcJigsiC7d+/HzKZDPv379dqX7t2LUJDQ2FnZwd3d3dN+1dffYVy5cpBLpejevXqhRormb+3334blStXNnUYOsvrfWBu+vTpAxcXF5PGwGLif5YuXQqZTIY6deqYOpQiJyAgADKZTPPj7e2NRo0aYevWraYOzSCWLl2KNWvWmDqMN7p165bW62BnZ4cSJUqgfv36+Pzzz3Hnzh2d9nP58mX06dMHQUFBWLlyJVasWAEA2LVrFz777DM0aNAAq1evxowZM4yZDuWT+v346aef5rhPXTxu2rTJBJGZl7zeB5Q/tqYOoKhYt24dAgICcPz4cVy/fh3BwcGmDqlIqV69OkaOHAkAuHfvHqKjo9GpUycsW7YMH3/8sYmjK5ilS5eiRIkS6NOnj6lD0Un37t3Rpk0bqFQqPH36FLGxsZg/fz4WLFiAVatWoVu3bpptGzdujOfPn8Pe3l7Ttn//fqhUKixYsEDr93zv3r2wsbHBqlWrtLanomnlypUYN24cfH19TR2KWcrrfUD5w54JADdv3sRff/2FefPmwcvLC+vWrSv0GFQqFV68eFHox9VV6dKl0atXL/Tq1QufffYZDh8+DGdnZ3zzzTcF3veLFy+gUqkMEKV1qFmzJnr16oXevXtj6NCh+OGHH3Dp0iWUKVMGUVFROHv2rGZbGxsbODg4wMbm5Vs9ISEBAHJ06yYkJMDR0dGghURaWprB9kUvhYWFISsrC7NmzTJ1KIXOUJ+Veb0PKH9YTEDqlfDw8EDbtm3RpUsXrWJCqVTC09MTffv2zfG45ORkODg4YNSoUZq29PR0TJw4EcHBwVAoFPDz88Nnn32G9PR0rcfKZDIMHjwY69atQ1hYGBQKBXbs2AEA+Prrr1G/fn0UL14cjo6OCA8Pz7Xb8vnz5xgyZAhKlCgBV1dXtG/fHnFxcZDJZJg0aZLWtnFxcejXrx9KliwJhUKBsLAw/Pe//833c1aqVClUrFgRN2/e1OsY6m7YDRs2YPz48ShdujScnJyQnJwMADh27BjatGkDDw8PODs7o2rVqliwYIHWPi5fvowuXbrA09MTDg4OqFWrFn799VetbdasWQOZTIbDhw9jxIgR8PLygrOzM9577z08fPhQs11AQAAuXryIAwcOaE4fvP322wCAJ0+eYNSoUahSpQpcXFzg5uaG1q1ba31Zq92+fRvt27eHs7MzvL29MXz4cOzcuTPX8QrHjh3DO++8g2LFisHJyQkRERE4fPiw3q9Bdv7+/lizZg0yMjIwZ84cTfurYyYCAgIwceJEAICXl5fmd0Umk2H16tVITU3VPA/ZT/388MMPCA8Ph6OjIzw9PdGtWzf8+++/WjGoz5efPHkSjRs3hpOTEz7//HMA+r8vtm3bhsqVK2t+j9Tvjezi4uLw4YcfwtfXFwqFAoGBgRg4cCAyMjI02yQmJmLYsGHw8/ODQqFAcHAwZs+enaN43bBhA8LDw+Hq6go3NzdUqVIlx+9ddvp+LixatAhhYWFwcnKCh4cHatWqhfXr1+e5/zcJCAhA7969sXLlSty7d++12/bp0wcBAQE52tWve3bq5//nn39GpUqV4OjoiHr16uH8+fMAgOjoaAQHB8PBwQFvv/02bt26lesxT548ifr168PR0RGBgYFYvnx5jm0M8VmZl6VLl2q29fX1xaBBg5CYmKi5P6/3wevo87lz8OBBDBgwAMWLF4ebmxt69+6Np0+f6h2nmi6fi4D0nujYsSNcXFzg5eWFUaNGISsrS2sbfX/XdSZIhIaGig8//FAIIcTBgwcFAHH8+HHN/f369RPu7u4iPT1d63HfffedACBiY2OFEEJkZWWJli1bCicnJzFs2DARHR0tBg8eLGxtbUWHDh20HgtAVKxYUXh5eYnJkyeLJUuWiNOnTwshhChTpoz45JNPxOLFi8W8efPEW2+9JQCI33//XWsfkZGRAoD44IMPxJIlS0RkZKSoVq2aACAmTpyo2e7+/fuiTJkyws/PT0yZMkUsW7ZMtG/fXgAQ33zzzRufH39/f9G2bVuttoyMDFGyZElRqlQpvY6xb98+AUBUqlRJVK9eXcybN0/MnDlTpKamil27dgl7e3vh7+8vJk6cKJYtWyaGDBkimjdvrnn8hQsXRLFixUSlSpXE7NmzxeLFi0Xjxo2FTCYTW7Zs0Wy3evVqAUDUqFFDNG3aVCxatEiMHDlSyOVyERkZqdlu69atokyZMiI0NFSsXbtWrF27VuzatUsIIURsbKwICgoSY8eOFdHR0WLKlCmidOnSolixYiIuLk6zj5SUFFGuXDnh6Ogoxo4dK+bPny/eeustzWuxb98+zbZ79uwR9vb2ol69emLu3Lnim2++EVWrVhX29vbi2LFjr30dbt68KQCIr776Ks9tgoKChJeXV47nWx3D1q1bxXvvvScAiGXLlom1a9eKs2fPirVr14pGjRoJhUKheR5u3LghhBBi2rRpQiaTia5du4qlS5eKyZMnixIlSoiAgADx9OlTzbEiIiJEqVKlhJeXl/j0009FdHS02LZtm97vi2rVqgkfHx8xdepUMX/+fFGuXDnh5OQkHj16pNkuLi5O+Pr6ava5fPlyMWHCBFGxYkVNTKmpqaJq1aqiePHi4vPPPxfLly8XvXv3FjKZTAwdOlSzr127dgkAolmzZmLJkiViyZIlYvDgweL9999/7euh6+fCihUrBADRpUsXER0dLRYsWCA+/PBDMWTIkNfuPy/q9+ONGzeEra2t+PTTTzX3qV/vn3/+WdMWFRUl/P39c+xn4sSJ4tWvAACiatWqws/PT8yaNUvMmjVLFCtWTJQtW1YsXrxYVKpUScydO1eMHz9e2NvbiyZNmmg9PiIiQvj6+gpvb28xePBgsXDhQtGwYUMBQKxatUqznaE+K3Ojzqt58+Zi0aJFYvDgwUIul4vatWuLjIwMIUTe74O86Pu5U6VKFdGoUSOxcOFCMWjQIGFjYyMaN24sVCqVXnEKIXT6XIyKihIODg4iLCxM9OvXTyxbtkx07txZABBLly7V2ld+ftd1YfXFxIkTJwQAERMTI4QQQqVSiTJlymh92OzcuVMAEL/99pvWY9u0aSPKlSunub127VphY2Mj/vzzT63tli9fLgCIw4cPa9oACBsbG3Hx4sUcMaWlpWndzsjIEJUrVxZNmzbVtJ08eVIAEMOGDdPatk+fPjmKiQ8//FD4+PhofRgLIUS3bt1EsWLFchzvVf7+/qJly5bi4cOH4uHDh+Ls2bOiW7duAoDmg0zXY6g/7MqVK6d13MzMTBEYGCj8/f21vqCEEFpvwGbNmokqVaqIFy9eaN1fv359ERISomlTv6mbN2+u9fjhw4cLuVwuEhMTNW1hYWEiIiIiR94vXrwQWVlZWm03b94UCoVCTJkyRdM2d+5cAUBs27ZN0/b8+XMRGhqq9UWuUqlESEiIaNWqlVZMaWlpIjAwULRo0SJHDK8e+03FRIcOHQQAkZSUJITIWUwI8fJD7OHDh1qPjYqKEs7Ozlptt27dEnK5XEyfPl2r/fz588LW1larPSIiQgAQy5cv19pW3/eFvb29uH79uqbt7NmzAoBYtGiRpq13797CxsZG84Wdnfq5nTp1qnB2dhZXr17Vun/s2LFCLpeLO3fuCCGEGDp0qHBzcxOZmZk59vU6un4udOjQQYSFhem179fJXtz37dtXODg4iHv37gkhDFNMKBQKcfPmTU1bdHS0ACBKlSolkpOTNe3jxo0TALS2Vf8OzJ07V9OWnp4uqlevLry9vTVfkob6rHxVQkKCsLe3Fy1bttR67y5evFgAEP/9739z5P/q+yA3+n7uhIeHaxUEc+bMEQDEL7/8olecun4uRkVFCQBan0tCCFGjRg0RHh6uuZ3f33VdWP1pjnXr1qFkyZJo0qQJAKlLrWvXrtiwYYOme6hp06YoUaIEfvrpJ83jnj59ipiYGHTt2lXT9vPPP6NixYoIDQ3Fo0ePND9NmzYFAOzbt0/r2BEREahUqVKOmBwdHbWOk5SUhEaNGuHUqVOadnU33yeffKL12FdHeAshsHnzZrRr1w5CCK24WrVqhaSkJK395mXXrl3w8vKCl5cXqlWrhp9//hkffPABZs+ena9jREVFaeV5+vRp3Lx5E8OGDctxDlPdFfvkyRPs3bsXkZGRePbsmeYYjx8/RqtWrXDt2jXExcVpPfajjz7S6spt1KgRsrKycPv27TfmrFAoNGMNsrKy8PjxY7i4uKBChQo5XovSpUujffv2mjYHBwf0799fa39nzpzBtWvX0KNHDzx+/FgTf2pqKpo1a4aDBw8WeOyIenrYs2fPCrQftS1btkClUiEyMlLrdS1VqhRCQkJy/E4rFIocXf/6vi+aN2+OoKAgze2qVavCzc0N//zzDwDpnPm2bdvQrl071KpVK0fM6tf7559/RqNGjeDh4aF13ObNmyMrKwsHDx4EIJ0zT01NRUxMjF7Pja6fC+7u7rh79y5iY2P12r8uxo8fj8zMTIOOnWjWrJnWaRH1DLfOnTvD1dU1R7v6dVGztbXFgAEDNLft7e0xYMAAJCQk4OTJkwAM91n5qt27dyMjIwPDhg3TGifUv39/uLm54Y8//tDlKdCS388dOzs7ze2BAwfC1tYW//d//6dXnLp8Lmb36mD4Ro0aab0++f1d14VVz+bIysrChg0b0KRJE61z/3Xq1MHcuXOxZ88etGzZEra2tujcuTPWr1+P9PR0KBQKbNmyBUqlUutD49q1a7h06RK8vLxyPZ56wI9aYGBgrtv9/vvvmDZtGs6cOaN1/jD7L8/t27dhY2OTYx+vjkp++PAhEhMTsWLFijynPr0aV27q1KmDadOmQSaTwcnJCRUrVtT8cickJOh9jFfjvnHjBgC8do769evXIYTAhAkTMGHChDyPU7p0ac3tsmXLat3v4eEBALmev3yVeqT30qVLcfPmTa1zj8WLF9f8//bt2wgKCsrx5n71tbh27RoAqZDKS1JSkibG/EhJSQEArQ/9grh27RqEEAgJCcn1/uwfmIA0UPfVAZz6vi9efc0A6XVTv2YPHz5EcnLyG9czuHbtGs6dO/fG437yySfYuHEjWrdujdKlS6Nly5aIjIzEO++889r96/q5MGbMGOzevRtvvfUWgoOD0bJlS/To0QMNGjR47f51Ua5cOXzwwQdYsWIFxo4dW+D9ATmf/2LFigEA/Pz8cm1/9b3k6+sLZ2dnrbby5csDkKY3161b12Cfla9S/5FQoUIFrXZ7e3uUK1dOpz8iXpWfz51X3y8uLi7w8fHRjDHRNU5dPhfVHBwccjyf2d83QP5/13Vh1cXE3r17ER8fjw0bNmDDhg057l+3bh1atmwJAOjWrRuio6Oxfft2dOzYERs3bkRoaCiqVaum2V6lUqFKlSqYN29ersd79c2Y/S9ztT///BPt27dH48aNsXTpUvj4+MDOzg6rV6/O14At9V+6vXr1yvNLrGrVqm/cT4kSJdC8eXODHSO33N9EfZxRo0ahVatWuW7z6he4XC7PdTshxBuPN2PGDEyYMAH9+vXD1KlT4enpCRsbGwwbNixfPQjqx3z11Vd5LghV0IVnLly4AG9vb7i5uRVoP2oqlQoymQzbt2/P9bl8Nd7cXld93xcFec1ePW6LFi3w2Wef5Xq/+gvO29sbZ86cwc6dO7F9+3Zs374dq1evRu/evfHdd9+99hi6fC5UrFgRV65cwe+//44dO3Zg8+bNWLp0Kb788ktMnjxZr5xy88UXX2Dt2rWYPXs2OnbsmOP+3P6CBZBjYJ5aXs+/oV4XwDCflYUlP587ppDX65NdQX7X38Sqi4l169bB29sbS5YsyXHfli1bsHXrVixfvhyOjo5o3LgxfHx88NNPP6Fhw4bYu3cvvvjiC63HBAUF4ezZs2jWrFmeb+A32bx5MxwcHLBz504oFApN++rVq7W28/f3h0qlws2bN7Wq4OvXr2tt5+XlBVdXV2RlZeVZDBSUIY6h7ta+cOFCnvsoV64cAOmvYUPmktdrtWnTJjRp0gSrVq3Sak9MTESJEiU0t/39/fH3339DCKG1r1dfC3WObm5uRnktjhw5ghs3bqBXr14G22dQUBCEEAgMDNR8+eZnHwV9X2Tn5eUFNzc3XLhw4Y3HTUlJ0em5tre3R7t27dCuXTuoVCp88skniI6OxoQJE177RaHL5wIAODs7o2vXrujatSsyMjLQqVMnTJ8+HePGjYODg8Obk35Dnr169UJ0dHSui+55eHjkOkMgP3+l6+LevXtITU3V6p24evUqAGhOnxj6d0LN398fAHDlyhXN5wUAZGRk4ObNm/l63+Xnc+fatWuaU+eA1GMYHx+PNm3a6BWnLp+L+srv7/qbWO2YiefPn2PLli1499130aVLlxw/gwcPxrNnzzRTf2xsbNClSxf89ttvWLt2LTIzM7W6MgEgMjIScXFxWLlyZa7HS01NfWNccrkcMplM66+GW7duYdu2bVrbqSvkpUuXarUvWrQox/46d+6MzZs35/rhm32aZH4Z4hg1a9ZEYGAg5s+fn+ODT/2Xj7e3N95++21ER0cjPj4+X8fJjbOzc64ftnK5PMdfXT///HOO86OtWrVCXFyc1jSxFy9e5Pg9CA8PR1BQEL7++mvN6QhDxA9IXwx9+vSBvb09Ro8ene/9vKpTp06Qy+WYPHlyjudCCIHHjx+/cR+GeF9kZ2Njg44dO+K3337DiRMnctyvjjMyMhJHjhzBzp07c2yTmJiIzMxMAMiRg42NjaYn7dVpirnF8qbPhVf3b29vj0qVKkEIAaVSCUBaj+Py5ct49OjRa4+Xl/Hjx0OpVGpNC1YLCgpCUlISzp07p2mLj4832gq2mZmZiI6O1tzOyMhAdHQ0vLy8EB4eDsDwvxNqzZs3h729PRYuXKj1+7pq1SokJSWhbdu2eu8zP587K1as0Ly2ALBs2TJkZmaidevWesWpy+eiPgryu/4mVtsz8euvv+LZs2dag+ayq1u3rmYBK/WHQ9euXbFo0SJMnDgRVapUQcWKFbUe88EHH2Djxo34+OOPsW/fPjRo0ABZWVm4fPkyNm7ciJ07d+Y6YCy7tm3bYt68eXjnnXfQo0cPJCQkYMmSJQgODtb6MAgPD0fnzp0xf/58PH78GHXr1sWBAwc0fwFkr/ZnzZqFffv2oU6dOujfvz8qVaqEJ0+e4NSpU9i9ezeePHmSr+cwu4Iew8bGBsuWLUO7du1QvXp19O3bFz4+Prh8+TIuXryo+UJYsmQJGjZsiCpVqqB///4oV64cHjx4gCNHjuDu3bu5rgHxJuHh4Vi2bBmmTZuG4OBgeHt7o2nTpnj33XcxZcoU9O3bF/Xr18f58+exbt06rb8kAGDAgAFYvHgxunfvjqFDh8LHxwfr1q3T/MWpfi1sbGzw7bffonXr1ggLC0Pfvn1RunRpxMXFYd++fXBzc8Nvv/32xnhPnTqFH374ASqVComJiYiNjcXmzZshk8mwdu1anU5b6SooKAjTpk3DuHHjcOvWLXTs2BGurq64efMmtm7dio8++khrPYXcGOJ98aoZM2Zg165diIiIwEcffYSKFSsiPj4eP//8Mw4dOgR3d3eMHj0av/76K95991306dMH4eHhSE1Nxfnz57Fp0ybcunULJUqUwH/+8x88efIETZs2RZkyZXD79m0sWrQI1atXz/Eez82bPhdatmyJUqVKoUGDBihZsiQuXbqExYsXo23btpqxLcePH0eTJk0wceLEN653kBt170RuXdXdunXDmDFj8N5772HIkCFIS0vDsmXLUL58eZ0GX+vL19cXs2fPxq1bt1C+fHn89NNPOHPmDFasWKEZY2OM3wlA6rUaN24cJk+ejHfeeQft27fHlStXsHTpUtSuXTvfvXb6fu5kZGSgWbNmiIyM1By/YcOGmu8bXePU9XNRVwX9XX8tg88PMRPt2rUTDg4OIjU1Nc9t+vTpI+zs7DTTHVUqlfDz8xMAxLRp03J9TEZGhpg9e7YICwsTCoVCeHh4iPDwcDF58mTNdD0hpOlOgwYNynUfq1atEiEhIUKhUIjQ0FCxevXqXKdxpaamikGDBglPT0/h4uIiOnbsKK5cuSIAiFmzZmlt++DBAzFo0CDh5+cn7OzsRKlSpUSzZs3EihUr3vhc5bbORG50OUZuU9eyO3TokGjRooVwdXUVzs7OomrVqlpTAoUQ4saNG6J3796iVKlSws7OTpQuXVq8++67YtOmTZpt1FO0Xp06mNtUyfv374u2bdsKV1dXAUAzTfTFixdi5MiRwsfHRzg6OooGDRqII0eOiIiIiBxTSf/55x/Rtm1b4ejoKLy8vMTIkSPF5s2bBQBx9OhRrW1Pnz4tOnXqJIoXLy4UCoXw9/cXkZGRYs+ePa99ftVTQ9U/tra2wtPTU9SpU0eMGzdO3L59O8djCjo1VG3z5s2iYcOGwtnZWTg7O4vQ0FAxaNAgceXKFc02EREReU6BLOj7wt/fX0RFRWm13b59W/Tu3Vt4eXkJhUIhypUrJwYNGqS17sOzZ8/EuHHjRHBwsLC3txclSpQQ9evXF19//bVm6t6mTZtEy5Ythbe3t7C3txdly5YVAwYMEPHx8bnm8qo3fS5ER0eLxo0ba17voKAgMXr0aK281a9T9indecnr/Xjt2jUhl8tzfX/t2rVLVK5cWdjb24sKFSqIH374Ic+poa8+/3lNSc7tvaz+HThx4oSoV6+ecHBwEP7+/mLx4sU54jXEZ2VeFi9eLEJDQ4WdnZ0oWbKkGDhwYI6plfpMDRVCv8+dAwcOiI8++kh4eHgIFxcX0bNnT/H48eN8xSnEmz8X83rvvvoaF/R3/XVkQuSjr4SKrDNnzqBGjRr44Ycf0LNnT1OHY9Xmz5+P4cOH4+7du1ojvYnIMq1ZswZ9+/ZFbGxsvnpWzJnVjpmwBM+fP8/RNn/+fNjY2KBx48YmiMh6vfpavHjxAtHR0QgJCWEhQUQWz2rHTFiCOXPm4OTJk2jSpAlsbW01U30++uijHFOryLg6deqEsmXLonr16khKSsIPP/yAy5cvm+SicUREhY3FhBmrX78+YmJiMHXqVKSkpKBs2bKYNGlSrlPTyLhatWqFb7/9FuvWrUNWVhYqVaqEDRs25BjZT0RkiThmgoiIiAqEYyaIiIioQFhMEBERUYFY/JgJlUqFe/fuwdXV1aDLthIREVk6IQSePXsGX19frSucvsrii4l79+5xZgMREVEB/PvvvyhTpkye91t8MaFervbff//VupKiUqnErl270LJlyxyXUbY01pIr87Q81pIr87Q8lpJrcnIy/Pz8NN+lebH4YkJ9asPNzS1HMeHk5AQ3NzezfqF1YS25Mk/LYy25Mk/LY2m5vmmYAAdgEhERUYGwmCAiIqICYTFBREREBcJigoiIiAqExQQREREVCIsJIiIiKhCTFhMHDx5Eu3bt4OvrC5lMhm3btmndL4TAl19+CR8fHzg6OqJ58+a4du2aaYIlIiKiXJm0mEhNTUW1atWwZMmSXO+fM2cOFi5ciOXLl+PYsWNwdnZGq1at8OLFi0KOlIiIiPJi0kWrWrdujdatW+d6nxAC8+fPx/jx49GhQwcAwPfff4+SJUti27Zt6NatW66PS09PR3p6uuZ2cnIyAGkBEaVSqWlX/z97m6WyllyZp+WxllyZp+WxlFx1jV8mhBBGjkUnMpkMW7duRceOHQEA//zzD4KCgnD69GlUr15ds11ERASqV6+OBQsW5LqfSZMmYfLkyTna169fDycnpwLHmZUF/P13cTx96gAPjxeoVOkx5PIC75aIiKjISUtLQ48ePZCUlKS1ivSriuxy2vfv3wcAlCxZUqu9ZMmSmvtyM27cOIwYMUJzW72ueMuWLXMspx0TE4MWLVrovNTp1q0yjBghR1zcy2VFS5cWmDcvC++9VyRqslzlJ1dzxDwtj7Xkyjwtj6Xkqu7df5MiW0zkl0KhgEKhyNFuZ2eX6wuaV/urtmwBunUDXu3HuXdPhm7dbLFpE9CpU77DLhS65mrumKflsZZcmaflMfdcdY29yE4NLVWqFADgwYMHWu0PHjzQ3FdYsrKAoUNzFhLAy7Zhw6TtiIiIrE2RLSYCAwNRqlQp7NmzR9OWnJyMY8eOoV69eoUay59/Anfv5n2/EMC//0rbERERWRuTnuZISUnB9evXNbdv3ryJM2fOwNPTE2XLlsWwYcMwbdo0hISEIDAwEBMmTICvr69mkGZhiY837HZERESWxKTFxIkTJ9CkSRPNbfXAyaioKKxZswafffYZUlNT8dFHHyExMRENGzbEjh074ODgUKhx+vgYdjsiIiJLYtJi4u2338brZqbKZDJMmTIFU6ZMKcSocmrUCChTBoiLy33chEwm3d+oUeHHRkREZGpFdsxEUSKXA+plLWQy7fvUt+fPB9ebICIiq8RiQkedOgGbNgGlS2u3lykDs5gWSkREZCwsJvTQqRNw6xZQubJ0e9Ik4OZNFhJERGTdWEzoSS6XeiMAICCApzaIiIhYTOSDs7P0b0qKaeMgIiIqClhM5IOLi/QviwkiIiIWE/miLiZSU00bBxERUVHAYiIf2DNBRET0EouJfGAxQURE9BKLiXxgMUFERPQSi4l8YDFBRET0EouJfODUUCIiopdYTOQDeyaIiIheYjGRD5waSkRE9BKLiXxgzwQREdFLLCbygcUEERHRSywm8oHFBBER0UssJvJBPZsjI0P6ISIismYsJvJB3TMBcBAmERERi4l8sLcH7Oyk/7OYICIia8diIp84boKIiEjCYiKfWEwQERFJWEzkE4sJIiIiCYuJfGIxQUREJGExkU+82BcREZGExUQ+sWeCiIhIwmIin3ixLyIiIgmLiXxizwQREZGExUQ+sZggIiKSsJjIJxYTREREEhYT+cRigoiISMJiIp84NZSIiEjCYiKf2DNBREQkYTGRT5waSkREJGExkU/smSAiIpIU+WLi2bNnGDZsGPz9/eHo6Ij69esjNjbW1GGxmCAiIvqfIl9M/Oc//0FMTAzWrl2L8+fPo2XLlmjevDni4uJMGheLCSIiIkmRLiaeP3+OzZs3Y86cOWjcuDGCg4MxadIkBAcHY9myZSaNjbM5iIiIJLamDuB1MjMzkZWVBQcHB612R0dHHDp0KNfHpKenIz09XXM7OTkZAKBUKqFUKjXt6v9nb9OHQgEAdkhJEcjIyIRMlq/dFIqC5moumKflsZZcmaflsZRcdY1fJoQQRo6lQOrXrw97e3usX78eJUuWxI8//oioqCgEBwfjypUrObafNGkSJk+enKN9/fr1cHJyMlhcz5/bonv3tgCAn376DQqFymD7JiIiKgrS0tLQo0cPJCUlwc3NLc/tinwxcePGDfTr1w8HDx6EXC5HzZo1Ub58eZw8eRKXLl3KsX1uPRN+fn549OiR1hOhVCoRExODFi1awM7OTu+4srIAR0fpcXFxSnh55SO5QlLQXM0F87Q81pIr87Q8lpJrcnIySpQo8cZiokif5gCAoKAgHDhwAKmpqUhOToaPjw+6du2KcuXK5bq9QqGAQjoHocXOzi7XFzSv9jexswOcnIC0NCA93Q7m8LuS31zNDfO0PNaSK/O0POaeq66xF+kBmNk5OzvDx8cHT58+xc6dO9GhQwdTh8QZHURERDCDnomdO3dCCIEKFSrg+vXrGD16NEJDQ9G3b19ThwYXFyAhgcUEERFZtyLfM5GUlIRBgwYhNDQUvXv3RsOGDbFz584i0W3E6aFERERm0DMRGRmJyMhIU4eRK57mICIiMoOeiaKMF/siIiJiMVEg7JkgIiJiMVEgLCaIiIhYTBQIiwkiIiIWEwXCYoKIiIjFRIFwaigRERGLiQJhzwQRERGLiQLh1FAiIiIWEwXCngkiIiIWEwXCYoKIiIjFRIGwmCAiImIxUSCczUFERMRiokDYM0FERMRiokA4m4OIiIjFRIGoi4nnz4GsLNPGQkREZCosJgpAXUwA7J0gIiLrxWKiABQKQC6X/s9xE0REZK1YTBSATMZBmERERCwmCojTQ4mIyNqxmCgg9kwQEZG1y1cxkZiYiG+//Rbjxo3DkydPAACnTp1CXFycQYMzB5weSkRE1s5W3wecO3cOzZs3R7FixXDr1i30798fnp6e2LJlC+7cuYPvv//eGHEWWeyZICIia6d3z8SIESPQp08fXLt2DQ4ODpr2Nm3a4ODBgwYNzhywmCAiImundzERGxuLAQMG5GgvXbo07t+/b5CgzAmLCSIisnZ6FxMKhQLJyck52q9evQovLy+DBGVOWEwQEZG107uYaN++PaZMmQKlUgkAkMlkuHPnDsaMGYPOnTsbPMCijlNDiYjI2uldTMydOxcpKSnw9vbG8+fPERERgeDgYLi6umL69OnGiLFI42wOIiKydnrP5ihWrBhiYmJw+PBhnD17FikpKahZsyaaN29ujPiKPJ7mICIia6d3MaHWoEEDNGjQwJCxmCUWE0REZO30Ps0xZMgQLFy4MEf74sWLMWzYMEPEZFZYTBARkbXTu5jYvHlzrj0S9evXx6ZNmwwSlDlhMUFERNZO72Li8ePHKFasWI52Nzc3PHr0yCBBmRPO5iAiImundzERHByMHTt25Gjfvn07ypUrZ5CgzAl7JoiIyNrpPQBzxIgRGDx4MB4+fIimTZsCAPbs2YO5c+di/vz5ho6vyOPUUCIisnZ6FxP9+vVDeno6pk+fjqlTpwIAAgICsGzZMvTu3dvgARZ17JkgIiJrl69LkA8cOBB3797FgwcPkJycjH/++ccohURWVhYmTJiAwMBAODo6IigoCFOnToUQwuDHyq/sxUQRCouIiKjQ5HudCQBGvxbH7NmzsWzZMnz33XcICwvDiRMn0LdvXxQrVgxDhgwx6rF1pS4mMjOBjAxAoTBtPERERIVN756JBw8e4IMPPoCvry9sbW0hl8u1fgzpr7/+QocOHdC2bVsEBASgS5cuaNmyJY4fP27Q4xSEejYHwFMdRERknfTumejTpw/u3LmDCRMmwMfHBzKZzBhxAZDWrlixYgWuXr2K8uXL4+zZszh06BDmzZuX52PS09ORnp6uua2+wqlSqdRcnEx9O/u/BaFQ2CI9XYanT5Vwcyvw7gzOkLkWZczT8lhLrszT8lhKrrrGLxN6DkBwdXXFn3/+ierVq+cnLr2oVCp8/vnnmDNnDuRyObKysjB9+nSMGzcuz8dMmjQJkydPztG+fv16ODk5GSXODz54B8+eKbBw4V6ULfvMKMcgIiIqbGlpaejRoweSkpLg9pq/lvXumfDz8yu0AZAbN27EunXrsH79eoSFheHMmTMYNmwYfH19ERUVletjxo0bhxEjRmhuJycnw8/PDy1bttR6IpRKJWJiYtCiRQvY2dkVKE5PT1s8ewaEhzdG7dpFbxSmIXMtypin5bGWXJmn5bGUXNW9+2+idzExf/58jB07FtHR0QgICND34XoZPXo0xo4di27dugEAqlSpgtu3b2PmzJl5FhMKhQKKXEZB2tnZ5fqC5tWuD/UgzBcvbFGUf2cMkas5YJ6Wx1pyZZ6Wx9xz1TV2vYuJrl27Ii0tDUFBQXBycspxoCdPnui7yzylpaXBxkZ7jKhcLodKpTLYMQyBa00QEZE1y1fPRGFp164dpk+fjrJlyyIsLAynT5/GvHnz0K9fv0KLQRcsJoiIyJrpXUzkdXrBGBYtWoQJEybgk08+QUJCAnx9fTFgwAB8+eWXhRaDLlhMEBGRNcvXolU3btzA6tWrcePGDSxYsADe3t7Yvn27pgfBUFxdXTF//vwif80PXjmUiIismd6LVh04cABVqlTBsWPHsGXLFqT87xv07NmzmDhxosEDNAe82BcREVkzvYuJsWPHYtq0aYiJiYG9vb2mvWnTpjh69KhBgzMXPM1BRETWTO9i4vz583jvvfdytHt7e+PRo0cGCcrcsJggIiJrpncx4e7ujvj4+Bztp0+fRunSpQ0SlLlhMUFERNZM72KiW7duGDNmDO7fvw+ZTAaVSoXDhw9j1KhRRrkMuTlgMUFERNZM72JixowZCA0NhZ+fH1JSUlCpUiU0btwY9evXx/jx440RY5HH2RxERGTN9JoaKoTA/fv3sXDhQnz55Zc4f/48UlJSUKNGDYSEhBgrxiKPPRNERGTN9C4mgoODcfHiRYSEhMDPz89YcZkVTg0lIiJrptdpDhsbG4SEhODx48fGiscssWeCiIismd5jJmbNmoXRo0fjwoULxojHLLGYICIia6b3ctq9e/dGWloaqlWrBnt7ezg6Omrdb8irhpoLFhNERGTNivRVQ81F9jETKhVgo3d/DxERkfkq0lcNNRfqqaEAkJb2srggIiKyBvn6G/rGjRsYP348unfvjoSEBADA9u3bcfHiRYMGZy4cHQGZTPo/T3UQEZG14VVDDcDG5mXvBKeHEhGRteFVQw2EgzCJiMha8aqhBsJigoiIrBWvGmogLCaIiMha8aqhBsJigoiIrBWvGmogvHIoERFZK53WmUhOToabmxsAwN7eHitXruRVQ1/Bi30REZG10qmY8PDwQHx8PLy9vdG0aVNs2bIFfn5+vGpoNjzNQURE1kqn0xwuLi6aK4Xu378fSqXSqEGZIxYTRERkrXTqmWjevDmaNGmCihUrAgDee+89rTUmstu7d6/hojMjLCaIiMha6VRM/PDDD/juu+9w48YNHDhwAGFhYXBycjJ2bGaFxQQREVkrnYoJpVKJjz/+GABw4sQJzJ49G+7u7saMy+xwNgcREVkrncZMeHh4aC7oJVNf0Yq0sGeCiIisld4DMA8cOMABmLng1FAiIrJWeg/AFEJwAGYu2DNBRETWigMwDYTFBBERWSudiglHR0cOwHwDFhNERGStdComstu3b58x4jB7LCaIiMha6VRMjBgxAlOnToWzszNGjBjx2m3nzZtnkMDMDaeGEhGRtdKpmDh9+rRmBsfp06fz3M6ap42qeyYyMgClErCzM208REREhUWnYiL7qQ2e5sidupgApOmhHFJCRETWQqd1Jl4lhMCjR480a08QYG//sjeCpzqIiMia6FVM3L9/H71794aHhwdKliwJb29veHh4oF+/fnjw4IFRAgwICIBMJsvxM2jQIKMcryA4CJOIiKyRzrM5kpOTUb9+faSkpKBv374IDQ2FEAJ///03fvzxRxw6dAinTp2CS/b+fgOIjY1FVlaW5vaFCxfQokULvP/++wY9jiG4uABPn7KYICIi66JzMbFgwQLI5XJcvHgRXl5eWveNHz8eDRo0wMKFC/H5558bNMBXjzVr1iwEBQUhIiIi1+3T09ORnp6uuZ2cnAxAulhZ9mXA1f835NLgTk62AGRITMyEUikMtt+CMkauRRHztDzWkivztDyWkquu8cuEEDp969WtWxcDBgxA3759c73/v//9L1auXIkjR47oHqWeMjIy4OvrixEjRuRZtEyaNAmTJ0/O0b5+/Xqjr9o5alRjXL/ugS++OIratY1z2oeIiKiwpKWloUePHkhKSoKbm1ue2+lcTHh6euLIkSOoUKFCrvdfvnwZ9evXx5MnT/IXsQ42btyIHj164M6dO/D19c11m9x6Jvz8/PDo0SOtJ0KpVCImJgYtWrSAnYHmcbZoIceBAzb44YdMREYWrZ4JQ+daFDFPy2MtuTJPy2MpuSYnJ6NEiRJvLCb0GjPxuiW03d3dNacUjGXVqlVo3bp1noUEACgUCigUihztdnZ2ub6gebXnh6ur9O+LF7ZFcp0JQ+ZalDFPy2MtuTJPy2Puueoau87FhBACNjZ5T/6QyWTQsZMjX27fvo3du3djy5YtRjtGQXE2BxERWSO9iony5cvnucqlMQsJAFi9ejW8vb3Rtm1box6nIFhMEBGRNdK5mFi9erUx43gtlUqF1atXIyoqCra2el+brNCwmCAiImuk8zdzVFSUMeN4rd27d+POnTvo16+fyWLQBS/2RURE1qjo/pmfTcuWLY1+GsUQ2DNBRETWKF/X5qDcqYuJ1FTTxkFERFSYWEwYEHsmiIjIGrGYMCAWE0REZI3yXUxkZGTgypUryMzMNGQ8Zo3FBBERWSO9i4m0tDR8+OGHcHJyQlhYGO7cuQMA+PTTTzFr1iyDB2hOWEwQEZE10ruYGDduHM6ePYv9+/fDwcFB0968eXP89NNPBg3O3HBqKBERWSO9p4Zu27YNP/30E+rWrau1GmZYWBhu3Lhh0ODMDXsmiIjIGundM/Hw4UN4e3vnaE9NTc1zqW1rkX1qqBksi0FERGQQehcTtWrVwh9//KG5rS4gvv32W9SrV89wkZkhdTGhUgEvXpg2FiIiosKi92mOGTNmoHXr1vj777+RmZmJBQsW4O+//8Zff/2FAwcOGCNGs+Hk9PL/KSmAo6PpYiEiIiosevdMNGzYEGfOnEFmZiaqVKmCXbt2wdvbG0eOHEF4eLgxYjQbcvnLgoLjJoiIyFrk69ocQUFBWLlypaFjsQjOzkBaGosJIiKyHnoXE8nJybm2y2QyKBQK2NvbFzgoc+biAjx8yGKCiIish97FhLu7+2tnbZQpUwZ9+vTBxIkTYWNjfat182JfRERkbfQuJtasWYMvvvgCffr0wVtvvQUAOH78OL777juMHz8eDx8+xNdffw2FQoHPP//c4AEXdVxrgoiIrI3excR3332HuXPnIjIyUtPWrl07VKlSBdHR0dizZw/Kli2L6dOns5ggIiKyAnqfh/jrr79Qo0aNHO01atTAkSNHAEgzPtTX7LA2LCaIiMja6F1M+Pn5YdWqVTnaV61aBT8/PwDA48eP4eHhUfDozBCLCSIisjZ6n+b4+uuv8f7772P79u2oXbs2AODEiRO4fPkyNm3aBACIjY1F165dDRupmeDFvoiIyNroXUy0b98eV65cQXR0NK5cuQIAaN26NbZt24aAgAAAwMCBAw0apDlhzwQREVmbfC1aFRAQgJkzZxo6FovAqaFERGRt8lVMAEBaWhru3LmDjIwMrfaqVasWOChzxp4JIiKyNnoXEw8fPkTfvn2xffv2XO/PysoqcFDmjMUEERFZG71ncwwbNgyJiYk4duwYHB0dsWPHDnz33XcICQnBr7/+aowYzQqLCSIisjZ690zs3bsXv/zyC2rVqgUbGxv4+/ujRYsWcHNzw8yZM9G2bVtjxGk2WEwQEZG10btnIjU1Fd7e3gAADw8PPHz4EABQpUoVnDp1yrDRmSFODSUiImujdzFRoUIFzZTQatWqITo6GnFxcVi+fDl8fHwMHqC5Yc8EERFZG71PcwwdOhTx8fEAgIkTJ+Kdd97BunXrYG9vjzVr1hg6PrPDqaFERGRt9C4mevXqpfl/eHg4bt++jcuXL6Ns2bIoUaKEQYMzR+yZICIia6P3aY4pU6YgLS1Nc9vJyQk1a9aEs7MzpkyZYtDgzJG6mHj+HLDyWbJERGQl9C4mJk+ejJRc/uxOS0vD5MmTDRKUOVMXEwBPdRARkXXQu5gQQkAmk+VoP3v2LDw9PQ0SlDlTKACb/z2rPNVBRETWQOcxEx4eHpDJZJDJZChfvrxWQZGVlYWUlBR8/PHHRgnSnMhkUu9EcjKLCSIisg46FxPz58+HEAL9+vXD5MmTUaxYMc199vb2CAgIQL169YwSpLlRFxM8zUFERNZA52IiKioKABAYGIj69evDzs7OaEGZO87oICIia6L31NCIiAioVCpcvXoVCQkJUKlUWvc3btzYYMEBQFxcHMaMGYPt27cjLS0NwcHBWL16NWrVqmXQ4xgSiwkiIrImehcTR48eRY8ePXD79m0IIbTuk8lkBr1q6NOnT9GgQQM0adIE27dvh5eXF65duwYPDw+DHcMYWEwQEZE10buY+Pjjj1GrVi388ccf8PHxyXVmh6HMnj0bfn5+WL16taYtMDDQaMczFBYTRERkTfQuJq5du4ZNmzYhODjYGPFo+fXXX9GqVSu8//77OHDgAEqXLo1PPvkE/fv3z/Mx6enpSE9P19xOTk4GACiVSiiVSk27+v/Z2wzF0VEOwAZJSVlQKlVv3N7YjJlrUcI8LY+15Mo8LY+l5Kpr/DLx6rmKN2jatCk+++wzvPPOO/kKTB8ODg4AgBEjRuD9999HbGwshg4diuXLl2sGhL5q0qRJuS6etX79ejg5ORk1XrVFi6pjzx5/9Or1N7p0uVYoxyQiIjK0tLQ09OjRA0lJSXBzc8tzO72Lia1bt2L8+PEYPXo0qlSpkmNWR9WqVfMXcS7s7e1Rq1Yt/PXXX5q2IUOGIDY2FkeOHMn1Mbn1TPj5+eHRo0daT4RSqURMTAxatGhh8Jkpw4fbYMkSOcaOzcKUKUWjZ8JYuRYlzNPyWEuuzNPyWEquycnJKFGixBuLCb1Pc3Tu3BkA0K9fP02bTCbTrIxpyAGYPj4+qFSpklZbxYoVsXnz5jwfo1AooFAocrTb2dnl+oLm1V4Q6uf7+XM57OzkBt13QRgj16KIeVoea8mVeVoec89V19j1LiZu3rypdzD51aBBA1y5ckWr7erVq/D39y+0GPKDAzCJiMia6F1MFOYX+fDhw1G/fn3MmDEDkZGROH78OFasWIEVK1YUWgz5wWKCiIisid4X+gKAtWvXokGDBvD19cXt27cBSMtt//LLLwYNrnbt2ti6dSt+/PFHVK5cGVOnTsX8+fPRs2dPgx7H0FhMEBGRNdG7mFi2bBlGjBiBNm3aIDExUTNGwt3dHfPnzzd0fHj33Xdx/vx5vHjxApcuXXrttNCiwtlZ+pfFBBERWQO9i4lFixZh5cqV+OKLLyCXvxxcWKtWLZw/f96gwZkr9kwQEZE10buYuHnzJmrUqJGjXaFQIJWXyQTwspjg00FERNZA72IiMDAQZ86cydG+Y8cOVKxY0RAxmT32TBARkTXRezbHiBEjMGjQILx48QJCCBw/fhw//vgjZs6ciW+//dYYMZodFhNERGRN9C4m/vOf/8DR0RHjx4/XLLPp6+uLBQsWoFu3bsaI0exkLyaEAIx4LTQiIiKT07uYAICePXuiZ8+eSEtLQ0pKCry9vQ0dl1lTz+bIzAQyMoBcFuQkIiKyGPkagHntmnTxKicnJ00hce3aNdy6dcugwZkrdTEB8FQHERFZPr2LiT59+mhdeEvt2LFj6NOnjyFiMnt2di97Izijg4iILJ3excTp06fRoEGDHO1169bNdZaHteIgTCIishZ6FxMymQzPnj3L0Z6UlGTQK4aaOxYTRERkLfQuJho3boyZM2dqFQ5ZWVmYOXMmGjZsaNDgzBmLCSIishZ6z+aYNWsWIiIiUKFCBTRq1AgA8OeffyI5ORl79+41eIDmisUEERFZC717JsLCwnDu3DlERkYiISEBz549Q+/evXH58mVUrlzZGDGaJV7si4iIrIVePRNKpRLvvPMOli9fjhkzZhgrJovAngkiIrIWevVM2NnZ4dy5c8aKxaLwYl9ERGQt9D7N0atXL6xatcoYsVgU9kwQEZG10HsAZmZmJv773/9i9+7dCA8Ph3P25R4BzJs3z2DBmTMWE0REZC30LiYuXLiAmjVrAgCuXr2qdZ+MV7TSYDFBRETWQu9iYt++fcaIw+KwmCAiImuh95gJtevXr2Pnzp14/vw5AEAIYbCgLAGnhhIRkbXQu5h4/PgxmjVrhvLly6NNmzaIj48HAHz44YcYOXKkwQM0V5zNQURE1kLvYmL48OGws7PDnTt34OTkpGnv2rUrduzYYdDgzBlPcxARkbXQe8zErl27sHPnTpQpU0arPSQkBLdv3zZYYOaOxQQREVkLvXsmUlNTtXok1J48eQKFQmGQoCwBiwkiIrIWehcTjRo1wvfff6+5LZPJoFKpMGfOHDRp0sSgwZkzFhNERGQt9D7NMWfOHDRr1gwnTpxARkYGPvvsM1y8eBFPnjzB4cOHjRGjWeJsDiIishZ690xUrlwZV69eRcOGDdGhQwekpqaiU6dOOH36NIKCgowRo1nKPptDpTJtLERERMakV8/ErVu3EBMTA6VSiQ4dOuCLL74wVlxmT11MAMDz5y97KoiIiCyNzsXEvn378O6772oWqbK1tcV///tf9OrVy2jBmTNHR0AmA4SQTnWwmCAiIkul82mOCRMmoEWLFoiLi8Pjx4/Rv39/fPbZZ8aMzazZ2HDcBBERWQedi4kLFy5gxowZ8PHxgYeHB7766iskJCTg8ePHxozPrHFGBxERWQOdi4nk5GSUKFFCc9vJyQmOjo5ISkoySmCWgMUEERFZA70GYO7cuRPFihXT3FapVNizZw8uXLigaWvfvr3hojNzPM1BRETWQK9iIioqKkfbgAEDNP+XyWTIysoqeFQWgj0TRERkDXQuJlRcLEFvvHIoERFZA70XrSpMkyZNgkwm0/oJDQ01dVg6Y88EERFZA72X0y5sYWFh2L17t+a2rW2RD1mDxQQREVmDIv/NbGtri1KlSpk6jHxhMUFERNagyBcT165dg6+vLxwcHFCvXj3MnDkTZcuWzXP79PR0pKena24nJycDAJRKJZRKpaZd/f/sbYbm6GgDQI7k5CwolaYbc1IYuRYFzNPyWEuuzNPyWEquusYvE0III8eSb9u3b0dKSgoqVKiA+Ph4TJ48GXFxcbhw4QJcXV1zfcykSZMwefLkHO3r16+Hk5OTsUPW8tNP5fHjjxXRosUtDBp0tlCPTUREVFBpaWno0aMHkpKS4Obmlud2+SomEhMTsWnTJty4cQOjR4+Gp6cnTp06hZIlS6J06dIFCvxNx/X398e8efPw4Ycf5rpNbj0Tfn5+ePTokdYToVQqERMTgxYtWsDOzs4o8S5YYIPRo+Xo1k2F77833ZTZwsi1KGCelsdacmWelsdSclUvWPmmYkLv0xznzp1D8+bNUaxYMdy6dQv9+/eHp6cntmzZgjt37uD7778vUOCv4+7ujvLly+P69et5bqNQKKBQKHK029nZ5fqC5tVuCOr1vdLSbGBnZ/qJM8bMtShhnpbHWnJlnpbH3HPVNXa9v+FGjBiBPn364Nq1a3BwcNC0t2nTBgcPHtR3d3pJSUnBjRs34OPjY9TjGAoHYBIRkTXQu5iIjY3VWvVSrXTp0rh//75BglIbNWoUDhw4gFu3buGvv/7Ce++9B7lcju7duxv0OMbCYoKIiKyB3qc5FAqFZoZEdlevXoWXl5dBglK7e/cuunfvjsePH8PLywsNGzbE0aNHDX4cY2ExQURE1kDvYqJ9+/aYMmUKNm7cCEC6HsedO3cwZswYdO7c2aDBbdiwwaD7K2y80BcREVkDvU9zzJ07FykpKfD29sbz588RERGB4OBguLq6Yvr06caI0WyxZ4KIiKyB3j0TxYoVQ0xMDA4dOoRz584hJSUFNWvWRPPmzY0Rn1njhb6IiMga5HsFzIYNG6Jhw4aGjMXiqIuJ9HRAqQTMeHYQERFRnvQuJhYuXJhru0wmg4ODA4KDg9G4cWPI5fICB2fu1MUEIPVOuLubLBQiIiKj0buY+Oabb/Dw4UOkpaXBw8MDAPD06VM4OTnBxcUFCQkJKFeuHPbt2wc/Pz+DB2xO7O2l3gilUho3wWKCiIgskd4DMGfMmIHatWvj2rVrePz4MR4/foyrV6+iTp06WLBgAe7cuYNSpUph+PDhxojX7HAQJhERWTq9eybGjx+PzZs3IygoSNMWHByMr7/+Gp07d8Y///yDOXPmGHyaqLlydgaePmUxQURElkvvnon4+HhkZmbmaM/MzNSsgOnr64tnz54VPDoLwJ4JIiKydHoXE02aNMGAAQNw+vRpTdvp06cxcOBANG3aFABw/vx5BAYGGi5KM8bpoUREZOn0LiZWrVoFT09PhIeHa67QWatWLXh6emLVqlUAABcXF8ydO9fgwZoj9kwQEZGl03vMRKlSpRATE4PLly/j6tWrAIAKFSqgQoUKmm2aNGliuAjNHIsJIiKydPletCo0NBShoaGGjMUisZggIiJLl69i4u7du/j1119x584dZGRkaN03b948gwRmKVhMEBGRpdO7mNizZw/at2+PcuXK4fLly6hcuTJu3boFIQRq1qxpjBjNGq8cSkRElk7vAZjjxo3DqFGjcP78eTg4OGDz5s34999/ERERgffff98YMZo1zuYgIiJLp3cxcenSJfTu3RsAYGtri+fPn8PFxQVTpkzB7NmzDR6gueNpDiIisnR6FxPOzs6acRI+Pj64ceOG5r5Hjx4ZLjILwWKCiIgsnd5jJurWrYtDhw6hYsWKaNOmDUaOHInz589jy5YtqFu3rjFiNGssJoiIyNLpXUzMmzcPKf/7Zpw8eTJSUlLw008/ISQkhDM5csFigoiILJ1exURWVhbu3r2LqlWrApBOeSxfvtwogVkKzuYgIiJLp9eYCblcjpYtW+Lp06fGisfisGeCiIgsnd4DMCtXrox//vnHGLFYJE4NJSIiS6d3MTFt2jSMGjUKv//+O+Lj45GcnKz1Q9rYM0FERJZO7wGYbdq0AQC0b98eMplM0y6EgEwmQ1ZWluGiswDZiwkhgGxPGRERkUXQu5jYt2+fMeKwWOpiQqUCXrwAHB1NGw8REZGh6V1MREREGCMOi+Xk9PL/KSksJoiIyPLoPWYCAP7880/06tUL9evXR1xcHABg7dq1OHTokEGDswRy+csCguMmiIjIEuldTGzevBmtWrWCo6MjTp06hfT0dABAUlISZsyYYfAALQEHYRIRkSXL12yO5cuXY+XKlbCzs9O0N2jQAKdOnTJocJaC00OJiMiS6V1MXLlyBY0bN87RXqxYMSQmJhoiJovDngkiIrJkehcTpUqVwvXr13O0Hzp0COXKlTNIUJaGxQQREVkyvYuJ/v37Y+jQoTh27BhkMhnu3buHdevWYdSoURg4cKAxYjR7LCaIiMiS6T01dOzYsVCpVGjWrBnS0tLQuHFjKBQKjBo1Cp9++qkxYjR7LCaIiMiS6V1MyGQyfPHFFxg9ejSuX7+OlJQUVKpUCS7qb0zKgVcOJSIiS6b3aY4ffvgBaWlpsLe3R6VKlfDWW2+xkHgDzuYgIiJLpncxMXz4cHh7e6NHjx74v//7P16LQwc8zUFERJZM72IiPj4eGzZsgEwmQ2RkJHx8fDBo0CD89ddfxohPy6xZsyCTyTBs2DCjH8uQWEwQEZEl07uYsLW1xbvvvot169YhISEB33zzDW7duoUmTZogKCjIGDECAGJjYxEdHY2qVasa7RjGwmKCiIgsmd4DMLNzcnJCq1at8PTpU9y+fRuXLl0yVFxaUlJS0LNnT6xcuRLTpk177bbp6emaJb4BIDk5GQCgVCqhVCo17er/Z28zFkdHGwByJCeroFQW/mmhwszVlJin5bGWXJmn5bGUXHWNXyaEEPruPC0tDVu3bsW6deuwZ88e+Pn5oXv37ujZsydCQ0P1DvZNoqKi4OnpiW+++QZvv/02qlevjvnz5+e67aRJkzB58uQc7evXr4dT9kt4FqL9+8tg/vxwVKuWgMmTj5gkBiIiIn2lpaWhR48eSEpKgpubW57b6d0z0a1bN/z+++9wcnJCZGQkJkyYgHr16hUo2NfZsGEDTp06hdjYWJ22HzduHEaMGKG5nZycDD8/P7Rs2VLriVAqlYiJiUGLFi20rjFiDEqlDPPnAw4OJdCmTRujHiv34xderqbEPC2PteTKPC2PpeSq7t1/E72LCblcjo0bN6JVq1aQy+Va9124cAGVK1fWd5d5+vfffzF06FDExMTAwcFBp8coFAooFIoc7XZ2drm+oHm1G5K7u/RvWpoN7OzyddV3gyiMXIsC5ml5rCVX5ml5zD1XXWPXu5hYt26d1u1nz57hxx9/xLfffouTJ08adKroyZMnkZCQgJo1a2rasrKycPDgQSxevBjp6ek5CpqiiAMwiYjIkuV7AObBgwexatUqbN68Gb6+vujUqROWLFliyNjQrFkznD9/Xqutb9++CA0NxZgxY8yikABYTBARkWXTq5i4f/8+1qxZg1WrViE5ORmRkZFIT0/Htm3bUKlSJYMH5+rqmuO0ibOzM4oXL27Q0ynGxmKCiIgsmc4n8Nu1a4cKFSrg3LlzmD9/Pu7du4dFixYZMzaLoS4mnj8HuGAoERFZGp17JrZv344hQ4Zg4MCBCAkJMWZMr7V//36THTu/1Bf6AqTrc7xmdg0REZHZ0bln4tChQ3j27BnCw8NRp04dLF68GI8ePTJmbBbDwQGw+d8zzVMdRERkaXQuJurWrYuVK1ciPj4eAwYMwIYNG+Dr6wuVSoWYmBg8e/bMmHGaNZmMVw4lIiLLpfeiB87OzujXrx8OHTqE8+fPY+TIkZg1axa8vb3Rvn17Y8RoETgIk4iILFWBVlCqUKEC5syZg7t37+LHH380VEwWicUEERFZKoMsxyiXy9GxY0f8+uuvhtidRWIxQURElsp0aztbGRYTRERkqVhMFBL19FAWE0REZGlYTBQSzuYgIiJLxWKikPA0BxERWSoWE4WExYRxZWUBBw7IcPBgaRw4IOOy5UREhYjFRCFhMWE8W7YAAQFAixa2mDevFlq0sEVAgNRORETGx2KikLCYMI4tW4AuXYC7d7Xb4+KkdhYURETGx2KikHA2h+FlZQFDhwJC5LxP3TZsGK/USkRkbCwmCgl7Jgzvzz9z9khkJwTw77/SdkREZDwsJgoJp4YaXny8YbcjIqL8YTFRSNgzYXilSum2nY+PceMgIrJ2LCYKCYsJw3rwAJg7983buboC9eoZPx4iImvGYqKQsJgwnN9+A6pUAf74A7C1ldpksty3ffYMaNMGSEgovPiIiKwNi4lCwmKi4FJSgAEDgPbtgYcPpYLi1Clg82agdGntbf38gOHDpVk0e/cCNWsCR4+aJm4iIkvHYqKQZJ8amttURnq9Y8eAGjWAFSuk2yNHAsePSwVFp07ArVtATEwmRow4gZiYTNy8CcybJ20TGiqtO9G4MbB4MZ9/IiJDYzFRSNQ9E5mZQEaGaWMxJ5mZwOTJQIMGwPXrQJkywJ49wNdfAw4OL7eTy4GICIHGjeMQESEgl0vtlSpJBUWXLoBSCXz6KdCrF2fVEBEZEouJQqLumQD4Raar69eBhg2BSZOkhae6dwfOnQOaNtVvP66uwMaNwDffSGMs1q8H6tQBrl41SthERFaHxUQhsbMDFArp/xw38XpCAN9+C1SvLp3eKFYMWLdOKgI8PPK3T5lMWg1z3z5pqujFi0CtWtJ4CyIiKhgWE4WIgzDf7OFDoGNHoH9/qQfn7bel3ogePQyz/4YNpUGbERHSTI8uXYBRo6TTKURElD8sJgoRi4nX++MPaUDlr79KPTlffSWNjyhb1rDHKVUK2L1bKiIAab2KZs2A+/cNexwiImvBYqIQsZjIXWoqMHAg8O670mJUYWFAbKz0ZW9jpN9QW1upWNm8WRpTcfCgNFuE1/EgItIfi4lCxCuH5hQbK60BsXy5dHvYMODECaBatcI5fqdOUgxhYVLPRJMm0kBNTh8lItIdi4lCxIt9vZSZCUybBtSvL82q8PUFYmKkL/LsUz4LQ4UK0kDPHj2kWSMjRgBdu0pjKoiI6M1YTBQinuaQ3LghLSA1YYJUVERGAufPA82bmy4mZ2fghx+ARYuk8Ro//wy89Rbw99+mi4mIyFywmChETk7SvwcPAvv3S38FWxMhgP/+V5ryeeQI4OYGrF0LbNgAeHqaOjpp+ujgwcCBA9Ly3JcvSwXFhg2mjoyIqGhjMVFItmyRLlAFSH8BN2kCBARI7dbg0SOgc2fgww+lnpnGjaUpn7165X2RLlOpVw84fVqa4ZGaKi2WNXQoVy4lIsoLi4lCsGWLtJ7Bq2Ml4uKkdksvKLZvl6Z8bt0qnUKYNUu6+Ja/v6kjy5uXF7BzJ/D559LthQulAjAuzrRxEREVRSwmjCwrS/qrNrfZAeq2YcMs85RHWpp02qBNG2mmRMWK0kDHMWOguXZGUSaXA9OnA7/8Iq3C+ddf0syTfftMHRkRUdHCYsLI/vwTuHs37/uFAP791/LWNzh1CggPB5YskW5/+ilw8qS0loO5ad9eir1aNSAhQRooOns2p48SEamxmDCy+HjDblfUZWUBM2dKF9K6fFm6DsaOHdJpAkdHU0eXf0FBUs9EVBSgUgFjx0prVCQlmToyIiLTK9LFxLJly1C1alW4ubnBzc0N9erVw/bt200dll58fAy7XVF286Z0LY3PP5emfHbuLE35bNXK1JEZhpMTsHo1EB0N2NsD27ZJFws7d87UkRERmVaRLibKlCmDWbNm4eTJkzhx4gSaNm2KDh064OLFi6YOTWeNGgFlyrx+xoKzs3l2/6sJAXz3nXQa4NAhaXnqNWuktRqKFzd1dIYlkwEffQQcPiwNIL1+HahbV5riSkRkrYp0MdGuXTu0adMGISEhKF++PKZPnw4XFxccPXrU1KHpTC4HFiyQ/p9XQZGaKq1ncOpU4cVlKI8fA++/D/TpI60Y2aABcPasdDqgqE35NKRataRxFK1aAc+fA717S9cXSU83dWRERIXP1tQB6CorKws///wzUlNTUa9evTy3S09PR3q2T/Tk5GQAgFKphFKp1LSr/5+9zVjatQM2bJBhxAg54uJefsOWKSPQr58Kq1bZ4OpVGerWFZg+XYUhQ1QGvcCVsXKNiZHhP/+RIz5eBltbgS+/VGH0aBXkcqAQntYcCvM1BaRFt7ZtA6ZPt8H06TZYvlyGkydV+PHHLINf6TS7ws7TlKwlV+ZpeSwlV13jlwlRtMeknz9/HvXq1cOLFy/g4uKC9evXo02bNnluP2nSJEyePDlH+/r16+GkXoLSRLKygL//Lo6nTx3g4fEClSo9hlwOJCfbYcmSGjh2TBo4UbPmAwwZchru7kXzz9z0dBusXVsJv/8eBAAoXfoZhg8/ieBg6x2NePKkN775JhwpKfZwdU3HiBEnUaPGQ1OHRURUIGlpaejRoweSkpLg5uaW53ZFvpjIyMjAnTt3kJSUhE2bNuHbb7/FgQMHUKlSpVy3z61nws/PD48ePdJ6IpRKJWJiYtCiRQvY2dkZPY83EQJYudIGo0bZ4MULGUqWFFi1KgstWxb85TFkrqdPA3362OLSJamHZeDALMycqYKJ6zQApn9Nb90CunWT49QpG8hkAhMnqjB2rGF7mQDT51mYrCVX5ml5LCXX5ORklChR4o3FRJE/zWFvb4/g4GAAQHh4OGJjY7FgwQJER0fnur1CoYBCocjRbmdnl+sLmle7KQwaBERESMs3X7ggw7vv2mLkSGDGDGn2QEEVJNesLODrr6WLcymVQKlS0nU2WreWAyhaK1CZ6jUNCZEGZg4ZAqxcKcOkSXLExsqxdi3g4WH44xWl311js5ZcmaflMfdcdY29SA/AzI1KpdLqebA0lSsDx49LhQUAzJ0rXSvi6lXTxXT7NtC0qbS2glIJdOwoTfls3dp0MRVVDg7AihVSoeXgAPzxh7R41+nTpo6MiMh4inQxMW7cOBw8eBC3bt3C+fPnMW7cOOzfvx89e/Y0dWhG5egILF4sDe7z9JRmedSsKU23LMyTUkJIUx6rVpWudOriAqxaJV1LpESJwovDHPXtKy1yFRgorb9Rr55UYBARWaIiXUwkJCSgd+/eqFChApo1a4bY2Fjs3LkTLVq0MHVohaJDB2lBpCZNpOmjffsCPXoUzqqLT54A3bpJUx6Tk6UvwzNngH79LHvKpyHVqCFNH333XWnK6IcfAv37Ay9emDoyIiLDKtLFxKpVq3Dr1i2kp6cjISEBu3fvtppCQq10aSAmRho3IZcDGzYA1asDxlxqY/duqTdi40bpmFOmSD0TQUHGO6al8vCQLhQ2fTpgYwN8+620FsfNm6aOjIjIcIp0MUESuRwYN05aXTIwUJo10LCh9AVlyKuNvngBjBgBtGghXWo7JETqqp8wAbAt8kN1iy4bG2mJ8Z07pdND6oug/d//mToyIiLDYDFhRurWlQbyde8uFRHjx0tXsIyLK/i+z54FatcGvvlGuv3xx9Kx3nqr4PsmSfPmUiHx1lvA06dA27bAl19a5uXnici6sJgwM8WKAevWSYMxnZ2B/fulUxK//JK//alU0pTPt94CLlwAvL2B338Hli2T9k+G5ecnnTL65BPp9tSpQJs2wKNHpo2LiKggWEyYIZlMuvbF6dNSd/mTJ9J0zUGDpOtE6OrOHaBZM2D0aCAjA2jfXpry2bat0UInAAoFsGSJNFPG0RHYtUt6HWNjTR0ZEVH+sJgwY+oxDaNGSbeXLn3Zw6CWlQUcOCDDwYOlceCATNOlvn691KOxf790ae0VK6SpqN7ehZ2F9erVCzh2DAgOlgq7hg2ly5sX7TVpiYhyYjFh5uztga++kgb3lSwpFRK1a0unKTZvBgICgBYtbDFvXi20aGGLsmWly6L37ClNMa1TR5ry2b8/p3yaQpUqwIkTwHvvSb1DH38sXYE1Lc3UkRER6Y7FhIVo2VJak6J1a2lWxiefAF26AHfvam937540K8TGBpg0Sfp/SIhJQqb/KVZMKvzmzJFel++/l9b1uH7d1JEREemGxYQFUQ+enDv3zdt6eUmzQTjls2iQyaSxK3v2SK/juXPSOIr8DqwlIipMLCYsjI2NtPT2mzx4APz5p/HjIf28/bY0sLZBA2nl0Y4dpTVGMjNNHRkRUd5YTFig+HjDbkeFy9cX2LcPGDZMuj1rFtCqFZCQkPeAWiIiU2IxYYF8fAy7HRU+OztpAbENG6T1PvbuBSpWlAqN7ANqAwKkC68REZkSiwkL1KgRUKZM3rMzZDJp8aRGjQo3LtJf167SJelLl5bWE0lI0L4/Lk4aaMuCgohMicWEBZLLgQULpP+/WlCob8+fL21HRV+FCnmvPaFuHzaMy3JT0WZNp+isKVc1FhMWqlMnYNMm6S/a7MqUkdo7dTJNXKS/P/+UpvTmRQjg33+li8C98460VsXMmcCPP0qLmt27Jy2bTmQqW7bkXPPGUk/RWVOu2XFioAXr1Ano0AHYty8T27efQevW1dGkiS17JMyMrgNl//1X+smNvT1Qtizg7y990L36r68vpwmbSva/Yp2dZWjSxLJ6DbdskU7Fvdq7pj5FZ0l/3FhTrq/ix4eFk8uBiAiB1NQ4RERUs6gPKWuh60DZuXMBd3fg9m3pMvXqf+/elVbXvH4974Ww5HJpHE1exUaZMlJBQoa1ZQswdChw964tgFqYN096rhcsMM8vnYwMIDX15U9ystRTlttpOnXbf/4jTVV/3Qq8bzrNVxQeo1IBU6bknatMJp2O7NDBsopFNRYTREWcekBtXFzuH1QymXT/0KG5f0hlZkqPfbXIUP975w6gVEr/v3ULOHAg92OULp13sVG2LODgYLicAf7Fboy/YoWQVsjN/oVvyJ/8rIfy9OnLq+haMvXpyI0bgW7dLO/yBSwmiIo49YDaLl2kD6DsXz66DKi1tZW+9P39gcaNc96vUkmnUtTFxasFx+3b0hfQ3bvSz+HDuR+nVKmXxcWrBYe/v36XtLe0v9hflZUl5fe6v2I//VS6doshv/zT0gpn/IytrfR6y2RAYuKbt69VK+8ZaK+blVbY7a/b9tYt4MiR3O/PrkcPYMQIoH59aXG6+vWBGjWkqwmbMxYTRGZAPaBW+oJ92V6mjFRIFOQL1sZG6nUoXVr6YHuVENKU1Nx6NdT/pqYC9+9LP8eO5X6cEiVy79VQFxvFiknbmeov9owMID1dt58XL3TfNrefhISc1815NZ5794Dy5Q2bZ3YKhfSFb4wf9Smx/fuBJk3eHMtXX0mrv5ozXXOVy6X3yZYtLwdlKhRSQVW/vvRTr5504UZ9ZGVJg7Xj46VTo40aFW5PHosJIjNhqgG1Mpn0wVaypHSV2VcJIa2B8bpiIykJePRI+jlxIvfjuLtLRcWVK68/x/7hh8CNG9Kpmfx8kedWCGRkGOSpMjh7e6nIMvSXvZNT4Qy41fUUnSWseaNrrn//LS2Z/9dfL38ePZJ6/LL3+gUFafdeVKqUd3HwsifvZVth9+SxmCAyI0VxQK1MBhQvLv2Eh+e+TWJi3oXG7dvA48fSNrp0iScmAp99ZqDg82BrK40BUSjy//O6x1+7Bnz55Zvj2LnTvP9iL+gpOnOia64uLlLhoS6ghJAGRmcvLi5elArmGzeAtWul7dzcgLp1X/Ze1KkjtRWVGSQsJojI6NzdpZ9q1XK/PyVFKiq++07q8n6TBg2kxbwK8oX+uh8bI6/Ak5UFrFhhHX+xG/MUXVGTn1xlMiAkRPqJipLaEhOl04Xq4uLoUWlmzK5d0o/6cZUrA//8UzRmkLCYICKTc3EBwsKANm10KyamTeNf7ObEmta8MUSu7u7Sxf1atZJuZ2YCFy5o917cvAmcP//6/ahnkPz5p/HfL1wBk4iKDGu6roy1rVKrPkXXuHEcIiKERRYSaobO1dYWqF5dmkL7ww9Sb8S9ey+vLPwmhXGFaBYTRFRkWNt1ZTp1ksaNxMRkYsSIE4iJycTNm5ZXSJDh+fhIPSC6bmtsLCaIqEjhX+ymjojMRVHqyWMxQURFDv9iJ3qzotSTx2KCiIok/sVO9GZFpSePszmIiIjMmHoGCVfAJCIionyTy007XZqnOYiIiKhAWEwQERFRgbCYICIiogJhMUFEREQFwmKCiIiICqRIFxMzZ85E7dq14erqCm9vb3Ts2BFXrlwxdVhERESUTZEuJg4cOIBBgwbh6NGjiImJgVKpRMuWLZGammrq0IiIiOh/ivQ6Ezt27NC6vWbNGnh7e+PkyZNo3LixiaIiIiKi7Ip0MfGqpKQkAICnp2ee26SnpyM9PV1zOzk5GQCgVCqhVCo17er/Z2+zVNaSK/O0PNaSK/O0PJaSq67xy4QQwsixGIRKpUL79u2RmJiIQ4cO5bndpEmTMHny5Bzt69evh5OTkzFDJCIisihpaWno0aMHkpKS4Obmlud2ZlNMDBw4ENu3b8ehQ4dQpkyZPLd7tWciKSkJZcuWxc2bN+Hq6qppVyqV2LdvH5o0aQI7Ozujxm5q1pIr87Q81pIr87Q8lpLrs2fPEBgYiMTERBQrVizP7cziNMfgwYPx+++/4+DBg68tJABAoVBAoVBobqtPcwQGBho1RiIiIkv17Nmz1xYTRbpnQgiBTz/9FFu3bsX+/fsREhKi9z5UKhXu3bsHV1dXyLJd8D05ORl+fn74999/X9t1YwmsJVfmaXmsJVfmaXksJVchBJ49ewZfX1/Y2OQ9AbRI90wMGjQI69evxy+//AJXV1fcv38fAFCsWDE4OjrqtA8bG5vX9ma4ubmZ9QutD2vJlXlaHmvJlXlaHkvI9XU9EmpFep2JZcuWISkpCW+//TZ8fHw0Pz/99JOpQyMiIqL/KdI9E0X4DAwRERH9T5HumTAmhUKBiRMnag3WtFTWkivztDzWkivztDzWlCtQxAdgEhERUdFntT0TREREZBgsJoiIiKhAWEwQERFRgbCYICIiogKx2mJiyZIlCAgIgIODA+rUqYPjx4+bOqQCmTlzJmrXrg1XV1d4e3ujY8eOuHLlitY2L168wKBBg1C8eHG4uLigc+fOePDggYkiNoxZs2ZBJpNh2LBhmjZLyjMuLg69evVC8eLF4ejoiCpVquDEiROa+4UQ+PLLL+Hj4wNHR0c0b94c165dM2HE+svKysKECRMQGBgIR0dHBAUFYerUqVpTw80xz4MHD6Jdu3bw9fWFTCbDtm3btO7XJacnT56gZ8+ecHNzg7u7Oz788EOkpKQUYha6eV2uSqUSY8aMQZUqVeDs7AxfX1/07t0b9+7d09qHOeT6ptc0u48//hgymQzz58/XajeHPPPDKouJn376CSNGjMDEiRNx6tQpVKtWDa1atUJCQoKpQ8u3AwcOYNCgQTh69ChiYmKgVCrRsmVLpKamarYZPnw4fvvtN/z88884cOAA7t27h06dOpkw6oKJjY1FdHQ0qlatqtVuKXk+ffoUDRo0gJ2dHbZv346///4bc+fOhYeHh2abOXPmYOHChVi+fDmOHTsGZ2dntGrVCi9evDBh5PqZPXs2li1bhsWLF+PSpUuYPXs25syZg0WLFmm2Mcc8U1NTUa1aNSxZsiTX+3XJqWfPnrh48SJiYmI01yf66KOPCisFnb0u17S0NJw6dQoTJkzAqVOnsGXLFly5cgXt27fX2s4ccn3Ta6q2detWHD16FL6+vjnuM4c880VYobfeeksMGjRIczsrK0v4+vqKmTNnmjAqw0pISBAAxIEDB4QQQiQmJgo7Ozvx888/a7a5dOmSACCOHDliqjDz7dmzZyIkJETExMSIiIgIMXToUCGEZeU5ZswY0bBhwzzvV6lUolSpUuKrr77StCUmJgqFQiF+/PHHwgjRINq2bSv69eun1dapUyfRs2dPIYRl5AlAbN26VXNbl5z+/vtvAUDExsZqttm+fbuQyWQiLi6u0GLX16u55ub48eMCgLh9+7YQwjxzzSvPu3fvitKlS4sLFy4If39/8c0332juM8c8dWV1PRMZGRk4efIkmjdvrmmzsbFB8+bNceTIERNGZlhJSUkAAE9PTwDAyZMnoVQqtfIODQ1F2bJlzTLvQYMGoW3btlr5AJaV56+//opatWrh/fffh7e3N2rUqIGVK1dq7r958ybu37+vlWuxYsVQp04ds8q1fv362LNnD65evQoAOHv2LA4dOoTWrVsDsJw8s9MlpyNHjsDd3R21atXSbNO8eXPY2Njg2LFjhR6zISUlJUEmk8Hd3R2A5eSqUqnwwQcfYPTo0QgLC8txv6XkmZsivZy2MTx69AhZWVkoWbKkVnvJkiVx+fJlE0VlWCqVCsOGDUODBg1QuXJlAMD9+/dhb2+vefOqlSxZUnMBNXOxYcMGnDp1CrGxsTnus6Q8//nnHyxbtgwjRozA559/jtjYWAwZMgT29vaIiorS5JPb77I55Tp27FgkJycjNDQUcrkcWVlZmD59Onr27AkAFpNndrrkdP/+fXh7e2vdb2trC09PT7PNG5DGNI0ZMwbdu3fXXADLUnKdPXs2bG1tMWTIkFzvt5Q8c2N1xYQ1GDRoEC5cuIBDhw6ZOhSD+/fffzF06FDExMTAwcHB1OEYlUqlQq1atTBjxgwAQI0aNXDhwgUsX74cUVFRJo7OcDZu3Ih169Zh/fr1CAsLw5kzZzBs2DD4+vpaVJ4kDcaMjIyEEALLli0zdTgGdfLkSSxYsACnTp2CTCYzdTiFzupOc5QoUQJyuTzH6P4HDx6gVKlSJorKcAYPHozff/8d+/bt07r0eqlSpZCRkYHExESt7c0t75MnTyIhIQE1a9aEra0tbG1tceDAASxcuBC2trYoWbKkReQJAD4+PqhUqZJWW8WKFXHnzh0A0ORj7r/Lo0ePxtixY9GtWzdUqVIFH3zwAYYPH46ZM2cCsJw8s9Mlp1KlSuUYFJ6ZmYknT56YZd7qQuL27duIiYnRuiy3JeT6559/IiEhAWXLltV8Nt2+fRsjR45EQEAAAMvIMy9WV0zY29sjPDwce/bs0bSpVCrs2bMH9erVM2FkBSOEwODBg7F161bs3bsXgYGBWveHh4fDzs5OK+8rV67gzp07ZpV3s2bNcP78eZw5c0bzU6tWLfTs2VPzf0vIEwAaNGiQY3rv1atX4e/vDwAIDAxEqVKltHJNTk7GsWPHzCrXtLQ02NhofxTJ5XKoVCoAlpNndrrkVK9ePSQmJuLkyZOabfbu3QuVSoU6deoUeswFoS4krl27ht27d6N48eJa91tCrh988AHOnTun9dnk6+uL0aNHY+fOnQAsI888mXoEqCls2LBBKBQKsWbNGvH333+Ljz76SLi7u4v79++bOrR8GzhwoChWrJjYv3+/iI+P1/ykpaVptvn4449F2bJlxd69e8WJEydEvXr1RL169UwYtWFkn80hhOXkefz4cWFrayumT58url27JtatWyecnJzEDz/8oNlm1qxZwt3dXfzyyy/i3LlzokOHDiIwMFA8f/7chJHrJyoqSpQuXVr8/vvv4ubNm2LLli2iRIkS4rPPPtNsY455Pnv2TJw+fVqcPn1aABDz5s0Tp0+f1sxg0CWnd955R9SoUUMcO3ZMHDp0SISEhIju3bubKqU8vS7XjIwM0b59e1GmTBlx5swZrc+n9PR0zT7MIdc3vaavenU2hxDmkWd+WGUxIYQQixYtEmXLlhX29vbirbfeEkePHjV1SAUCINef1atXa7Z5/vy5+OSTT4SHh4dwcnIS7733noiPjzdd0AbyajFhSXn+9ttvonLlykKhUIjQ0FCxYsUKrftVKpWYMGGCKFmypFAoFKJZs2biypUrJoo2f5KTk8XQoUNF2bJlhYODgyhXrpz44osvtL5ozDHPffv25fqejIqKEkLoltPjx49F9+7dhYuLi3BzcxN9+/YVz549M0E2r/e6XG/evJnn59O+ffs0+zCHXN/0mr4qt2LCHPLMD16CnIiIiArE6sZMEBERkWGxmCAiIqICYTFBREREBcJigoiIiAqExQQREREVCIsJIiIiKhAWE0RERFQgLCaIiIioQFhMEBEA4NatW5DJZDhz5oypQ9G4fPky6tatCwcHB1SvXt3U4eRp//79kMlkOS4wR2QtWEwQFRF9+vSBTCbDrFmztNq3bdtmlZc0BoCJEyfC2dkZV65c0booFhEVLSwmiIoQBwcHzJ49G0+fPjV1KAaTkZGR78feuHEDDRs2hL+/f44rTRJR0cFigqgIad68OUqVKoWZM2fmuc2kSZNydPnPnz8fAQEBmtt9+vRBx44dMWPGDJQsWRLu7u6YMmUKMjMzMXr0aHh6eqJMmTJYvXp1jv1fvnwZ9evXh4ODAypXrowDBw5o3X/hwgW0bt0aLi4uKFmyJD744AM8evRIc//bb7+NwYMHY9iwYShRogRatWqVax4qlQpTpkxBmTJloFAoUL16dezYsUNzv0wmw8mTJzFlyhTIZDJMmjQpz/3MnDkTgYGBcHR0RLVq1bBp0ybN/epTEH/88QeqVq0KBwcH1K1bFxcuXNDaz+bNmxEWFgaFQoGAgADMnTtX6/709HSMGTMGfn5+UCgUCA4OxqpVq7S2OXnyJGrVqgUnJyfUr19f6xLyZ8+eRZMmTeDq6go3NzeEh4fjxIkTueZEZG5YTBAVIXK5HDNmzMCiRYtw9+7dAu1r7969uHfvHg4ePIh58+Zh4sSJePfdd+Hh4YFjx47h448/xoABA3IcZ/To0Rg5ciROnz6NevXqoV27dnj8+DEAIDExEU2bNkWNGjVw4sQJ7NixAw8ePEBkZKTWPr777jvY29vj8OHDWL58ea7xLViwAHPnzsXXX3+Nc+fOoVWrVmjfvj2uXbsGAIiPj0dYWBhGjhyJ+Ph4jBo1Ktf9zJw5E99//z2WL1+OixcvYvjw4ejVq1eOImj06NGYO3cuYmNj4eXlhXbt2kGpVAKQioDIyEh069YN58+fx6RJkzBhwgSsWbNG8/jevXvjxx9/xMKFC3Hp0iVER0fDxcVF6xhffPEF5s6dixMnTsDW1hb9+vXT3NezZ0+UKVMGsbGxOHnyJMaOHQs7O7u8Xj4i82Lqy5YSkSQqKkp06NBBCCFE3bp1Rb9+/YQQQmzdulVkf6tOnDhRVKtWTeux33zzjfD399fal7+/v8jKytK0VahQQTRq1EhzOzMzUzg7O4sff/xRCCE0l4qeNWuWZhulUinKlCkjZs+eLYQQYurUqaJly5Zax/73338FAM3lsyMiIkSNGjXemK+vr6+YPn26Vlvt2rXFJ598orldrVo1MXHixDz38eLFC+Hk5CT++usvrfYPP/xQdO/eXQjx8rLRGzZs0Nz/+PFj4ejoKH766SchhBA9evQQLVq00NrH6NGjRaVKlYQQQly5ckUAEDExMbnGoT7G7t27NW1//PGHACCeP38uhBDC1dVVrFmzJs9ciMwZeyaIiqDZs2fju+++w6VLl/K9j7CwMNjYvHyLlyxZElWqVNHclsvlKF68OBISErQeV69ePc3/bW1tUatWLU0cZ8+exb59++Di4qL5CQ0NBSCNb1ALDw9/bWzJycm4d+8eGjRooNXeoEEDvXK+fv060tLS0KJFC62Yvv/+e614Xs3L09MTFSpU0Bzr0qVLucZy7do1ZGVl4cyZM5DL5YiIiHhtPFWrVtX838fHBwA0z++IESPwn//8B82bN8esWbNyxEdkzmxNHQAR5dS4cWO0atUK48aNQ58+fbTus7GxgRBCq03dXZ/dq13oMpks1zaVSqVzXCkpKWjXrh1mz56d4z71lycAODs767zPgkhJSQEA/PHHHyhdurTWfQqFwmDHcXR01Gm77M+vegaO+vmdNGkSevTogT/++APbt2/HxIkTsWHDBrz33nsGi5PIVNgzQVREzZo1C7/99huOHDmi1e7l5YX79+9rFRSGXBvi6NGjmv9nZmbi5MmTqFixIgCgZs2auHjxIgICAhAcHKz1o08B4ebmBl9fXxw+fFir/fDhw6hUqZLO+6lUqRIUCgXu3LmTIx4/P78883r69CmuXr2qyatixYq5xlK+fHnI5XJUqVIFKpUqxzgMfZUvXx7Dhw/Hrl270KlTp1wHwBKZI/ZMEBVRVapUQc+ePbFw4UKt9rfffhsPHz7EnDlz0KVLF+zYsQPbt2+Hm5ubQY67ZMkShISEoGLFivjmm2/w9OlTzUDCQYMGYeXKlejevTs+++wzeHp64vr169iwYQO+/fZbyOVynY8zevRoTJw4EUFBQahevTpWr16NM2fOYN26dTrvw9XVFaNGjcLw4cOhUqnQsGFDJCUl4fDhw3Bzc0NUVJRm2ylTpqB48eIoWbIkvvjiC5QoUQIdO3YEAIwcORK1a9fG1KlT0bVrVxw5cgSLFy/G0qVLAQABAQGIiopCv379sHDhQlSrVg23b99GQkJCjsGnuXn+/DlGjx6NLl26IDAwEHfv3kVsbCw6d+6sc65ERRl7JoiKsClTpuQ4DVGxYkUsXboUS5YsQbVq1XD8+PE8Zzrkx6xZszBr1ixUq1YNhw4dwq+//ooSJUoAgKY3ISsrCy1btkSVKlUwbNgwuLu7a43P0MWQIUMwYsQIjBw5ElWqVMGOHTvw66+/IiQkRK/9TJ06FRMmTMDMmTNRsWJFvPPOO/jjjz8QGBiYI6+hQ4ciPDwc9+/fx2+//QZ7e3sAUo/Lxo0bsWHDBlSuXBlffvklpkyZonWKadmyZejSpQs++eQThIaGon///khNTdUpRrlcjsePH6N3794oX748IiMj0bp1a0yePFmvXImKKpl49eQrEZEF2b9/P5o0aYKnT5/C3d3d1OEQWST2TBAREVGBsJggIiKiAuFpDiIiIioQ9kwQERFRgbCYICIiogJhMUFEREQFwmKCiIiICoTFBBERERUIiwkiIiIqEBYTREREVCAsJoiIiKhA/h/RAXD9gbj29QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(epochs, avg_percentages_diffs_epochs, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Percentage Differences vs. Number of epochs')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Average Percentage Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fe764",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092bfbfc",
   "metadata": {},
   "source": [
    "Second part of the project : Predicting on a quarterly basis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b84f8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracts_google_trends_quarterly_data(merged_data_google_trends, features_kept):\n",
    "    \"\"\"\n",
    "    Extract quarterly Google Trends data from a merged DataFrame.\n",
    "\n",
    "    This function extracts quarterly Google Trends data (specified by quartiles) from the merged DataFrame\n",
    "    'merged_data_google_trends'. It also calculates the sum of features for each quarter and returns separate\n",
    "    DataFrames for each quarter (quarter1, quarter2, quarter3, quarter4) and the sum across all quarters (quartersum).\n",
    "\n",
    "    Parameters:\n",
    "        merged_data_google_trends (pandas.DataFrame): The merged DataFrame containing Google Trends data.\n",
    "        features_kept (list of str): List of feature column names to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple of DataFrames: A tuple containing the following DataFrames:\n",
    "            - quarter1: DataFrame containing data for the first quartile.\n",
    "            - quarter2: DataFrame containing data for the second quartile.\n",
    "            - quarter3: DataFrame containing data for the third quartile.\n",
    "            - quarter4: DataFrame containing data for the fourth quartile.\n",
    "            - quartersum: DataFrame containing the sum of features across all quarters.\n",
    "    \"\"\"\n",
    "    # Keep only relevant columns and reset the index\n",
    "    df = merged_data_google_trends.loc[:, features_kept + [\"ISO\", \"year\", \"quartile\"]].reset_index(drop=True)\n",
    "    \n",
    "    # Extracting quartile 1\n",
    "    quarter1 = df[df[\"quartile\"] == 1]\n",
    "    quarter1 = quarter1.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter1.columns = [col + \"_1\" if col != \"ISO\" and col != \"year\" else col for col in quarter1.columns ]\n",
    "\n",
    "    # Extracting quartile 2\n",
    "    quarter2 = df[df[\"quartile\"] == 2]\n",
    "    quarter2 = quarter2.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter2.columns = [col + \"_2\" if col != \"ISO\" and col != \"year\" else col for col in quarter2.columns ]\n",
    "\n",
    "    # Extracting quartile 3\n",
    "    quarter3 = df[df[\"quartile\"] == 3]\n",
    "    quarter3 = quarter3.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter3.columns = [col + \"_3\" if col != \"ISO\" and col != \"year\" else col for col in quarter3.columns ]\n",
    "\n",
    "    # Extracting quartile 4\n",
    "    quarter4 = df[df[\"quartile\"] == 4]\n",
    "    quarter4 = quarter4.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter4.columns = [col + \"_4\" if col != \"ISO\" and col != \"year\" else col for col in quarter4.columns ]\n",
    "\n",
    "    # Calculate the sum of features for each quarter and reset the index\n",
    "    quartersum = df.groupby([\"ISO\", \"year\"]).sum()\n",
    "    quartersum = quartersum.drop(axis=1, columns=[\"quartile\"])\n",
    "    quartersum = quartersum.reset_index()\n",
    "    quartersum.columns = [col + \"_sum\" if col != \"ISO\" and col != \"year\" else col for col in quartersum.columns ]\n",
    "\n",
    "    return quarter1, quarter2, quarter3, quarter4, quartersum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39242303",
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter1,quarter2,quarter3,quarter4,quartersum = extracts_google_trends_quarterly_data(merged_data_google_trends,features_kept) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0f69a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web Apps &amp; Online Tools_1</th>\n",
       "      <th>Business Finance_1</th>\n",
       "      <th>Pharmaceutical Manufacturing_1</th>\n",
       "      <th>Data Management_y_1</th>\n",
       "      <th>Venture Capital_1</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech_1</th>\n",
       "      <th>Genetics_1</th>\n",
       "      <th>Automotive Industry_1</th>\n",
       "      <th>Nanobiotechnology_1</th>\n",
       "      <th>Software Utilities_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Genetics_sum</th>\n",
       "      <th>Automotive Industry_sum</th>\n",
       "      <th>Nanobiotechnology_sum</th>\n",
       "      <th>Software Utilities_sum</th>\n",
       "      <th>Oil &amp; Gas_sum</th>\n",
       "      <th>Renewable Energy_sum</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)_sum</th>\n",
       "      <th>Risk Management_sum</th>\n",
       "      <th>Environmental Science_sum</th>\n",
       "      <th>Artificial Intelligence_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>305.666667</td>\n",
       "      <td>325.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>332.666667</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>334.666667</td>\n",
       "      <td>317.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>314.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>336.666667</td>\n",
       "      <td>316.333333</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.333333</td>\n",
       "      <td>326.333333</td>\n",
       "      <td>321.666667</td>\n",
       "      <td>328.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.333333</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>90.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.666667</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>350.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>311.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>343.666667</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>266.666667</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>273.666667</td>\n",
       "      <td>334.333333</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>311.333333</td>\n",
       "      <td>334.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.333333</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>325.333333</td>\n",
       "      <td>330.666667</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>279.333333</td>\n",
       "      <td>269.666667</td>\n",
       "      <td>268.666667</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>330.333333</td>\n",
       "      <td>244.333333</td>\n",
       "      <td>311.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>158.666667</td>\n",
       "      <td>174.333333</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>257.333333</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>103.666667</td>\n",
       "      <td>174.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>127.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>75.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>181.666667</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>166.333333</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>40.666667</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>123.666667</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>192.666667</td>\n",
       "      <td>367.333333</td>\n",
       "      <td>324.666667</td>\n",
       "      <td>324.666667</td>\n",
       "      <td>323.666667</td>\n",
       "      <td>369.666667</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>177.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Web Apps & Online Tools_1  Business Finance_1  \\\n",
       "0                    68.333333           94.666667   \n",
       "1                    84.000000           81.000000   \n",
       "2                    53.333333           78.666667   \n",
       "3                    68.000000           93.333333   \n",
       "4                    49.333333           84.333333   \n",
       "..                         ...                 ...   \n",
       "139                  68.000000           69.333333   \n",
       "140                  42.000000            0.000000   \n",
       "141                  75.666667           54.000000   \n",
       "142                  40.666667           67.666667   \n",
       "143                  55.333333           65.333333   \n",
       "\n",
       "     Pharmaceutical Manufacturing_1  Data Management_y_1  Venture Capital_1  \\\n",
       "0                         94.000000            85.000000          51.666667   \n",
       "1                         89.000000            89.333333          26.000000   \n",
       "2                         83.666667            74.333333          36.000000   \n",
       "3                         77.333333            91.666667          36.000000   \n",
       "4                         63.000000            92.666667          15.333333   \n",
       "..                              ...                  ...                ...   \n",
       "139                       88.333333            64.333333           7.333333   \n",
       "140                        0.000000            50.333333          19.333333   \n",
       "141                       77.666667            33.000000           6.000000   \n",
       "142                       62.333333             0.000000          60.333333   \n",
       "143                       61.666667            53.000000          18.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech_1  Genetics_1  Automotive Industry_1  \\\n",
       "0                      96.333333   86.333333              82.333333   \n",
       "1                      92.000000   95.000000              79.000000   \n",
       "2                      74.000000    0.000000              83.666667   \n",
       "3                      94.666667   87.666667              91.666667   \n",
       "4                      91.333333   95.333333              94.666667   \n",
       "..                           ...         ...                    ...   \n",
       "139                    68.666667   42.000000              38.333333   \n",
       "140                    29.666667   27.000000              39.666667   \n",
       "141                    40.000000   41.666667              47.666667   \n",
       "142                    57.666667   29.333333              25.666667   \n",
       "143                    27.000000   37.000000              30.666667   \n",
       "\n",
       "     Nanobiotechnology_1  Software Utilities_1  ...  Genetics_sum  \\\n",
       "0              97.333333             95.000000  ...    305.666667   \n",
       "1              95.333333             82.333333  ...    336.666667   \n",
       "2              75.333333             90.666667  ...      0.000000   \n",
       "3              94.666667             72.333333  ...    307.000000   \n",
       "4              98.000000             84.333333  ...    325.333333   \n",
       "..                   ...                   ...  ...           ...   \n",
       "139            45.333333             32.000000  ...    172.000000   \n",
       "140            27.666667             46.000000  ...    100.000000   \n",
       "141            39.666667             38.666667  ...    181.666667   \n",
       "142            43.666667             90.000000  ...    123.666667   \n",
       "143            34.333333             53.666667  ...    124.666667   \n",
       "\n",
       "     Automotive Industry_sum  Nanobiotechnology_sum  Software Utilities_sum  \\\n",
       "0                 325.666667             336.000000              332.666667   \n",
       "1                 316.333333             346.000000              278.666667   \n",
       "2                 318.666667             307.666667              335.000000   \n",
       "3                 343.666667             344.000000              266.666667   \n",
       "4                 330.666667             345.000000              279.333333   \n",
       "..                       ...                    ...                     ...   \n",
       "139               158.666667             174.333333              124.666667   \n",
       "140               141.000000             103.666667              174.666667   \n",
       "141               190.000000             174.000000              166.333333   \n",
       "142                96.000000             192.666667              367.333333   \n",
       "143               108.000000             149.333333              204.333333   \n",
       "\n",
       "     Oil & Gas_sum  Renewable Energy_sum  \\\n",
       "0       337.000000            335.000000   \n",
       "1       327.000000            326.000000   \n",
       "2       335.000000            350.666667   \n",
       "3       268.000000            273.666667   \n",
       "4       269.666667            268.666667   \n",
       "..             ...                   ...   \n",
       "139     162.000000            162.000000   \n",
       "140     146.666667            146.666667   \n",
       "141      61.000000             61.666667   \n",
       "142     324.666667            324.666667   \n",
       "143     146.000000            146.000000   \n",
       "\n",
       "    Renewable Energy (Subcategory of Energy & Utilities)_sum  \\\n",
       "0                                           334.666667         \n",
       "1                                           326.333333         \n",
       "2                                           336.000000         \n",
       "3                                           334.333333         \n",
       "4                                           268.333333         \n",
       "..                                                 ...         \n",
       "139                                         163.000000         \n",
       "140                                         146.666667         \n",
       "141                                          61.333333         \n",
       "142                                         323.666667         \n",
       "143                                         147.333333         \n",
       "\n",
       "     Risk Management_sum  Environmental Science_sum  \\\n",
       "0             317.333333                 192.333333   \n",
       "1             326.333333                 321.666667   \n",
       "2             327.666667                 264.000000   \n",
       "3             365.000000                 311.333333   \n",
       "4             330.333333                 244.333333   \n",
       "..                   ...                        ...   \n",
       "139            97.666667                 257.333333   \n",
       "140           150.000000                 246.000000   \n",
       "141             0.000000                 249.000000   \n",
       "142           369.666667                 293.000000   \n",
       "143           116.333333                 195.000000   \n",
       "\n",
       "     Artificial Intelligence_sum  \n",
       "0                     314.333333  \n",
       "1                     328.333333  \n",
       "2                     311.333333  \n",
       "3                     334.666667  \n",
       "4                     311.666667  \n",
       "..                           ...  \n",
       "139                    92.000000  \n",
       "140                   127.333333  \n",
       "141                    93.000000  \n",
       "142                   215.000000  \n",
       "143                   177.333333  \n",
       "\n",
       "[144 rows x 82 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grouping all the quartiles dataframe together , this will be useful to train the model , and evaluate it later\n",
    "merged_quartiles = pd.merge(quarter1, quarter2, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quarter3, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quarter4, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quartersum, on=[\"ISO\", \"year\"], how='inner')\n",
    "\n",
    "merged_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "830e248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v-1</th>\n",
       "      <th>v</th>\n",
       "      <th>Web Apps &amp; Online Tools_sum</th>\n",
       "      <th>Business Finance_sum</th>\n",
       "      <th>Pharmaceutical Manufacturing_sum</th>\n",
       "      <th>Data Management_y_sum</th>\n",
       "      <th>Venture Capital_sum</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech_sum</th>\n",
       "      <th>Genetics_sum</th>\n",
       "      <th>Automotive Industry_sum</th>\n",
       "      <th>Nanobiotechnology_sum</th>\n",
       "      <th>Software Utilities_sum</th>\n",
       "      <th>Oil &amp; Gas_sum</th>\n",
       "      <th>Renewable Energy_sum</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)_sum</th>\n",
       "      <th>Risk Management_sum</th>\n",
       "      <th>Environmental Science_sum</th>\n",
       "      <th>Artificial Intelligence_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>326.666667</td>\n",
       "      <td>327.333333</td>\n",
       "      <td>304.666667</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>340.666667</td>\n",
       "      <td>305.666667</td>\n",
       "      <td>325.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>332.666667</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>334.666667</td>\n",
       "      <td>317.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>314.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.039421</td>\n",
       "      <td>306.666667</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>308.333333</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>295.333333</td>\n",
       "      <td>276.666667</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>309.666667</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>307.333333</td>\n",
       "      <td>271.333333</td>\n",
       "      <td>176.333333</td>\n",
       "      <td>245.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.903578</td>\n",
       "      <td>-0.047800</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>288.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>278.333333</td>\n",
       "      <td>271.666667</td>\n",
       "      <td>233.666667</td>\n",
       "      <td>221.666667</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>308.666667</td>\n",
       "      <td>312.333333</td>\n",
       "      <td>311.666667</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>196.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.855778</td>\n",
       "      <td>0.061638</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>249.666667</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>105.333333</td>\n",
       "      <td>221.333333</td>\n",
       "      <td>237.333333</td>\n",
       "      <td>233.666667</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>272.666667</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>274.666667</td>\n",
       "      <td>180.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>135.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.917415</td>\n",
       "      <td>-0.092138</td>\n",
       "      <td>303.333333</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>195.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>206.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>226.333333</td>\n",
       "      <td>234.666667</td>\n",
       "      <td>236.333333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2.853501</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>236.666667</td>\n",
       "      <td>201.666667</td>\n",
       "      <td>225.666667</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>153.333333</td>\n",
       "      <td>153.666667</td>\n",
       "      <td>153.333333</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>157.333333</td>\n",
       "      <td>168.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2.904324</td>\n",
       "      <td>0.105778</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>243.666667</td>\n",
       "      <td>225.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>106.666667</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>102.666667</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>175.333333</td>\n",
       "      <td>203.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3.010102</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>224.666667</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>101.666667</td>\n",
       "      <td>148.666667</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>199.333333</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>205.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3.170487</td>\n",
       "      <td>0.297284</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>232.333333</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>134.666667</td>\n",
       "      <td>140.333333</td>\n",
       "      <td>200.666667</td>\n",
       "      <td>147.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>144.333333</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>165.666667</td>\n",
       "      <td>193.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>212.333333</td>\n",
       "      <td>274.333333</td>\n",
       "      <td>220.333333</td>\n",
       "      <td>208.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>117.666667</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>177.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          v-1         v  Web Apps & Online Tools_sum  Business Finance_sum  \\\n",
       "0    1.971243 -0.028245                   278.666667            326.666667   \n",
       "1    1.942999 -0.039421                   306.666667            293.000000   \n",
       "2    1.903578 -0.047800                   336.000000            288.666667   \n",
       "3    1.855778  0.061638                   302.000000            249.666667   \n",
       "4    1.917415 -0.092138                   303.333333            247.000000   \n",
       "..        ...       ...                          ...                   ...   \n",
       "123  2.853501  0.050823                   236.666667            201.666667   \n",
       "124  2.904324  0.105778                   235.000000            231.333333   \n",
       "125  3.010102  0.160385                   235.000000            224.666667   \n",
       "126  3.170487  0.297284                   228.000000            234.000000   \n",
       "127  3.467771 -0.010725                   212.333333            274.333333   \n",
       "\n",
       "     Pharmaceutical Manufacturing_sum  Data Management_y_sum  \\\n",
       "0                          327.333333             304.666667   \n",
       "1                          308.333333             327.666667   \n",
       "2                          277.333333             302.000000   \n",
       "3                          227.000000             232.666667   \n",
       "4                          232.666667             195.666667   \n",
       "..                                ...                    ...   \n",
       "123                        225.666667             215.000000   \n",
       "124                        243.666667             225.666667   \n",
       "125                        238.000000             216.000000   \n",
       "126                        232.333333             207.000000   \n",
       "127                        220.333333             208.333333   \n",
       "\n",
       "     Venture Capital_sum  Pharmaceuticals & Biotech_sum  Genetics_sum  \\\n",
       "0             179.000000                     340.666667    305.666667   \n",
       "1             155.333333                     297.000000    295.333333   \n",
       "2             135.000000                     278.333333    271.666667   \n",
       "3             105.333333                     221.333333    237.333333   \n",
       "4              86.666667                     206.333333    204.333333   \n",
       "..                   ...                            ...           ...   \n",
       "123            75.333333                     106.000000    147.333333   \n",
       "124            78.000000                     106.666667    155.000000   \n",
       "125            71.000000                     101.666667    148.666667   \n",
       "126            72.000000                     102.000000    137.000000   \n",
       "127            63.000000                     117.666667    124.666667   \n",
       "\n",
       "     Automotive Industry_sum  Nanobiotechnology_sum  Software Utilities_sum  \\\n",
       "0                 325.666667             336.000000              332.666667   \n",
       "1                 276.666667             272.000000              293.000000   \n",
       "2                 233.666667             221.666667              290.000000   \n",
       "3                 233.666667             168.333333              236.000000   \n",
       "4                 199.000000             139.000000              210.000000   \n",
       "..                       ...                    ...                     ...   \n",
       "123                98.333333             149.333333              200.000000   \n",
       "124               102.666667             152.000000              207.000000   \n",
       "125               110.000000             144.000000              199.333333   \n",
       "126               134.666667             140.333333              200.666667   \n",
       "127               108.000000             149.333333              204.333333   \n",
       "\n",
       "     Oil & Gas_sum  Renewable Energy_sum  \\\n",
       "0       337.000000            335.000000   \n",
       "1       309.666667            307.666667   \n",
       "2       308.666667            312.333333   \n",
       "3       272.666667            272.000000   \n",
       "4       226.333333            234.666667   \n",
       "..             ...                   ...   \n",
       "123     153.333333            153.666667   \n",
       "124     154.333333            154.000000   \n",
       "125     144.666667            144.666667   \n",
       "126     147.666667            147.000000   \n",
       "127     146.000000            146.000000   \n",
       "\n",
       "     Renewable Energy (Subcategory of Energy & Utilities)_sum  \\\n",
       "0                                           334.666667          \n",
       "1                                           307.333333          \n",
       "2                                           311.666667          \n",
       "3                                           274.666667          \n",
       "4                                           236.333333          \n",
       "..                                                 ...          \n",
       "123                                         153.333333          \n",
       "124                                         154.000000          \n",
       "125                                         145.000000          \n",
       "126                                         144.333333          \n",
       "127                                         147.333333          \n",
       "\n",
       "     Risk Management_sum  Environmental Science_sum  \\\n",
       "0             317.333333                 192.333333   \n",
       "1             271.333333                 176.333333   \n",
       "2             246.666667                 154.333333   \n",
       "3             180.333333                 120.000000   \n",
       "4             154.000000                 112.000000   \n",
       "..                   ...                        ...   \n",
       "123           126.666667                 157.333333   \n",
       "124           132.333333                 175.333333   \n",
       "125           129.000000                 172.000000   \n",
       "126           126.666667                 165.666667   \n",
       "127           116.333333                 195.000000   \n",
       "\n",
       "     Artificial Intelligence_sum  \n",
       "0                     314.333333  \n",
       "1                     245.666667  \n",
       "2                     196.333333  \n",
       "3                     135.666667  \n",
       "4                     112.666667  \n",
       "..                           ...  \n",
       "123                   168.666667  \n",
       "124                   203.666667  \n",
       "125                   205.333333  \n",
       "126                   193.666667  \n",
       "127                   177.333333  \n",
       "\n",
       "[128 rows x 18 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging google trends data with R&D expanditures \n",
    "google_trends_R_D = pd.merge(first_merged, merged_quartiles, on=['ISO', 'year'], how='inner')\n",
    "google_trends_R_D = google_trends_R_D.drop(axis =1 ,columns=[\"ISO\",\"year\",\"v-2\"])\n",
    "\n",
    "#Keep  a copy of this dataframe with quarterly basis data, this will be useful to evaluate our model on a quarterly basis\n",
    "quartiles_data_frame = google_trends_R_D.copy()\n",
    "\n",
    "# columns to keep that we will be using to train our model(only columns that represents sums of google trends data),\n",
    "# also v-1, and v which will be used to evaluate our models \n",
    "cols_to_keep = []\n",
    "for col in google_trends_R_D.columns :\n",
    "    if col ==\"v-1\" or col==\"v\" or col.split(\"_\")[-1]==\"sum\":\n",
    "        cols_to_keep.append(col)\n",
    "\n",
    "google_trends_R_D = google_trends_R_D.loc[:,cols_to_keep]\n",
    "google_trends_R_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78829714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarterly_based_dataframes(X_test, merged_quartiles):\n",
    "    \"\"\"\n",
    "    Extract quarterly-based DataFrames from a merged quartiles DataFrame.\n",
    "\n",
    "    This function takes the testing data X_test and extracts separate DataFrames for each quarter (1, 2, 3, 4) based on the\n",
    "    provided merged quartiles DataFrame. The DataFrames are filtered to include only columns corresponding to the respective\n",
    "    quarters.\n",
    "\n",
    "    Parameters:\n",
    "        X_test (pandas.DataFrame): The testing data for which quarterly-based DataFrames are extracted.\n",
    "        merged_quartiles (pandas.DataFrame): The merged quartiles DataFrame containing features for all quarters.\n",
    "\n",
    "    Returns:\n",
    "        tuple of DataFrames: A tuple containing the following DataFrames:\n",
    "            - X_test_quarter1: DataFrame containing data for the first quarter.\n",
    "            - X_test_quarter2: DataFrame containing data for the second quarter.\n",
    "            - X_test_quarter3: DataFrame containing data for the third quarter.\n",
    "            - X_test_quarter4: DataFrame containing data for the fourth quarter.\n",
    "    \"\"\"\n",
    "    # Extracting data for quarter 1\n",
    "    X_test_quarter1 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep1 = [col for col in X_test_quarter1.columns if col.split(\"_\")[-1] == \"1\"]\n",
    "    X_test_quarter1 = X_test_quarter1.loc[:, cols_to_keep1]\n",
    "\n",
    "    # Extracting data for quarter 2\n",
    "    X_test_quarter2 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep2 = [col for col in X_test_quarter2.columns if col.split(\"_\")[-1] == \"2\"]\n",
    "    X_test_quarter2 = X_test_quarter2.loc[:, cols_to_keep2]\n",
    "\n",
    "    # Extracting data for quarter 3\n",
    "    X_test_quarter3 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep3 = [col for col in X_test_quarter3.columns if col.split(\"_\")[-1] == \"3\"]\n",
    "    X_test_quarter3 = X_test_quarter3.loc[:, cols_to_keep3]\n",
    "\n",
    "    # Extracting data for quarter 4\n",
    "    X_test_quarter4 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep4 = [col for col in X_test_quarter4.columns if col.split(\"_\")[-1] == \"4\"]\n",
    "    X_test_quarter4 = X_test_quarter4.loc[:, cols_to_keep4]\n",
    "\n",
    "    return X_test_quarter1, X_test_quarter2, X_test_quarter3, X_test_quarter4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e823c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_quarterly_basis(df, n_folds, merged_quartiles):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a quarterly basis using cross-validation.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with quarterly data using cross-validation.\n",
    "    It splits the data into `n_folds` folds and calculates the average percentage difference between true and predicted\n",
    "    R&D expenditure values for each fold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data with quarterly features.\n",
    "        n_folds (int): The number of folds for cross-validation.\n",
    "        merged_quartiles (pandas.DataFrame): The DataFrame containing merged quartile-based features.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fold = 0\n",
    "    avg_percentages_diffs = []\n",
    "\n",
    "    # Loop through each fold of cross-validation\n",
    "    for (train_index, test_index) in cross_validation_indices(df, n_folds):\n",
    "        \n",
    "        # Split the data into training and test sets for the current fold\n",
    "        train_df = df.iloc[train_index]\n",
    "        train_df = train_df[:]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # Prepare input data and target data\n",
    "        X_train = train_df.drop(['v', 'v-1'], axis=1)\n",
    "        y_train = train_df['v']\n",
    "        previous_R_D_values = test_df[\"v-1\"]\n",
    "        X_test = test_df.drop(['v', 'v-1'], axis=1)\n",
    "        y_test = test_df['v']\n",
    "        input_shape = X_train.shape[1]\n",
    "        \n",
    "        # Train an NLP model\n",
    "        model = NN_optimized(X_train, y_train, input_shape)\n",
    "        \n",
    "        # Extract quarterly-based DataFrames for testing data\n",
    "        X_test_quarter1, X_test_quarter2, X_test_quarter3, X_test_quarter4 = extract_quarterly_based_dataframes(X_test, merged_quartiles)\n",
    "        \n",
    "        # Make predictions for each quarter\n",
    "        y_pred_quarter1 = model.predict(X_test_quarter1)\n",
    "        y_pred_quarter2 = model.predict(X_test_quarter2)\n",
    "        y_pred_quarter3 = model.predict(X_test_quarter3)\n",
    "        y_pred_quarter4 = model.predict(X_test_quarter4)\n",
    "        \n",
    "        # Calculate true and predicted R&D expenditure values for the entire year\n",
    "        R_D_true_values = previous_R_D_values + y_test\n",
    "        R_D_predicted_values = previous_R_D_values + y_pred_quarter1.flatten() + y_pred_quarter2.flatten() + y_pred_quarter3.flatten() + y_pred_quarter4.flatten()\n",
    "        \n",
    "        # Calculate the average percentage difference for the current fold\n",
    "        avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "        print(f\"the average percentage diff for the {fold}th fold is : {avg_percentage_diff}%\")\n",
    "        \n",
    "        # Store the average percentage difference for this fold\n",
    "        avg_percentages_diffs.append(avg_percentage_diff)\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate the overall average percentage difference across all folds\n",
    "    avg_percentage_diff_folds = sum(avg_percentages_diffs) / n_folds \n",
    "    print(f\"the average percentage diff for this training is : {avg_percentage_diff_folds}%\")\n",
    "    return avg_percentage_diff_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 56ms/step - loss: 168.7302 - val_loss: 0.8487 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 22.9893 - val_loss: 24.8477 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 10.7097 - val_loss: 1.0382 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 3.8615 - val_loss: 2.6584 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 3.6901 - val_loss: 6.6088 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 2.9233 - val_loss: 0.3121 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 1.0447 - val_loss: 0.1505 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2549 - val_loss: 0.0683 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0519 - val_loss: 0.0455 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0230 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0207 - val_loss: 0.0282 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0430 - val_loss: 0.0420 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0664 - val_loss: 0.0346 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0285 - val_loss: 0.0446 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0297 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0878 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0418"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_quarterly_basis(google_trends_R_D,5,merged_quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eac89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1260ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c939ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06290ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
