{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb97fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rac\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from NN_versions import *\n",
    "import random\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb996f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix randomness \n",
    "np.random.seed(675)\n",
    "tf.random.set_seed(675)\n",
    "random.seed(675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541e6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries that will be subject to our study\n",
    "iso = [\n",
    "    \"USA\",  # United States\n",
    "    \"CHN\",  # China\n",
    "    \"JPN\",  # Japan\n",
    "    \"DEU\",  # Germany\n",
    "    \"KOR\",  # South Korea\n",
    "    \"FRA\",  # France\n",
    "    \"GBR\",  # United Kingdom\n",
    "    \"CAN\",  # Canada\n",
    "    \"CHE\"   # Switzerland\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_R_D_expenditure_data(iso):\n",
    "    \"\"\"\n",
    "    Load and preprocess R&D expenditure data.\n",
    "\n",
    "    This function reads a CSV file containing R&D expenditure data, filters and preprocesses it to create a DataFrame\n",
    "    suitable for analysis. It also calculates the difference between consecutive R&D expenditure values for future use.\n",
    "\n",
    "    Parameters:\n",
    "        iso (list of str): List of ISO country codes to filter data by.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the following columns:\n",
    "            - 'ISO': ISO country code.\n",
    "            - 'year': Year of the data.\n",
    "            - 'v-1': R&D expenditure for the previous year.\n",
    "            - 'v-2': R&D expenditure for the year before the previous year.\n",
    "            - 'v': The difference between consecutive R&D expenditure values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loading the dataframe with all the R&D expenditure\n",
    "    df = pd.read_csv('./data/DP_LIVE_08052023154811337.csv')\n",
    "    \n",
    "    # Filter on the measure, time, and location\n",
    "    df_GERD = df[(df['MEASURE']=='PC_GDP') &\n",
    "                 (df['TIME'] >= 2003)]\n",
    "    df_GERD = df_GERD[df_GERD['LOCATION'].isin(iso)][['LOCATION','TIME', 'Value']]\n",
    "    df_GERD = df_GERD.sort_values(by=['LOCATION', 'TIME'])\n",
    "    \n",
    "    # Then, we will shift Our window in the 'Value' column, we use this since we want to predict R&D expenditures with previous \n",
    "    # values as features\n",
    "    df_GERD['v-1'] = df_GERD.groupby('LOCATION')['Value'].shift(1)\n",
    "    df_GERD['v-2'] = df_GERD.groupby('LOCATION')['Value'].shift(2)\n",
    "\n",
    "    # Drop rows that do not have complete data for the previous two years.\n",
    "    df_GERD = df_GERD.dropna(subset=['v-1', 'v-2']).reset_index(drop=True)\n",
    "\n",
    "    df_GERD.rename(columns={'LOCATION': 'ISO', 'TIME': 'year', 'Value': 'v'}, inplace=True)\n",
    "    df_GERD = df_GERD[['ISO', 'year', 'v-1', 'v-2', 'v']]\n",
    "    \n",
    "    # Here we adopt the approach of predicting the difference between 2 consecutive values of R&D expenditures rather than predicting\n",
    "    # the actual value, this will be useful next when we want to predict R&D expenditures on a quarterly basis.\n",
    "    df_GERD[\"v\"] = df_GERD[\"v\"] - df_GERD[\"v-1\"]\n",
    "    \n",
    "    return df_GERD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf4ca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO</th>\n",
       "      <th>year</th>\n",
       "      <th>v-1</th>\n",
       "      <th>v-2</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.997333</td>\n",
       "      <td>1.967807</td>\n",
       "      <td>-0.026090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>1.997333</td>\n",
       "      <td>-0.028245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.039421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.903578</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.855778</td>\n",
       "      <td>1.903578</td>\n",
       "      <td>0.061638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>USA</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.853501</td>\n",
       "      <td>2.786995</td>\n",
       "      <td>0.050823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.904324</td>\n",
       "      <td>2.853501</td>\n",
       "      <td>0.105778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>USA</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.010102</td>\n",
       "      <td>2.904324</td>\n",
       "      <td>0.160385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>3.010102</td>\n",
       "      <td>0.297284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>-0.010725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ISO  year       v-1       v-2         v\n",
       "0    CAN  2005  1.997333  1.967807 -0.026090\n",
       "1    CAN  2006  1.971243  1.997333 -0.028245\n",
       "2    CAN  2007  1.942999  1.971243 -0.039421\n",
       "3    CAN  2008  1.903578  1.942999 -0.047800\n",
       "4    CAN  2009  1.855778  1.903578  0.061638\n",
       "..   ...   ...       ...       ...       ...\n",
       "132  USA  2017  2.853501  2.786995  0.050823\n",
       "133  USA  2018  2.904324  2.853501  0.105778\n",
       "134  USA  2019  3.010102  2.904324  0.160385\n",
       "135  USA  2020  3.170487  3.010102  0.297284\n",
       "136  USA  2021  3.467771  3.170487 -0.010725\n",
       "\n",
       "[137 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading R&D expanditures values \n",
    "merged_df_R_D = load_R_D_expenditure_data(iso)\n",
    "\n",
    "#Keeping a copy of the initial dataframe\n",
    "first_merged = merged_df_R_D.copy()\n",
    "\n",
    "merged_df_R_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c1e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_indices(df, n_folds):\n",
    "    \"\"\"\n",
    "    Generates indices for cross-validation.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame to perform cross-validation on.\n",
    "    n_folds (int): Number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains two arrays, the first for training indices and the second for test indices.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    indices = [(train_index, test_index) for train_index, test_index in kf.split(df)]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea66be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler function for training neural networks.\n",
    "\n",
    "    This scheduler function adjusts the learning rate based on the training epoch. It keeps the learning rate constant for\n",
    "    the first 20 epochs and then applies an exponential decay with a decay rate of tf.math.exp(-0.1).\n",
    "\n",
    "    Parameters:\n",
    "        epoch (int): The current training epoch.\n",
    "        lr (float): The current learning rate.\n",
    "\n",
    "    Returns:\n",
    "        float: The adjusted learning rate for the current epoch.\n",
    "    \"\"\"\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94db9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_optimized(X_train, y_train, input_shape,initial_rate=0.001,batch_size = 8,epochs=80):\n",
    "    \"\"\"\n",
    "    Create and train a more complex neural network model for Natural Language Processing (NLP) tasks.\n",
    "\n",
    "    This function defines a multi-layer neural network model with several hidden layers, ReLU activation functions,\n",
    "    and uses mean squared error as the loss function. It also includes a learning rate scheduler callback to adjust\n",
    "    the learning rate during training.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Input training data.\n",
    "        y_train (numpy.ndarray): Target training data.\n",
    "        input_shape (int): The shape of the input data.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.models.Sequential: The trained neural network model.\n",
    "    \"\"\"\n",
    "    # More complex neural network model\n",
    "    model = Sequential([\n",
    "        Dense(2048, input_shape=(input_shape,)),\n",
    "        Activation('relu'),\n",
    "        Dense(1024),\n",
    "        Activation('relu'),\n",
    "        Dense(512),\n",
    "        Activation('relu'),\n",
    "        Dense(256),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        Activation('relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the model with an initial learning rate\n",
    "    initial_learning_rate = initial_rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Learning rate scheduler callback\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "    # Fit the model with the learning rate scheduler\n",
    "    history=model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[lr_scheduler], validation_split=0.2)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error on the test set\n",
    "    return model,history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4970ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_yearly_basis(df, n_folds, is_google_trends_only=False):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a yearly basis using cross-validation.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with yearly data using cross-validation. It splits\n",
    "    the data into `n_folds` folds and calculates the average percentage difference (MAPE) between true and predicted R&D expenditure\n",
    "    values for each fold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data.\n",
    "        n_folds (int): The number of folds for cross-validation.\n",
    "        is_google_trends_only (bool, optional): Indicates whether only Google Trends data is used as input features. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fold = 0\n",
    "    avg_percentages_diffs_train_set = []\n",
    "    MAEs_train_set = []\n",
    "    avg_percentages_diffs = []\n",
    "    MAEs = []\n",
    "\n",
    "\n",
    "    # Loop through each fold of cross-validation\n",
    "    for (train_index, test_index) in cross_validation_indices(df, n_folds):\n",
    "        \n",
    "        \n",
    "        # Split the data into training and test sets for the current fold\n",
    "        train_df = df.iloc[train_index]\n",
    "        train_df = train_df[:]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # Prepare input data and target data\n",
    "        X_train = train_df.drop(['v', 'year'], axis=1)\n",
    "        y_train = train_df['v']\n",
    "        X_test = test_df.drop(['v', 'year'], axis=1)\n",
    "        previous_R_D_values = X_test[\"v-1\"]\n",
    "        previous_R_D_values_train_set = X_train[\"v-1\"]\n",
    "\n",
    "        \n",
    "        if is_google_trends_only:\n",
    "            # Optionally remove the \"v-1\" column if using Google Trends data only\n",
    "            X_train = X_train.drop(axis=1, columns=[\"v-1\"])\n",
    "            X_test = X_test.drop(axis=1, columns=[\"v-1\"])\n",
    "        \n",
    "        input_shape = X_train.shape[1]\n",
    "        y_test = test_df['v']\n",
    "        \n",
    "        # Train an NLP model\n",
    "        model,history = NN_optimized(X_train, y_train, input_shape)\n",
    "        \n",
    "        # plot the evolution of train and test loss, only 1 plot suffices since the behavior is the same for all other folds\n",
    "        if fold ==4 :\n",
    "            plot_train_val_loss(history, skip = 0, log=False)\n",
    "            \n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Make predictions on the train set\n",
    "        y_pred_train_set = model.predict(X_train)\n",
    "        \n",
    "        # Calculate true and predicted R&D expenditure values\n",
    "        R_D_true_values = previous_R_D_values + y_test\n",
    "        R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "        \n",
    "        # Calculate true and predicted R&D expenditure values for train set\n",
    "        R_D_true_values_train_set = previous_R_D_values_train_set + y_train\n",
    "        R_D_predicted_values_train_set = previous_R_D_values_train_set + y_pred_train_set.flatten()\n",
    "        \n",
    "        #MAE\n",
    "        MAE = np.mean(np.abs(R_D_true_values - R_D_predicted_values))\n",
    "        MAEs.append(MAE)\n",
    "        \n",
    "        #MAE train set\n",
    "        MAE_train_set = np.mean(np.abs(R_D_true_values_train_set - R_D_predicted_values_train_set))\n",
    "        MAEs_train_set.append(MAE_train_set)\n",
    "\n",
    "        \n",
    "        # Calculate the average percentage difference and MAE for the current fold\n",
    "        avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "        print(f\"the MAPE for the {fold}th fold is : {avg_percentage_diff}%\")\n",
    "        \n",
    "        # Store the average percentage difference for this fold\n",
    "        avg_percentages_diffs.append(avg_percentage_diff)\n",
    "        \n",
    "        # Calculate the average percentage difference and MAE for the current fold on the training set\n",
    "        avg_percentage_diff_train_set = np.mean((np.abs(R_D_true_values_train_set - R_D_predicted_values_train_set) / R_D_true_values_train_set * 100))        \n",
    "        \n",
    "        # Store the average percentage difference for this fold for the training set\n",
    "        avg_percentages_diffs_train_set.append(avg_percentage_diff_train_set)\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate the overall average percentage difference across all folds for test and training set \n",
    "    avg_percentage_diff_folds = sum(avg_percentages_diffs) / n_folds \n",
    "    avg_MAE = sum(MAEs)/n_folds\n",
    "    \n",
    "    avg_percentage_diff_folds_train_set = sum(avg_percentages_diffs_train_set) / n_folds \n",
    "    avg_MAE_train_set = sum(MAEs_train_set)/n_folds\n",
    "    \n",
    "    print(f\"the MAPE for this training is : {avg_percentage_diff_folds}%\")\n",
    "    return avg_percentage_diff_folds,avg_MAE,avg_percentage_diff_folds_train_set,avg_MAE_train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ae449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss(history, skip=0, log=False):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss of a model over epochs.\n",
    "\n",
    "    This function takes the history object returned by the fit method of a \n",
    "    Keras model and plots the training and validation loss. It allows for \n",
    "    skipping initial epochs in the plot for better visualization and can \n",
    "    display the plot on a logarithmic scale.\n",
    "\n",
    "    Parameters:\n",
    "    history (History): The history object returned by the fit method of a Keras model.\n",
    "                       This object contains the loss values recorded during training.\n",
    "    skip (int, optional): Number of initial epochs to skip in the plot. Defaults to 0.\n",
    "    log (bool, optional): If True, the plot's axes will be in logarithmic scale. Defaults to False.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract training and validation loss from the history object\n",
    "    training_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "\n",
    "    # Define the range of epochs\n",
    "    epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Plotting the training and validation loss\n",
    "    plt.plot(epochs[skip:], training_loss[skip:], 'b-', label='Training loss')\n",
    "    plt.plot(epochs[skip:], validation_loss[skip:], 'r-', label='Validation loss')\n",
    "\n",
    "    # Set logarithmic scale if requested\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "\n",
    "    # Setting the title, labels, and legend\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    # Save the plot as a PDF\n",
    "    plt.savefig('train_val_loss.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23490576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_yearly_basis_select_parameters(df, is_google_trends_only=False,initial_rate=0.001,batch_size=20,epochs=80,f=NN_optimized):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a yearly basis using a fixed 80-20 train-test split.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with yearly data using a fixed 80-20 train-test split.\n",
    "    It calculates the average percentage difference between true and predicted R&D expenditure values for the test set.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data.\n",
    "        is_google_trends_only (bool, optional): Indicates whether only Google Trends data is used as input features. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        float: The average percentage difference for the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the data into training (80%) and test (20%) sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Prepare input data and target data for training\n",
    "    X_train = train_df.drop(['v', 'year'], axis=1)\n",
    "    y_train = train_df['v']\n",
    "    \n",
    "    # Prepare input data and target data for testing\n",
    "    X_test = test_df.drop(['v', 'year'], axis=1)\n",
    "    previous_R_D_values = test_df[\"v-1\"]\n",
    "    \n",
    "    if is_google_trends_only:\n",
    "        # Optionally remove the \"v-1\" column if using Google Trends data only\n",
    "        X_train = X_train.drop(axis=1, columns=[\"v-1\"])\n",
    "        X_test = X_test.drop(axis=1, columns=[\"v-1\"])\n",
    "    \n",
    "    input_shape = X_train.shape[1]\n",
    "    y_test = test_df['v']\n",
    "    \n",
    "    if f == NN_optimized :\n",
    "        \n",
    "        # Train an NLP model\n",
    "        model,history = f(X_train, y_train, input_shape,initial_rate,batch_size,epochs=epochs)\n",
    "    else : \n",
    "        # Train an NLP model\n",
    "        model= f(X_train, y_train, input_shape,initial_rate,batch_size,epochs=epochs)\n",
    "        \n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate true and predicted R&D expenditure values\n",
    "    R_D_true_values = previous_R_D_values + y_test\n",
    "    R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "    \n",
    "    # Calculate the average percentage difference for the test set\n",
    "    avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "    print(f\"The MAPE for the test set is: {avg_percentage_diff}%\")\n",
    "    \n",
    "    return avg_percentage_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e05f39",
   "metadata": {},
   "source": [
    "### Baseline  R&D ESTIMATION ON A YEARLY BASIS (GERD DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6709f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 42ms/step - loss: 0.0526 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0124 - val_loss: 0.0347 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0123 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0120 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0113 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0120 - val_loss: 0.0175 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0107 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0112 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0108 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0106 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0106 - val_loss: 0.0124 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0105 - val_loss: 0.0101 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0105 - val_loss: 0.0106 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0105 - val_loss: 0.0113 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0105 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0110 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0104 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0111 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0109 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0114 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0115 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0104 - val_loss: 0.0108 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0113 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "the MAPE for the 0th fold is : 3.7154212496692245%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 1s 35ms/step - loss: 0.0341 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0169 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0183 - val_loss: 0.0300 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0134 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0155 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0136 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0137 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0139 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0135 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0135 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0137 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0140 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0143 - val_loss: 0.0121 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0140 - val_loss: 0.0146 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0135 - val_loss: 0.0102 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0145 - val_loss: 0.0121 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0134 - val_loss: 0.0104 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0136 - val_loss: 0.0112 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0139 - val_loss: 0.0129 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0133 - val_loss: 0.0103 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0133 - val_loss: 0.0109 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0133 - val_loss: 0.0114 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0107 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0109 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0109 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0108 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0132 - val_loss: 0.0107 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0107 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0106 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0132 - val_loss: 0.0105 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.8316e-05\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "the MAPE for the 1th fold is : 2.2900654464675982%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 0.0300 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0193 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0139 - val_loss: 0.0169 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0146 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0133 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0123 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0102 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0104 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0092 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0098 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0111 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0106 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0100 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0098 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0104 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0123 - val_loss: 0.0106 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0099 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0099 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0105 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0101 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0105 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0107 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0100 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0102 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 5.5023e-05\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0104 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0102 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0103 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "the MAPE for the 2th fold is : 2.947108996221274%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 0.0160 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0087 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0096 - val_loss: 0.0174 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0092 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0130 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0077 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0109 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0107 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0108 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0108 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0109 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0106 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0104 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0108 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0104 - lr: 1.6530e-04\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0104 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0105 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0105 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "the MAPE for the 3th fold is : 3.7907907373796337%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 0.0312 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0147 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0138 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0154 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0129 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0127 - val_loss: 0.0153 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0182 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0129 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0126 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0126 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0127 - val_loss: 0.0157 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0126 - val_loss: 0.0159 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0175 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0159 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0166 - lr: 4.9659e-04\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0172 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0166 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0167 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0172 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0175 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0172 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0164 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0125 - val_loss: 0.0165 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0173 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0168 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0125 - val_loss: 0.0171 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0170 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0170 - lr: 2.4788e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "the MAPE for the 4th fold is : 1.8726661097362773%\n",
      "the MAPE for this training is : 2.923210507894802%\n",
      "MAPE on Test Set: 2.923210507894802%\n",
      "MAE on Test Set: 0.07340133372143576\n",
      "MAPE on Training Set: 2.9095370707642916%\n",
      "MAE on Training Set: 0.07286275976584164\n"
     ]
    }
   ],
   "source": [
    "merged_df_train = merged_df_R_D.drop(columns = [\"ISO\"])\n",
    "\n",
    "MAPE_test, MAE_test, MAPE_train, MAE_train = train_and_evaluate_yearly_basis(merged_df_train, 5)\n",
    "\n",
    "# Printing each value\n",
    "print(f\"MAPE on Test Set: {MAPE_test}%\")\n",
    "print(f\"MAE on Test Set: {MAE_test}\")\n",
    "print(f\"MAPE on Training Set: {MAPE_train}%\")\n",
    "print(f\"MAE on Training Set: {MAE_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc5b134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile(month):\n",
    "    \"\"\"\n",
    "    Determine the quartile (quarter) of a given month.\n",
    "\n",
    "    This function takes an integer representing a month (1 to 12) and returns the corresponding quartile based on the calendar year:\n",
    "    - 1: January to March\n",
    "    - 2: April to June\n",
    "    - 3: July to September\n",
    "    - 4: October to December\n",
    "\n",
    "    Parameters:\n",
    "        month (int): An integer representing a month (1 to 12).\n",
    "\n",
    "    Returns:\n",
    "        int: The quartile (quarter) to which the given month belongs.\n",
    "    \"\"\"\n",
    "    if 1 <= month <= 3:\n",
    "        return 1  # January to March\n",
    "    elif 4 <= month <= 6:\n",
    "        return 2  # April to June\n",
    "    elif 7 <= month <= 9:\n",
    "        return 3  # July to September\n",
    "    else:\n",
    "        return 4  # October to December\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de024e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading google trends data\n",
    "google_trends_data1 = pd.read_csv(\"google_trends_data_1\")\n",
    "google_trends_data2 = pd.read_csv(\"google_trends_data_2\")\n",
    "google_trends_data3 = pd.read_csv(\"google_trends_data_3\")\n",
    "google_trends_data4 = pd.read_csv(\"google_trends_data_4\")\n",
    "google_trends_data5 = pd.read_csv(\"google_trends_data_5\")\n",
    "google_trends_data6 = pd.read_csv(\"google_trends_data_6\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7addc80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ISO</th>\n",
       "      <th>quartile</th>\n",
       "      <th>Aerospace &amp; Defense</th>\n",
       "      <th>Chemicals Industry</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Computers &amp; Electronics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Fuel Economy</th>\n",
       "      <th>Biological Sciences</th>\n",
       "      <th>...</th>\n",
       "      <th>Jobs &amp; Education</th>\n",
       "      <th>Crime &amp; Justice</th>\n",
       "      <th>Social Services</th>\n",
       "      <th>Business News</th>\n",
       "      <th>Health News</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Social Issues &amp; Advocacy</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Ecology &amp; Environment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>85.666667</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>3</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>CAN</td>\n",
       "      <td>4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>74.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>CHE</td>\n",
       "      <td>1</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>90.666667</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2021</td>\n",
       "      <td>KOR</td>\n",
       "      <td>4</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>83.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>35.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>44.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2021</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  ISO  quartile  Aerospace & Defense  Chemicals Industry  \\\n",
       "0    2006  CAN         1            91.333333           94.333333   \n",
       "1    2006  CAN         2            74.333333           86.333333   \n",
       "2    2006  CAN         3            82.000000           81.000000   \n",
       "3    2006  CAN         4            65.333333           83.666667   \n",
       "4    2006  CHE         1            79.666667           92.000000   \n",
       "..    ...  ...       ...                  ...                 ...   \n",
       "571  2021  KOR         4            76.666667           87.666667   \n",
       "572  2021  USA         1            29.000000           69.333333   \n",
       "573  2021  USA         2            39.333333           84.333333   \n",
       "574  2021  USA         3            31.000000           76.333333   \n",
       "575  2021  USA         4            28.666667           61.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech  Computers & Electronics  Automotive Industry  \\\n",
       "0                    96.333333                92.000000            82.333333   \n",
       "1                    86.666667                76.333333            82.000000   \n",
       "2                    79.666667                72.666667            83.333333   \n",
       "3                    78.000000                80.000000            78.000000   \n",
       "4                    92.000000                89.000000            79.000000   \n",
       "..                         ...                      ...                  ...   \n",
       "571                  82.333333                92.333333            23.000000   \n",
       "572                  27.000000                30.333333            30.666667   \n",
       "573                  28.333333                33.000000            28.000000   \n",
       "574                  29.000000                33.000000            27.000000   \n",
       "575                  33.333333                29.333333            22.333333   \n",
       "\n",
       "     Fuel Economy  Biological Sciences  ...  Jobs & Education  \\\n",
       "0       19.000000            87.666667  ...         85.666667   \n",
       "1       21.666667            83.666667  ...         87.000000   \n",
       "2       58.666667            69.333333  ...         81.000000   \n",
       "3       20.000000            89.000000  ...         82.333333   \n",
       "4       48.000000            92.666667  ...         90.666667   \n",
       "..            ...                  ...  ...               ...   \n",
       "571     69.000000            83.000000  ...         89.000000   \n",
       "572     22.000000            50.333333  ...         64.000000   \n",
       "573     18.666667            55.666667  ...         68.666667   \n",
       "574     15.333333            55.666667  ...         61.000000   \n",
       "575     14.333333            44.666667  ...         52.333333   \n",
       "\n",
       "     Crime & Justice  Social Services  Business News  Health News   Politics  \\\n",
       "0          92.666667        57.333333      91.000000    15.333333  94.666667   \n",
       "1          85.000000        50.333333      78.000000    17.333333  82.000000   \n",
       "2          81.333333        47.000000      62.666667    12.000000  70.666667   \n",
       "3          89.000000        50.666667      83.666667    21.000000  84.666667   \n",
       "4          91.333333        66.333333      95.666667    26.666667  80.666667   \n",
       "..               ...              ...            ...          ...        ...   \n",
       "571        85.333333        87.000000      73.333333    56.000000  88.000000   \n",
       "572        42.666667        44.000000      28.333333     8.333333  50.333333   \n",
       "573        88.333333        74.333333      30.333333     5.000000  59.666667   \n",
       "574        70.333333        49.333333      24.333333     7.333333  51.666667   \n",
       "575        51.666667        45.000000      22.000000    40.333333  44.333333   \n",
       "\n",
       "     Social Issues & Advocacy  Real Estate  Astronomy  Ecology & Environment  \n",
       "0                   86.666667    66.666667  91.000000              86.000000  \n",
       "1                   83.333333    48.666667  79.666667              79.000000  \n",
       "2                   86.000000    39.666667  76.666667              56.000000  \n",
       "3                   68.000000    49.333333  73.333333              74.333333  \n",
       "4                   92.000000    72.666667  95.666667              65.000000  \n",
       "..                        ...          ...        ...                    ...  \n",
       "571                 84.666667    63.666667  81.333333              83.666667  \n",
       "572                 59.666667    18.666667  27.666667              35.666667  \n",
       "573                 64.666667    20.000000  28.666667              34.000000  \n",
       "574                 67.666667    19.333333  28.000000              44.666667  \n",
       "575                 54.000000    22.000000  21.666667              30.333333  \n",
       "\n",
       "[576 rows x 95 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the dataframes\n",
    "merged_data_google_trends = pd.merge(google_trends_data1, google_trends_data2, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data3, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data4, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data5, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "merged_data_google_trends = pd.merge(merged_data_google_trends, google_trends_data6, on=[\"Country\", \"year\", \"month\",\"date\"], how='inner')\n",
    "\n",
    "#Replacing each month with its corresponding quartile of the year\n",
    "merged_data_google_trends[\"month\"] = merged_data_google_trends[\"month\"].apply(lambda x : quartile(x))\n",
    "merged_data_google_trends.rename(columns={'month': 'quartile'}, inplace=True)\n",
    "merged_data_google_trends = merged_data_google_trends.drop(columns = [\"date\"])\n",
    "\n",
    "#Add a year to every row, so that google trends data match the actual predicted value of R&D expanditures\n",
    "merged_data_google_trends[\"year\"] = merged_data_google_trends[\"year\"] +1\n",
    "\n",
    "#Average over all values for months within a quartile\n",
    "merged_data_google_trends = merged_data_google_trends.groupby([\"year\",\"Country\",\"quartile\"]).mean()\n",
    "merged_data_google_trends = merged_data_google_trends.reset_index()\n",
    "\n",
    "#replace country names with appropriate ISO encoding\n",
    "replacements = {\n",
    "    'CA': 'CAN', 'CH': 'CHE', 'CN': 'CHN', 'DE': 'DEU', 'FR': 'FRA', \n",
    "    'GB': 'GBR', 'JP': 'JPN', 'KR': 'KOR', 'US': 'USA', 'RU': 'RUS',\n",
    "    'IT': 'ITA', 'AU': 'AUS', 'ES': 'ESP', 'NL': 'NLD', 'SE': 'SWE', \n",
    "    'FI': 'FIN', 'BE': 'BEL', 'TW': 'TWN', 'SG': 'SGP', 'AT': 'AUT', \n",
    "    'DK': 'DNK', 'NO': 'NOR', 'PL': 'POL', 'TR': 'TUR', 'PT': 'PRT', \n",
    "    'IE': 'IRL', 'CZ': 'CZE'\n",
    "}\n",
    "\n",
    "merged_data_google_trends['Country'] = merged_data_google_trends['Country'].replace(replacements, regex=True)\n",
    "merged_data_google_trends.rename(columns={'Country': 'ISO'}, inplace=True)\n",
    "\n",
    "merged_data_google_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e3ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_uncorrelated_features(combined_data_quartiles, merged_df_R_D, correlation_threshold=0.12):\n",
    "    \"\"\"\n",
    "    Filter features based on their correlation with a target variable.\n",
    "\n",
    "    This function filters the features in the `combined_data_quartiles` DataFrame based on their correlation with the target variable 'v'\n",
    "    from the `merged_df_R_D` DataFrame. Features with an absolute correlation coefficient greater than or equal to the specified\n",
    "    `correlation_threshold` are retained.\n",
    "\n",
    "    Parameters:\n",
    "        combined_data_quartiles (pandas.DataFrame): The DataFrame containing features for filtering.\n",
    "        merged_df_R_D (pandas.DataFrame): The DataFrame containing the target variable 'v'.\n",
    "        correlation_threshold (float, optional): The minimum absolute correlation coefficient for feature retention.\n",
    "            Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of feature names that meet the correlation threshold.\n",
    "    \"\"\"\n",
    "    R_D_values = pd.DataFrame(merged_df_R_D[[\"ISO\", \"year\", \"v\"]])\n",
    "\n",
    "    # Join features (X_train) and target (y_train) to compute correlations\n",
    "    # This ensures that the indices are aligned\n",
    "    data = pd.merge(combined_data_quartiles, R_D_values, on=['ISO', 'year'], how='inner')\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    data = data.drop(axis=1, columns=[\"ISO\", \"year\"])\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    # Get the absolute correlation values with the target variable\n",
    "    feature_correlation = correlation_matrix['v'].abs().sort_values(ascending=False)\n",
    "\n",
    "    # Drop the target variable correlation with itself\n",
    "    feature_correlation = feature_correlation.drop(labels=['v'])\n",
    "\n",
    "    # Keep only features with correlation above or equal to the threshold\n",
    "    features_kept = []\n",
    "    correlations = []\n",
    "    for feature, corr in feature_correlation.items():\n",
    "        if correlation_threshold <= corr:\n",
    "            features_kept.append(feature)\n",
    "            correlations.append(corr)\n",
    "    \n",
    "    return features_kept,correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82ec1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Web Apps & Online Tools', 'Business Finance', 'Pharmaceutical Manufacturing', 'Data Management_y', 'Venture Capital', 'Pharmaceuticals & Biotech', 'Genetics', 'Automotive Industry', 'Nanobiotechnology', 'Software Utilities', 'Oil & Gas', 'Renewable Energy', 'Renewable Energy (Subcategory of Energy & Utilities)', 'Risk Management', 'Environmental Science', 'Artificial Intelligence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web Apps &amp; Online Tools</th>\n",
       "      <th>Business Finance</th>\n",
       "      <th>Pharmaceutical Manufacturing</th>\n",
       "      <th>Data Management_y</th>\n",
       "      <th>Venture Capital</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Nanobiotechnology</th>\n",
       "      <th>Software Utilities</th>\n",
       "      <th>Oil &amp; Gas</th>\n",
       "      <th>Renewable Energy</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)</th>\n",
       "      <th>Risk Management</th>\n",
       "      <th>Environmental Science</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <th>ISO</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.666667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>55.666667</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>USA</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>52.666667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>47.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Web Apps & Online Tools  Business Finance  Pharmaceutical Manufacturing  \\\n",
       "0                  68.333333         94.666667                     94.000000   \n",
       "1                  67.666667         75.666667                     78.000000   \n",
       "2                  75.000000         82.000000                     74.000000   \n",
       "3                  67.666667         74.333333                     81.333333   \n",
       "4                  74.333333         83.333333                     83.000000   \n",
       "..                       ...               ...                           ...   \n",
       "571                55.666667         59.000000                     57.000000   \n",
       "572                55.333333         65.333333                     61.666667   \n",
       "573                57.000000         71.000000                     52.666667   \n",
       "574                52.666667         75.000000                     55.000000   \n",
       "575                47.333333         63.000000                     51.000000   \n",
       "\n",
       "     Data Management_y  Venture Capital  Pharmaceuticals & Biotech   Genetics  \\\n",
       "0            85.000000        51.666667                  96.333333  86.333333   \n",
       "1            75.000000        46.333333                  86.666667  70.000000   \n",
       "2            66.333333        35.000000                  79.666667  64.333333   \n",
       "3            78.333333        46.000000                  78.000000  85.000000   \n",
       "4            95.000000        44.666667                  83.333333  84.000000   \n",
       "..                 ...              ...                        ...        ...   \n",
       "571          51.666667        18.333333                  24.333333  34.666667   \n",
       "572          53.000000        18.000000                  27.000000  37.000000   \n",
       "573          54.000000        15.000000                  28.333333  31.000000   \n",
       "574          53.000000        15.000000                  29.000000  27.333333   \n",
       "575          48.333333        15.000000                  33.333333  29.333333   \n",
       "\n",
       "     Automotive Industry  Nanobiotechnology  Software Utilities  Oil & Gas  \\\n",
       "0              82.333333          97.333333           95.000000  92.333333   \n",
       "1              82.000000          83.000000           78.000000  88.333333   \n",
       "2              83.333333          74.666667           77.333333  76.000000   \n",
       "3              78.000000          81.000000           82.333333  80.333333   \n",
       "4              77.333333          77.000000           76.666667  82.666667   \n",
       "..                   ...                ...                 ...        ...   \n",
       "571            41.333333          33.333333           51.666667  37.333333   \n",
       "572            30.666667          34.333333           53.666667  36.000000   \n",
       "573            28.000000          41.666667           54.666667  39.666667   \n",
       "574            27.000000          39.333333           53.333333  36.000000   \n",
       "575            22.333333          34.000000           42.666667  34.333333   \n",
       "\n",
       "     Renewable Energy  Renewable Energy (Subcategory of Energy & Utilities)  \\\n",
       "0           92.000000                                          92.000000      \n",
       "1           87.000000                                          87.000000      \n",
       "2           76.000000                                          75.666667      \n",
       "3           80.000000                                          80.000000      \n",
       "4           83.333333                                          83.000000      \n",
       "..                ...                                                ...      \n",
       "571         36.666667                                          36.333333      \n",
       "572         36.000000                                          36.000000      \n",
       "573         39.666667                                          39.666667      \n",
       "574         36.000000                                          35.666667      \n",
       "575         34.333333                                          36.000000      \n",
       "\n",
       "     Risk Management  Environmental Science  Artificial Intelligence  ISO  \\\n",
       "0          93.333333              57.000000                93.666667  CAN   \n",
       "1          81.666667              44.000000                74.333333  CAN   \n",
       "2          69.000000              37.333333                65.000000  CAN   \n",
       "3          73.333333              54.000000                81.333333  CAN   \n",
       "4          79.333333              51.666667                75.333333  CAN   \n",
       "..               ...                    ...                      ...  ...   \n",
       "571        31.000000              47.000000                48.333333  USA   \n",
       "572        31.000000              49.666667                46.000000  USA   \n",
       "573        31.000000              57.333333                48.000000  USA   \n",
       "574        29.333333              57.000000                45.000000  USA   \n",
       "575        25.000000              31.000000                38.333333  USA   \n",
       "\n",
       "     year  \n",
       "0    2006  \n",
       "1    2006  \n",
       "2    2006  \n",
       "3    2006  \n",
       "4    2007  \n",
       "..    ...  \n",
       "571  2020  \n",
       "572  2021  \n",
       "573  2021  \n",
       "574  2021  \n",
       "575  2021  \n",
       "\n",
       "[576 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine data of quartiles in order to use it for a yearly prediction basis\n",
    "combined_data_quartiles = merged_data_google_trends.groupby(['ISO', 'year', 'quartile']).mean()\n",
    "combined_data_quartiles = combined_data_quartiles.reset_index()\n",
    "combined_data_quartiles = combined_data_quartiles.drop(columns=[\"quartile\"])\n",
    "\n",
    "#Keeping this copy for feature selection afterwards\n",
    "full_combined_data_quartiles = combined_data_quartiles.copy()\n",
    "\n",
    "#Keep only features with a minimum threshold of correlation with the output\n",
    "features_kept,correlations = filter_uncorrelated_features(combined_data_quartiles,merged_df_R_D,correlation_threshold=0.12)\n",
    "print(features_kept)\n",
    "\n",
    "\n",
    "combined_data_quartiles = combined_data_quartiles.loc[:,features_kept+[\"ISO\",\"year\"]]\n",
    "combined_data_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8881a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the lists into a list of tuples and sort by the absolute value of correlations\n",
    "combined = list(zip(features_kept, correlations))\n",
    "combined_sorted = sorted(combined, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = combined_sorted[:10]\n",
    "\n",
    "# Unzip the features and their corresponding correlations\n",
    "top_features, top_correlations = zip(*top_10_features)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.barplot(x=list(top_correlations), y=list(top_features), hue=list(top_features), palette=\"vlag\", legend=False)\n",
    "plt.title('Top 10 Correlated Categories')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Categories')\n",
    "plt.savefig('correlations.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8f8e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>v-1</th>\n",
       "      <th>v</th>\n",
       "      <th>Web Apps &amp; Online Tools</th>\n",
       "      <th>Business Finance</th>\n",
       "      <th>Pharmaceutical Manufacturing</th>\n",
       "      <th>Data Management_y</th>\n",
       "      <th>Venture Capital</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>Automotive Industry</th>\n",
       "      <th>Nanobiotechnology</th>\n",
       "      <th>Software Utilities</th>\n",
       "      <th>Oil &amp; Gas</th>\n",
       "      <th>Renewable Energy</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)</th>\n",
       "      <th>Risk Management</th>\n",
       "      <th>Environmental Science</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>93.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>74.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>81.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.039421</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>75.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.170487</td>\n",
       "      <td>0.297284</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year       v-1         v  Web Apps & Online Tools  Business Finance  \\\n",
       "0    2006  1.971243 -0.028245                68.333333         94.666667   \n",
       "1    2006  1.971243 -0.028245                67.666667         75.666667   \n",
       "2    2006  1.971243 -0.028245                75.000000         82.000000   \n",
       "3    2006  1.971243 -0.028245                67.666667         74.333333   \n",
       "4    2007  1.942999 -0.039421                74.333333         83.333333   \n",
       "..    ...       ...       ...                      ...               ...   \n",
       "507  2020  3.170487  0.297284                55.666667         59.000000   \n",
       "508  2021  3.467771 -0.010725                55.333333         65.333333   \n",
       "509  2021  3.467771 -0.010725                57.000000         71.000000   \n",
       "510  2021  3.467771 -0.010725                52.666667         75.000000   \n",
       "511  2021  3.467771 -0.010725                47.333333         63.000000   \n",
       "\n",
       "     Pharmaceutical Manufacturing  Data Management_y  Venture Capital  \\\n",
       "0                       94.000000          85.000000        51.666667   \n",
       "1                       78.000000          75.000000        46.333333   \n",
       "2                       74.000000          66.333333        35.000000   \n",
       "3                       81.333333          78.333333        46.000000   \n",
       "4                       83.000000          95.000000        44.666667   \n",
       "..                            ...                ...              ...   \n",
       "507                     57.000000          51.666667        18.333333   \n",
       "508                     61.666667          53.000000        18.000000   \n",
       "509                     52.666667          54.000000        15.000000   \n",
       "510                     55.000000          53.000000        15.000000   \n",
       "511                     51.000000          48.333333        15.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech   Genetics  Automotive Industry  \\\n",
       "0                    96.333333  86.333333            82.333333   \n",
       "1                    86.666667  70.000000            82.000000   \n",
       "2                    79.666667  64.333333            83.333333   \n",
       "3                    78.000000  85.000000            78.000000   \n",
       "4                    83.333333  84.000000            77.333333   \n",
       "..                         ...        ...                  ...   \n",
       "507                  24.333333  34.666667            41.333333   \n",
       "508                  27.000000  37.000000            30.666667   \n",
       "509                  28.333333  31.000000            28.000000   \n",
       "510                  29.000000  27.333333            27.000000   \n",
       "511                  33.333333  29.333333            22.333333   \n",
       "\n",
       "     Nanobiotechnology  Software Utilities  Oil & Gas  Renewable Energy  \\\n",
       "0            97.333333           95.000000  92.333333         92.000000   \n",
       "1            83.000000           78.000000  88.333333         87.000000   \n",
       "2            74.666667           77.333333  76.000000         76.000000   \n",
       "3            81.000000           82.333333  80.333333         80.000000   \n",
       "4            77.000000           76.666667  82.666667         83.333333   \n",
       "..                 ...                 ...        ...               ...   \n",
       "507          33.333333           51.666667  37.333333         36.666667   \n",
       "508          34.333333           53.666667  36.000000         36.000000   \n",
       "509          41.666667           54.666667  39.666667         39.666667   \n",
       "510          39.333333           53.333333  36.000000         36.000000   \n",
       "511          34.000000           42.666667  34.333333         34.333333   \n",
       "\n",
       "     Renewable Energy (Subcategory of Energy & Utilities)  Risk Management  \\\n",
       "0                                            92.000000           93.333333   \n",
       "1                                            87.000000           81.666667   \n",
       "2                                            75.666667           69.000000   \n",
       "3                                            80.000000           73.333333   \n",
       "4                                            83.000000           79.333333   \n",
       "..                                                 ...                 ...   \n",
       "507                                          36.333333           31.000000   \n",
       "508                                          36.000000           31.000000   \n",
       "509                                          39.666667           31.000000   \n",
       "510                                          35.666667           29.333333   \n",
       "511                                          36.000000           25.000000   \n",
       "\n",
       "     Environmental Science  Artificial Intelligence  \n",
       "0                57.000000                93.666667  \n",
       "1                44.000000                74.333333  \n",
       "2                37.333333                65.000000  \n",
       "3                54.000000                81.333333  \n",
       "4                51.666667                75.333333  \n",
       "..                     ...                      ...  \n",
       "507              47.000000                48.333333  \n",
       "508              49.666667                46.000000  \n",
       "509              57.333333                48.000000  \n",
       "510              57.000000                45.000000  \n",
       "511              31.000000                38.333333  \n",
       "\n",
       "[512 rows x 19 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging Google Trends data and R&D expenditure values\n",
    "# In this merge, 'v-2' corresponds to the R&D expenditure value from 2 years ago,\n",
    "# 'v-1' corresponds to the R&D expenditure of the previous year,\n",
    "# and 'v' represents the difference we aim to predict between the current year\n",
    "# and the previous year's R&D expenditure value.\n",
    "\n",
    "google_trends_data = pd.merge(first_merged, combined_data_quartiles, on=['ISO', 'year'], how='inner')\n",
    "merged_data = google_trends_data.copy()\n",
    "google_trends_data = google_trends_data.drop(axis =1 ,columns=[\"ISO\",\"v-2\"])\n",
    "google_trends_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9e577",
   "metadata": {},
   "source": [
    "### R&D ESTIMATION ON A YEARLY BASIS (GOOGLE TRENDS DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1785a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 21ms/step - loss: 14.7252 - val_loss: 0.0319 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0559 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0352 - val_loss: 0.1431 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0385 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0309 - val_loss: 0.0798 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.1106 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0154 - val_loss: 0.0132 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0127 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0153 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0129 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0192 - val_loss: 0.0291 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0241 - val_loss: 0.0844 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0284 - val_loss: 0.0655 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0185 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0470 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0196 - val_loss: 0.1003 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0327 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0277 - val_loss: 0.2320 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0615 - val_loss: 0.0365 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0148 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0088 - val_loss: 0.0161 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0081 - val_loss: 0.0146 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0096 - val_loss: 0.0108 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0076 - val_loss: 0.0116 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0105 - val_loss: 0.0122 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0067 - val_loss: 0.0172 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0068 - val_loss: 0.0120 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0068 - val_loss: 0.0121 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0067 - val_loss: 0.0123 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0068 - val_loss: 0.0123 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0064 - val_loss: 0.0111 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0105 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0111 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0058 - val_loss: 0.0141 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0076 - val_loss: 0.0154 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0063 - val_loss: 0.0132 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0061 - val_loss: 0.0111 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0113 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0110 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0132 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0111 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0119 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0121 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0111 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0121 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0113 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0109 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0113 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0112 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0117 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0110 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0109 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0112 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0113 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0111 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0111 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0111 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0115 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0111 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0110 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0046 - val_loss: 0.0112 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0110 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0113 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0111 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0110 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0113 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0045 - val_loss: 0.0111 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "the MAPE for the 0th fold is : 2.5533513440210758%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 22ms/step - loss: 10.3853 - val_loss: 0.0141 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0220 - val_loss: 0.0435 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0746 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0214 - val_loss: 0.0456 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0600 - val_loss: 0.1809 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.3640 - val_loss: 0.3022 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0688 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0158 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0099 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0316 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0179 - val_loss: 0.0203 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0128 - val_loss: 0.0309 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0128 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0183 - val_loss: 0.0337 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0228 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0091 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0104 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0155 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0089 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0111 - val_loss: 0.0093 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0084 - val_loss: 0.0159 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0120 - val_loss: 0.0171 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0083 - val_loss: 0.0135 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0099 - val_loss: 0.0171 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0088 - val_loss: 0.0104 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0076 - val_loss: 0.0122 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0081 - val_loss: 0.0115 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0071 - val_loss: 0.0118 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0066 - val_loss: 0.0102 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0084 - val_loss: 0.0109 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0069 - val_loss: 0.0111 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0061 - val_loss: 0.0107 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0059 - val_loss: 0.0127 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0063 - val_loss: 0.0125 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 0.0110 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0060 - val_loss: 0.0109 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0116 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0062 - val_loss: 0.0111 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 0.0108 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 0.0107 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0057 - val_loss: 0.0106 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0110 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0109 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0062 - val_loss: 0.0109 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0107 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0117 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0114 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0107 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0111 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0110 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0111 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0109 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0111 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0112 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0110 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0112 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0116 - lr: 1.8316e-05\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0112 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0116 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0110 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0111 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0111 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0111 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0111 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0051 - val_loss: 0.0111 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0113 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "the MAPE for the 1th fold is : 2.6966982031864024%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 24ms/step - loss: 20.1462 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0592 - val_loss: 0.0288 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0531 - val_loss: 0.0471 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0219 - val_loss: 0.0272 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0783 - val_loss: 0.1806 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0675 - val_loss: 0.0785 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.1519 - val_loss: 0.1326 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0614 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0224 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0107 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0118 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0282 - val_loss: 0.0378 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0120 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0130 - val_loss: 0.0186 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0152 - val_loss: 0.0521 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0336 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0547 - val_loss: 0.2384 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0311 - val_loss: 0.0183 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0134 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0100 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0088 - val_loss: 0.0200 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0106 - val_loss: 0.0196 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0111 - val_loss: 0.0182 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0088 - val_loss: 0.0168 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0086 - val_loss: 0.0114 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0113 - val_loss: 0.0118 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0102 - val_loss: 0.0117 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0079 - val_loss: 0.0110 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0071 - val_loss: 0.0114 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0073 - val_loss: 0.0103 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0121 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0071 - val_loss: 0.0119 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0060 - val_loss: 0.0108 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0068 - val_loss: 0.0169 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0064 - val_loss: 0.0115 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0059 - val_loss: 0.0160 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0066 - val_loss: 0.0148 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0076 - val_loss: 0.0121 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0057 - val_loss: 0.0110 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0112 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0125 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0114 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0059 - val_loss: 0.0129 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0126 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0058 - val_loss: 0.0108 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0057 - val_loss: 0.0108 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0117 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0123 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0115 - lr: 5.5023e-05\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0128 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0119 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0142 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0112 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0132 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0114 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0136 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0127 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0125 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0053 - val_loss: 0.0112 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0111 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0126 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0123 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0121 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0120 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0128 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0121 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0122 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0122 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0123 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0118 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0122 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0122 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0050 - val_loss: 0.0121 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0123 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0125 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0119 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0120 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0122 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0119 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0050 - val_loss: 0.0122 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "the MAPE for the 2th fold is : 2.0730326849879246%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 24ms/step - loss: 14.6330 - val_loss: 0.3640 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0700 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0327 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0273 - val_loss: 0.0522 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.1792 - val_loss: 0.2265 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0470 - val_loss: 0.0199 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0321 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0147 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0588 - val_loss: 0.4493 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.1815 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0362 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0125 - val_loss: 0.0169 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0103 - val_loss: 0.0159 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0217 - val_loss: 0.0456 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0269 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0345 - val_loss: 0.0372 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0295 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0131 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0109 - val_loss: 0.0198 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0151 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0104 - val_loss: 0.0122 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0116 - val_loss: 0.0145 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0090 - val_loss: 0.0222 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0093 - val_loss: 0.0429 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0126 - val_loss: 0.0098 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0086 - val_loss: 0.0124 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0083 - val_loss: 0.0111 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0071 - val_loss: 0.0135 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0094 - val_loss: 0.0119 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0095 - val_loss: 0.0195 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0085 - val_loss: 0.0164 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0074 - val_loss: 0.0143 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0064 - val_loss: 0.0108 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0070 - val_loss: 0.0106 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0073 - val_loss: 0.0111 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0065 - val_loss: 0.0135 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0105 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0108 - lr: 1.6530e-04\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0065 - val_loss: 0.0109 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0060 - val_loss: 0.0121 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0109 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0112 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0059 - val_loss: 0.0109 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0116 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0062 - val_loss: 0.0106 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0117 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0059 - val_loss: 0.0120 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0058 - val_loss: 0.0112 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0106 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0057 - val_loss: 0.0123 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0114 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0108 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0057 - val_loss: 0.0111 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0115 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0108 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0108 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0106 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0122 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0060 - val_loss: 0.0106 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0113 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0055 - val_loss: 0.0110 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0056 - val_loss: 0.0115 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0110 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0107 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0112 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0113 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0054 - val_loss: 0.0108 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0109 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0108 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0112 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0055 - val_loss: 0.0110 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0110 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0053 - val_loss: 0.0108 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0110 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0110 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0109 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0107 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0110 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0053 - val_loss: 0.0109 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0109 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "the MAPE for the 3th fold is : 2.5129228506803223%\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 22ms/step - loss: 27.1893 - val_loss: 0.3221 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0346 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0136 - val_loss: 0.0674 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0909 - val_loss: 0.0285 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0187 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0127 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0200 - val_loss: 0.0296 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0141 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0583 - val_loss: 0.0174 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0335 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0401 - val_loss: 0.0199 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1882 - val_loss: 0.3032 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0500 - val_loss: 0.0267 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0147 - val_loss: 0.0270 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0089 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0249 - val_loss: 0.1619 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0671 - val_loss: 0.0574 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0307 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0077 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0087 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0154 - val_loss: 0.0149 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0087 - val_loss: 0.0226 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0090 - val_loss: 0.0117 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0107 - val_loss: 0.0112 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0095 - val_loss: 0.0106 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0096 - val_loss: 0.0282 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0092 - val_loss: 0.0221 - lr: 4.9659e-04\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0073 - val_loss: 0.0167 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0070 - val_loss: 0.0098 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0061 - val_loss: 0.0100 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0061 - val_loss: 0.0107 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0072 - val_loss: 0.0097 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0066 - val_loss: 0.0105 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0059 - val_loss: 0.0099 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0059 - val_loss: 0.0100 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0060 - val_loss: 0.0145 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0063 - val_loss: 0.0147 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0063 - val_loss: 0.0095 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0061 - val_loss: 0.0094 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0057 - val_loss: 0.0113 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0102 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0102 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0117 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0121 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0098 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0099 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0098 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0050 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0097 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0049 - val_loss: 0.0110 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0048 - val_loss: 0.0107 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0098 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0049 - val_loss: 0.0099 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0103 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0098 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0048 - val_loss: 0.0101 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0099 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0105 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0108 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0048 - val_loss: 0.0104 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0103 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0047 - val_loss: 0.0109 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0101 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0048 - val_loss: 0.0101 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0048 - val_loss: 0.0108 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0101 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0047 - val_loss: 0.0103 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0100 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0104 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0106 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0103 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0102 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.0047 - val_loss: 0.0103 - lr: 2.4788e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "the MAPE for the 4th fold is : 2.8289599753999717%\n",
      "the MAPE for this training is : 2.5329930116551393%\n",
      "MAPE on Test Set: 2.5329930116551393%\n",
      "MAE on Test Set: 0.0643895811520075\n",
      "MAPE on Training Set: 2.139834564801866%\n",
      "MAE on Training Set: 0.05502940079757566\n"
     ]
    }
   ],
   "source": [
    "MAPE_test, MAE_test, MAPE_train, MAE_train = train_and_evaluate_yearly_basis(google_trends_data,5,True)\n",
    "\n",
    "# Printing each value\n",
    "print(f\"MAPE on Test Set: {MAPE_test}%\")\n",
    "print(f\"MAE on Test Set: {MAE_test}\")\n",
    "print(f\"MAPE on Training Set: {MAPE_train}%\")\n",
    "print(f\"MAE on Training Set: {MAE_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c8b5",
   "metadata": {},
   "source": [
    "## Practial exemple : Predicting R&D expenditures from 2017 to 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92169b",
   "metadata": {},
   "source": [
    "For this example, we consider the training sample to be the R&D expanditures from 2005  up to 2018 , the test samples will be R&D expanditures from 2018 to 2020 included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f669292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "43/43 [==============================] - 2s 21ms/step - loss: 25.3496 - val_loss: 0.6660 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1128 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0291 - val_loss: 0.0739 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1363 - val_loss: 0.0322 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1536 - val_loss: 0.2600 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.2179 - val_loss: 0.0196 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0277 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0417 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0188 - val_loss: 0.0203 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0241 - val_loss: 0.0761 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0155 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0441 - val_loss: 0.1947 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0538 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0131 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0121 - val_loss: 0.0350 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.0502 - val_loss: 0.0419 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0217 - val_loss: 0.0318 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0219 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0133 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.0105 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0093 - val_loss: 0.0098 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0080 - val_loss: 0.0114 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.0084 - val_loss: 0.0182 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.0088 - val_loss: 0.0110 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0092 - val_loss: 0.0142 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0081 - val_loss: 0.0103 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0078 - val_loss: 0.0129 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0086 - val_loss: 0.0129 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0064 - val_loss: 0.0114 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0081 - val_loss: 0.0163 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0110 - val_loss: 0.0101 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0061 - val_loss: 0.0144 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0061 - val_loss: 0.0102 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0062 - val_loss: 0.0172 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0069 - val_loss: 0.0171 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0067 - val_loss: 0.0113 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0104 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0062 - val_loss: 0.0127 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0061 - val_loss: 0.0110 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0063 - val_loss: 0.0102 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0104 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0066 - val_loss: 0.0147 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0107 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0056 - val_loss: 0.0101 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0123 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0057 - val_loss: 0.0110 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0055 - val_loss: 0.0103 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0052 - val_loss: 0.0101 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0100 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0053 - val_loss: 0.0104 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0105 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0112 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0106 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0103 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0101 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0114 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0101 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0107 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0103 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0104 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0102 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0105 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0108 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0112 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0108 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0050 - val_loss: 0.0109 - lr: 2.4788e-06\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "The average MAPE for the test set is : 3.5558157287497263%\n"
     ]
    }
   ],
   "source": [
    "X_train = google_trends_data[google_trends_data[\"year\"] <= 2018 ]\n",
    "X_test = google_trends_data[google_trends_data[\"year\"] >=2019]\n",
    "y_test = X_test['v']\n",
    "y_train = X_train['v']\n",
    "previous_R_D_values = X_test[\"v-1\"]\n",
    "X_train = X_train.drop(axis=1, columns=[\"v-1\",\"v\",\"year\"])\n",
    "X_test = X_test.drop(axis=1, columns=[\"v-1\",\"v\",\"year\"])\n",
    "input_shape = X_train.shape[1]\n",
    "    \n",
    "# Train an NLP model\n",
    "model,_ = NN_optimized(X_train, y_train, input_shape,0.001,8,epochs=80)\n",
    "    \n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "    \n",
    "# Calculate true and predicted R&D expenditure values\n",
    "R_D_true_values = previous_R_D_values + y_test\n",
    "R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "    \n",
    "# Calculate the average percentage difference for the test set\n",
    "avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "print(f\"The average MAPE for the test set is : {avg_percentage_diff}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a07050",
   "metadata": {},
   "source": [
    "###  Difference of performance of the model between 2 countries : GREAT BRITAIN and GERMANY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04d369",
   "metadata": {},
   "source": [
    "Even if the model is trained using data from both countries, we will evaluate its performance on the same dataset to determine whether there is any bias in its performance towards either of the two countries. The objective here is to assess if the model demonstrates higher effectiveness or accuracy when dealing with data from one country over the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe7cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "52/52 [==============================] - 2s 20ms/step - loss: 8.6918 - val_loss: 0.4459 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.1080 - val_loss: 0.0205 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0219 - val_loss: 0.0206 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0161 - val_loss: 0.0130 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0216 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0385 - val_loss: 0.0630 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0438 - val_loss: 0.0434 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0452 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0299 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0678 - val_loss: 0.0423 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0145 - val_loss: 0.0669 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0316 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0106 - val_loss: 0.0415 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0274 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0110 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0144 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0106 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0098 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0119 - val_loss: 0.0280 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0382 - val_loss: 0.0249 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0155 - val_loss: 0.0263 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0113 - val_loss: 0.0102 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0097 - val_loss: 0.0100 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0085 - val_loss: 0.0234 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0088 - val_loss: 0.0121 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0112 - val_loss: 0.0105 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0081 - val_loss: 0.0136 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0073 - val_loss: 0.0108 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0084 - val_loss: 0.0118 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0071 - val_loss: 0.0105 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0075 - val_loss: 0.0109 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0069 - val_loss: 0.0114 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0082 - val_loss: 0.0120 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0068 - val_loss: 0.0110 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0059 - val_loss: 0.0125 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0073 - val_loss: 0.0101 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0057 - val_loss: 0.0108 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 0.0108 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0057 - val_loss: 0.0119 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 0.0103 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0059 - val_loss: 0.0105 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0068 - val_loss: 0.0105 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0058 - val_loss: 0.0113 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0116 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.0055 - val_loss: 0.0105 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.0063 - val_loss: 0.0129 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0059 - val_loss: 0.0107 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0057 - val_loss: 0.0108 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0119 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0055 - val_loss: 0.0110 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0103 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0106 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0109 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0112 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.0053 - val_loss: 0.0106 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.0053 - val_loss: 0.0120 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0053 - val_loss: 0.0110 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0103 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0053 - val_loss: 0.0110 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0113 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0107 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0110 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0106 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0051 - val_loss: 0.0113 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0109 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0106 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0112 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0109 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0109 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0108 - lr: 2.4788e-06\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "The MAPE for  GERMANY R&D expanditures is: 1.4719631127391737%\n"
     ]
    }
   ],
   "source": [
    "#Model perfomance on USA R&D expanditures\n",
    "X_train = merged_data\n",
    "X_test = X_train[X_train[\"ISO\"] == \"DEU\"]\n",
    "y_test = X_test['v']\n",
    "y_train = X_train['v']\n",
    "previous_R_D_values = X_test[\"v-1\"]\n",
    "X_train = X_train.drop(axis=1, columns=[\"v-1\",\"v\",\"year\",\"ISO\"])\n",
    "X_test = X_test.drop(axis=1, columns=[\"v-1\",\"v\",\"year\",\"ISO\"])\n",
    "input_shape = X_train.shape[1]\n",
    "    \n",
    "# Train an NLP model\n",
    "model,_ = NN_optimized(X_train, y_train, input_shape,0.001,8,epochs=80)\n",
    "    \n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "    \n",
    "# Calculate true and predicted R&D expenditure values\n",
    "R_D_true_values = previous_R_D_values + y_test\n",
    "R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "    \n",
    "# Calculate the average percentage difference for the test set\n",
    "avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "print(f\"The MAPE for  GERMANY R&D expanditures is: {avg_percentage_diff}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df4e75",
   "metadata": {},
   "source": [
    "Now we evaluate the performance on the model on GBR R&D expanditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33989461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "52/52 [==============================] - 3s 23ms/step - loss: 14.6877 - val_loss: 0.1175 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2364 - val_loss: 0.1159 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0835 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0193 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0150 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0126 - val_loss: 0.0186 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0650 - val_loss: 0.0756 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0314 - val_loss: 0.0852 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0345 - val_loss: 0.0345 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0246 - val_loss: 0.0202 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0205 - val_loss: 0.1515 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0198 - val_loss: 0.1702 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0445 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0604 - val_loss: 0.0335 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0312 - val_loss: 0.2034 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0304 - val_loss: 0.0397 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0101 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0094 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0093 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0111 - val_loss: 0.0285 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.0167 - val_loss: 0.0101 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.0089 - val_loss: 0.0098 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.0099 - val_loss: 0.0135 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0081 - val_loss: 0.0229 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0094 - val_loss: 0.0133 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0108 - val_loss: 0.0097 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0081 - val_loss: 0.0107 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0074 - val_loss: 0.0106 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0083 - val_loss: 0.0114 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0068 - val_loss: 0.0107 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0073 - val_loss: 0.0099 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0062 - val_loss: 0.0123 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0081 - val_loss: 0.0110 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0067 - val_loss: 0.0103 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0057 - val_loss: 0.0124 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0073 - val_loss: 0.0107 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0057 - val_loss: 0.0113 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0107 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0115 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0104 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0108 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0066 - val_loss: 0.0111 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0058 - val_loss: 0.0111 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0055 - val_loss: 0.0113 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0054 - val_loss: 0.0109 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0135 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0104 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0109 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0111 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0107 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0103 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0054 - val_loss: 0.0103 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0107 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0051 - val_loss: 0.0110 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0051 - val_loss: 0.0104 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0116 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0108 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0103 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0107 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0050 - val_loss: 0.0111 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0108 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0106 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0050 - val_loss: 0.0105 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0112 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0049 - val_loss: 0.0108 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0108 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0050 - val_loss: 0.0108 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0108 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0106 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0105 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0050 - val_loss: 0.0110 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.0050 - val_loss: 0.0108 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0108 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0107 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0107 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.0049 - val_loss: 0.0108 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 0.0107 - lr: 2.4788e-06\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "The MAPE for GREAT BRITAIN R&D expanditures is: 4.245154626901841%\n"
     ]
    }
   ],
   "source": [
    "#Model perfomance on GBR R&D expanditures\n",
    "X_train = merged_data\n",
    "X_test = X_train[X_train[\"ISO\"] == \"GBR\"]\n",
    "y_test = X_test['v']\n",
    "y_train = X_train['v']\n",
    "previous_R_D_values = X_test[\"v-1\"]\n",
    "X_train = X_train.drop(axis=1, columns=[\"v-1\",\"v\",\"year\",\"ISO\"])\n",
    "X_test = X_test.drop(axis=1, columns=[\"v-1\",\"v\",\"year\",\"ISO\"])\n",
    "input_shape = X_train.shape[1]\n",
    "    \n",
    "# Train an NLP model\n",
    "model,_ = NN_optimized(X_train, y_train, input_shape,0.001,8,epochs=80)\n",
    "    \n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "    \n",
    "# Calculate true and predicted R&D expenditure values\n",
    "R_D_true_values = previous_R_D_values + y_test\n",
    "R_D_predicted_values = previous_R_D_values + y_pred.flatten()\n",
    "    \n",
    "# Calculate the average percentage difference for the test set\n",
    "avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "print(f\"The MAPE for GREAT BRITAIN R&D expanditures is: {avg_percentage_diff}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12b49f",
   "metadata": {},
   "source": [
    "## Choices of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85006b0c",
   "metadata": {},
   "source": [
    "### 1 -  NN width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c70801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for NN_width 64\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 40.0648 - val_loss: 20.3646 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.0255 - val_loss: 17.9987 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 10.2578 - val_loss: 9.9796 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8386 - val_loss: 8.8822 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.2353 - val_loss: 6.3471 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.9808 - val_loss: 5.4076 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.1339 - val_loss: 4.7702 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.6471 - val_loss: 4.2789 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.0507 - val_loss: 3.6813 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.2382 - val_loss: 3.3580 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.7601 - val_loss: 2.8853 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.1157 - val_loss: 2.8402 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.1351 - val_loss: 2.7049 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8891 - val_loss: 2.4999 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9866 - val_loss: 2.1561 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5991 - val_loss: 2.2402 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.1315 - val_loss: 2.0462 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8494 - val_loss: 1.8460 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 2.6358 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4064 - val_loss: 1.8693 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2734 - val_loss: 1.5508 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0541 - val_loss: 1.4208 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0069 - val_loss: 1.3857 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9869 - val_loss: 1.5183 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9936 - val_loss: 1.3585 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9017 - val_loss: 1.5452 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8915 - val_loss: 1.3218 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.8739 - val_loss: 1.2799 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8562 - val_loss: 1.2774 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7955 - val_loss: 1.3336 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8684 - val_loss: 1.2170 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7760 - val_loss: 1.1581 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7549 - val_loss: 1.1718 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7467 - val_loss: 1.1546 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7556 - val_loss: 1.2844 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7951 - val_loss: 1.1328 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7218 - val_loss: 1.0984 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7533 - val_loss: 1.1034 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7276 - val_loss: 1.1089 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7185 - val_loss: 1.1722 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7165 - val_loss: 1.1125 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6800 - val_loss: 1.0611 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6836 - val_loss: 1.0649 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6705 - val_loss: 1.0865 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6702 - val_loss: 1.0511 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6628 - val_loss: 1.0863 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6658 - val_loss: 1.0396 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 1.0646 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6674 - val_loss: 1.0276 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6943 - val_loss: 1.0597 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6659 - val_loss: 1.0221 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6631 - val_loss: 1.0322 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6491 - val_loss: 1.0281 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6404 - val_loss: 1.0170 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6383 - val_loss: 1.0151 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6417 - val_loss: 1.0159 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 1.0101 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6365 - val_loss: 1.0111 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6395 - val_loss: 1.0192 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6333 - val_loss: 1.0054 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6312 - val_loss: 1.0069 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 1.0051 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 1.0040 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6287 - val_loss: 1.0038 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6304 - val_loss: 1.0056 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6285 - val_loss: 1.0082 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6281 - val_loss: 1.0031 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.9997 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 1.0010 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 1.0037 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 1.0030 - lr: 6.0967e-06\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6264 - val_loss: 0.9994 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6259 - val_loss: 1.0011 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 0.9990 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6246 - val_loss: 0.9985 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.9982 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 0.9976 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.9987 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 1.0003 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6239 - val_loss: 0.9999 - lr: 2.4788e-06\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000244C3BA4360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "The MAPE for the test set is: 29.363292330527898%\n",
      "Evaluating for NN_width 128\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 13.4264 - val_loss: 5.5163 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.6372 - val_loss: 3.5465 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9605 - val_loss: 1.4226 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2115 - val_loss: 0.9039 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8323 - val_loss: 0.5291 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5795 - val_loss: 0.4516 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5427 - val_loss: 0.4234 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4454 - val_loss: 0.4349 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4604 - val_loss: 0.3282 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5653 - val_loss: 0.4253 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4288 - val_loss: 0.9729 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5789 - val_loss: 0.4247 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3371 - val_loss: 0.4522 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3495 - val_loss: 0.2610 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3059 - val_loss: 0.2726 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3991 - val_loss: 0.2510 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3227 - val_loss: 0.5686 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3139 - val_loss: 0.3988 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2447 - val_loss: 0.3061 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3352 - val_loss: 0.2878 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 0.4928 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2381 - val_loss: 0.2968 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2352 - val_loss: 0.2027 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1654 - val_loss: 0.1966 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1411 - val_loss: 0.1876 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1509 - val_loss: 0.1950 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1333 - val_loss: 0.1702 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1382 - val_loss: 0.3245 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1636 - val_loss: 0.1703 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1346 - val_loss: 0.1741 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1249 - val_loss: 0.1820 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1112 - val_loss: 0.1788 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1124 - val_loss: 0.1882 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1191 - val_loss: 0.1596 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1072 - val_loss: 0.1595 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1295 - val_loss: 0.1725 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1088 - val_loss: 0.1575 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.1685 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1057 - val_loss: 0.1709 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1032 - val_loss: 0.1539 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1076 - val_loss: 0.1552 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1002 - val_loss: 0.1542 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1005 - val_loss: 0.1545 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0993 - val_loss: 0.1562 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1024 - val_loss: 0.1611 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1010 - val_loss: 0.1529 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0991 - val_loss: 0.1573 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1017 - val_loss: 0.1560 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0988 - val_loss: 0.1577 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0993 - val_loss: 0.1531 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1511 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0980 - val_loss: 0.1549 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0994 - val_loss: 0.1571 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0958 - val_loss: 0.1506 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0959 - val_loss: 0.1534 - lr: 3.0197e-05\n",
      "Epoch 56/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0982 - val_loss: 0.1501 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0972 - val_loss: 0.1494 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0951 - val_loss: 0.1500 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0954 - val_loss: 0.1496 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.1507 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0947 - val_loss: 0.1505 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0949 - val_loss: 0.1506 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.1500 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1505 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.1498 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0942 - val_loss: 0.1502 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.1507 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0944 - val_loss: 0.1503 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0941 - val_loss: 0.1504 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0940 - val_loss: 0.1503 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0939 - val_loss: 0.1501 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0939 - val_loss: 0.1501 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0939 - val_loss: 0.1501 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0938 - val_loss: 0.1501 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0938 - val_loss: 0.1501 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0938 - val_loss: 0.1505 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0938 - val_loss: 0.1503 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0937 - val_loss: 0.1502 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0938 - val_loss: 0.1502 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0938 - val_loss: 0.1504 - lr: 2.4788e-06\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000244AB1DFBA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The MAPE for the test set is: 12.752115380566185%\n",
      "Evaluating for NN_width 256\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 34.9430 - val_loss: 14.9905 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.7130 - val_loss: 1.7291 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1696 - val_loss: 0.8765 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7310 - val_loss: 0.6605 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4699 - val_loss: 0.6803 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3822 - val_loss: 0.5809 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3265 - val_loss: 0.6448 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2609 - val_loss: 0.4753 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2506 - val_loss: 0.4514 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2327 - val_loss: 0.4153 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2267 - val_loss: 0.6337 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2461 - val_loss: 0.3526 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1948 - val_loss: 0.4050 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1838 - val_loss: 0.3654 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1713 - val_loss: 0.3258 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1342 - val_loss: 0.3117 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1341 - val_loss: 0.3188 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.2942 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1248 - val_loss: 0.5644 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.2966 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1632 - val_loss: 0.2595 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0881 - val_loss: 0.2522 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0862 - val_loss: 0.2488 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0877 - val_loss: 0.2504 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0952 - val_loss: 0.2412 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0894 - val_loss: 0.2926 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0857 - val_loss: 0.2330 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0802 - val_loss: 0.2749 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.2545 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0765 - val_loss: 0.2291 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0706 - val_loss: 0.2252 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0671 - val_loss: 0.2424 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.2601 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.2179 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.2238 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0637 - val_loss: 0.2386 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0632 - val_loss: 0.2193 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.2180 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0617 - val_loss: 0.2161 - lr: 1.4957e-04\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0605 - val_loss: 0.2139 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.2173 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0604 - val_loss: 0.2245 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0597 - val_loss: 0.2161 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0584 - val_loss: 0.2133 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0584 - val_loss: 0.2129 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0576 - val_loss: 0.2125 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.2151 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.2100 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.2119 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.2189 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.2109 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0588 - val_loss: 0.2094 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0564 - val_loss: 0.2114 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0567 - val_loss: 0.2114 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.2103 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0563 - val_loss: 0.2111 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.2092 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0555 - val_loss: 0.2084 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.2095 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0555 - val_loss: 0.2090 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0555 - val_loss: 0.2096 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0555 - val_loss: 0.2085 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.2096 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.2086 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.2084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0551 - val_loss: 0.2093 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.2084 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.2087 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.2086 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0549 - val_loss: 0.2085 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0549 - val_loss: 0.2087 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0548 - val_loss: 0.2081 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0547 - val_loss: 0.2083 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.2080 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.2086 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.2083 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.2081 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.2083 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.2086 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.2081 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The MAPE for the test set is: 11.551745169249434%\n",
      "Evaluating for NN_width 512\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 342.5811 - val_loss: 98.2657 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 53.0762 - val_loss: 11.1309 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5700 - val_loss: 8.2348 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1563 - val_loss: 7.2120 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7299 - val_loss: 6.7080 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.2117 - val_loss: 5.2841 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.2865 - val_loss: 4.6710 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.5794 - val_loss: 4.4407 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.9664 - val_loss: 3.7781 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.6229 - val_loss: 3.5311 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.2156 - val_loss: 3.1370 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.0223 - val_loss: 2.8411 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.7619 - val_loss: 2.7327 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.9906 - val_loss: 3.1191 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.3820 - val_loss: 2.5607 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.0482 - val_loss: 2.2902 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9869 - val_loss: 2.2086 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7143 - val_loss: 2.5140 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8573 - val_loss: 2.4915 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5472 - val_loss: 2.3011 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5078 - val_loss: 2.1100 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4025 - val_loss: 1.8911 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.3728 - val_loss: 1.8285 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.3710 - val_loss: 1.7903 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2849 - val_loss: 1.9949 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2109 - val_loss: 1.9383 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1912 - val_loss: 2.0436 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1691 - val_loss: 1.8302 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1192 - val_loss: 1.8782 - lr: 4.0657e-04\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1076 - val_loss: 1.7989 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1051 - val_loss: 1.8534 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0687 - val_loss: 1.6945 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0570 - val_loss: 1.8713 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0673 - val_loss: 1.6443 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0881 - val_loss: 1.6369 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0388 - val_loss: 1.7283 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0335 - val_loss: 1.6622 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0162 - val_loss: 1.6664 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0038 - val_loss: 1.7291 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9930 - val_loss: 1.6501 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.6799 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9919 - val_loss: 1.7006 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9733 - val_loss: 1.6016 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9725 - val_loss: 1.6208 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9669 - val_loss: 1.6315 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.9570 - val_loss: 1.6688 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9554 - val_loss: 1.6346 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9501 - val_loss: 1.6147 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9572 - val_loss: 1.6511 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.9379 - val_loss: 1.5887 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9432 - val_loss: 1.6323 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9353 - val_loss: 1.6007 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9327 - val_loss: 1.6142 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9295 - val_loss: 1.6005 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9275 - val_loss: 1.5937 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 1.5948 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9240 - val_loss: 1.5985 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9213 - val_loss: 1.5916 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9197 - val_loss: 1.5817 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9179 - val_loss: 1.5822 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9170 - val_loss: 1.5891 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9165 - val_loss: 1.5803 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9158 - val_loss: 1.5872 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9136 - val_loss: 1.5787 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9133 - val_loss: 1.5820 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9128 - val_loss: 1.5651 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9131 - val_loss: 1.5619 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9114 - val_loss: 1.5673 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9101 - val_loss: 1.5673 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9100 - val_loss: 1.5700 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9091 - val_loss: 1.5660 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9093 - val_loss: 1.5620 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9087 - val_loss: 1.5711 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9079 - val_loss: 1.5666 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9077 - val_loss: 1.5690 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9074 - val_loss: 1.5651 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9067 - val_loss: 1.5687 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9067 - val_loss: 1.5684 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9065 - val_loss: 1.5692 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9063 - val_loss: 1.5686 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "The MAPE for the test set is: 37.43429209442275%\n",
      "Evaluating for NN_width 1024\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 35.5626 - val_loss: 12.3678 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.4736 - val_loss: 1.5016 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.8531 - val_loss: 0.7709 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4938 - val_loss: 0.2763 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2024 - val_loss: 0.1596 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1300 - val_loss: 0.1301 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1208 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.1183 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0969 - val_loss: 0.1571 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0811 - val_loss: 0.1199 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0820 - val_loss: 0.0863 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0737 - val_loss: 0.1195 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0535 - val_loss: 0.0626 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0622 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0332 - val_loss: 0.0413 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.0348 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0466 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0307 - lr: 0.0010\n",
      "Epoch 20/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0735 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0362 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0478 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0349 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0261 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0347 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0335 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0269 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0320 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0270 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0266 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0271 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0252 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0242 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0245 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0271 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0263 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0249 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0246 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0243 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0238 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0233 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0250 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0271 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0251 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0239 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0236 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0249 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0253 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0246 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0246 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0235 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0241 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0236 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0233 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0234 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0233 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0236 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0232 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0235 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0233 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0232 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0233 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0234 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0232 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0232 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0234 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0232 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0233 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0233 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0231 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0233 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0231 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0231 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0231 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0232 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "The MAPE for the test set is: 5.3839278564096%\n",
      "Evaluating for NN_width 2048\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 55.3881 - val_loss: 12.8948 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.5583 - val_loss: 1.5013 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9234 - val_loss: 0.8717 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3252 - val_loss: 0.2104 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1144 - val_loss: 0.0716 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0666 - val_loss: 0.1037 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.0727 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0452 - val_loss: 0.0409 - lr: 0.0010\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0390 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0520 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0427 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0338 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0337 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0298 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0529 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0377 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0436 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0245 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0236 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0267 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0327 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0244 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0251 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0214 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0213 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0370 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0198 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0218 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0247 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0202 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0225 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0206 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0233 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0205 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0200 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0204 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0196 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0199 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0199 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0202 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0199 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0201 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0206 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0215 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0203 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0200 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0197 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0201 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0200 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0202 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0202 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0196 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0196 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0201 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0197 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0202 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0197 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0198 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0199 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0199 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0198 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0201 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0198 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0200 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0200 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0198 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0199 - lr: 2.4788e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 4.757982722903556%\n",
      "Evaluating for NN_width 4096\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 207.2088 - val_loss: 42.9275 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.1716 - val_loss: 19.6957 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.7843 - val_loss: 0.4838 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9583 - val_loss: 0.4342 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3760 - val_loss: 0.2345 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1555 - val_loss: 0.1645 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.1269 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0601 - val_loss: 0.1110 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0600 - val_loss: 0.0672 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0639 - val_loss: 0.0673 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0551 - val_loss: 0.0538 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0386 - val_loss: 0.0438 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0364 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0329 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0278 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0359 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0209 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0191 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0183 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0214 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0164 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0168 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0161 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0192 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0226 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0176 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0150 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0166 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0147 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0147 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0141 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0153 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0147 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0147 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0151 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0142 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0140 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0142 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0146 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0160 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0152 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0145 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0134 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0136 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0147 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0141 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0139 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0142 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0147 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0135 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0143 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0143 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0136 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0140 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0140 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0136 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0140 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0140 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0136 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0138 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0138 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0138 - lr: 6.7379e-06\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0137 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0137 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0138 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0136 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 2.928552307646415%\n",
      "Evaluating for NN_width 8192\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 353.5281 - val_loss: 104.0967 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 36.4309 - val_loss: 3.4417 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 6.2673 - val_loss: 3.0255 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1473 - val_loss: 0.5634 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2642 - val_loss: 0.1005 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.0781 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0485 - val_loss: 0.0437 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0321 - val_loss: 0.0529 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0314 - val_loss: 0.0378 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0258 - val_loss: 0.0400 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0301 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0273 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0281 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0200 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0346 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0170 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0183 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0187 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0174 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0146 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0145 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0144 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0158 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0139 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0141 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0142 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0141 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0135 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0133 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0134 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0137 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0134 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0133 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0131 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0130 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0130 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0134 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0129 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0132 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0128 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0128 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0129 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0128 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0128 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0128 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0127 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0128 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0127 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0127 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0127 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0126 - lr: 1.8316e-05\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0126 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0126 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0126 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0126 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0126 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "The MAPE for the test set is: 3.1718801830606638%\n",
      "Evaluating for NN_width 16384\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 667.1257 - val_loss: 216.6137 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 58.9441 - val_loss: 36.6025 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.3978 - val_loss: 9.3019 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.2439 - val_loss: 1.5120 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.1919 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2274 - val_loss: 0.1672 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0893 - val_loss: 0.0755 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0371 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.0303 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0302 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0176 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0192 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0173 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0321 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0112 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0107 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0102 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0118 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0097 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0127 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0100 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0104 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0094 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0093 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0095 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0092 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0091 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0092 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0095 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0097 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0093 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0091 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0089 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0089 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0090 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0091 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0089 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0090 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0091 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0090 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 4.9787e-05\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 2.7112741595449936%\n",
      "Evaluating for NN_width 32768\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 1251.8314 - val_loss: 100.3456 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 65.9706 - val_loss: 16.0822 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.1409 - val_loss: 0.9637 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.8027 - val_loss: 0.3928 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1897 - val_loss: 0.0831 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0838 - val_loss: 0.0718 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0627 - val_loss: 0.0453 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0434 - val_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0260 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0111 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0104 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0120 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0105 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0107 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0106 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0107 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0107 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0099 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0099 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0099 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0109 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0106 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0102 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0106 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0104 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0098 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0099 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0100 - lr: 1.3534e-04\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0096 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0102 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0096 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0100 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0096 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0098 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0097 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0096 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0098 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0096 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0097 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0097 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0097 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0096 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.587354490154096%\n"
     ]
    }
   ],
   "source": [
    "NN_widths = [64,128,256,512,1024,2048,4096,8192,16384,32768]\n",
    "\n",
    "# List to store average percentage differences for each width\n",
    "avg_percentages_diffs_NN_widths = []\n",
    "\n",
    "\n",
    "#Evaluating for Width 64\n",
    "print(\"Evaluating for NN_width 64\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_64)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 128\n",
    "print(\"Evaluating for NN_width 128\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_128)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 256\n",
    "print(\"Evaluating for NN_width 256\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_256)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 512\n",
    "print(\"Evaluating for NN_width 512\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_512)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 1024\n",
    "print(\"Evaluating for NN_width 1024\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_1024)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 2048\n",
    "print(\"Evaluating for NN_width 2048\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_2048)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 4096\n",
    "print(\"Evaluating for NN_width 4096\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_4096)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 8192\n",
    "print(\"Evaluating for NN_width 8192\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_8192)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 16384\n",
    "print(\"Evaluating for NN_width 16384\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_16384)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n",
    "\n",
    "#Evaluating for Width 32768\n",
    "print(\"Evaluating for NN_width 32768\")\n",
    "avg_percentages_diffs_NN_width = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_width_32768)\n",
    "avg_percentages_diffs_NN_widths.append(avg_percentages_diffs_NN_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f10d3edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(NN_widths, avg_percentages_diffs_NN_widths, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. NN_width')\n",
    "plt.xlabel('NN_width')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "# Save the plot as a PDF\n",
    "plt.savefig('width.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd44f0",
   "metadata": {},
   "source": [
    "### 2- NN depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99045026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for NN_depth 1\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 719.7039 - val_loss: 230.8444 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 63.7195 - val_loss: 37.8013 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.9127 - val_loss: 8.6958 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3.1538 - val_loss: 1.5544 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5891 - val_loss: 0.1516 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1838 - val_loss: 0.1495 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0733 - val_loss: 0.0720 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0409 - val_loss: 0.0393 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.0333 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.0403 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0210 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0197 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0191 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0212 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0166 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0127 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0114 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0111 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0105 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0122 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0099 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0106 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0098 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0099 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0100 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0099 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0093 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0095 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0097 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0096 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0094 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0093 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0095 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0092 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0094 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0094 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0094 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0093 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0093 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0095 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0093 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0093 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0093 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0093 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0093 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0093 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0093 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0093 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 6.0967e-06\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0092 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.7492004025675265%\n",
      "Evaluating for NN_depth 3\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 404.3156 - val_loss: 4.4809 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 3.0539 - val_loss: 2.2245 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5909 - val_loss: 0.0398 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1066 - val_loss: 0.0367 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0182 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0159 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0127 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0162 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0387 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0121 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0084 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0085 - val_loss: 0.0114 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0083 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0091 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.0082 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0097 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0117 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0087 - val_loss: 0.0079 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0081 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0098 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0055 - val_loss: 0.0081 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0081 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0086 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0088 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0080 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0081 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0086 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0093 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0081 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0080 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0077 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0083 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0080 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0078 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0078 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0077 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0080 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0078 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0077 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 1.6573e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0078 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0077 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.34251624186965%\n",
      "Evaluating for NN_depth 5\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 77.9188 - val_loss: 1.5294 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4547 - val_loss: 0.1917 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0578 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3122 - val_loss: 0.0931 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.2975 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0458 - val_loss: 0.0603 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0640 - val_loss: 0.0853 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0517 - val_loss: 0.1604 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0859 - val_loss: 0.2165 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3138 - val_loss: 0.2751 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4188 - val_loss: 0.2097 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1243 - val_loss: 0.0871 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0294 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0334 - val_loss: 0.0329 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0183 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.1395 - val_loss: 0.4410 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.2787 - val_loss: 0.2115 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1802 - val_loss: 0.1391 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0446 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0173 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0093 - val_loss: 0.0095 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0090 - val_loss: 0.0091 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0090 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0095 - val_loss: 0.0103 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0110 - val_loss: 0.0209 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0109 - val_loss: 0.0096 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0071 - val_loss: 0.0089 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0069 - val_loss: 0.0109 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0100 - val_loss: 0.0082 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0084 - val_loss: 0.0152 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0192 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0097 - val_loss: 0.0101 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0112 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0071 - val_loss: 0.0082 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0088 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0081 - val_loss: 0.0080 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0085 - val_loss: 0.0137 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0084 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0080 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0086 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0082 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 4.5049e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0078 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.467728100097097%\n",
      "Evaluating for NN_depth 7\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 14.7667 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0557 - val_loss: 0.1282 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0760 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0252 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0318 - val_loss: 0.0562 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0753 - val_loss: 0.1480 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0337 - val_loss: 0.2501 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1108 - val_loss: 0.0866 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0467 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0272 - val_loss: 0.0416 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0133 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0140 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0158 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0098 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.0157 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0088 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0149 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0081 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0091 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0081 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0085 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0082 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0093 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0099 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0115 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0222 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0159 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0091 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0078 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0077 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0112 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0094 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0108 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0108 - lr: 1.2246e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0075 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0091 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0076 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0075 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0075 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0076 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0075 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0075 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0075 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0075 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0075 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 2.550618326798574%\n",
      "Evaluating for NN_depth 8\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 35ms/step - loss: 3.1338 - val_loss: 0.2169 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1019 - val_loss: 0.1724 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1201 - val_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0203 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0336 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0289 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0178 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0097 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0085 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0094 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0075 - val_loss: 0.0085 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0072 - val_loss: 0.0085 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0133 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0083 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0103 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0118 - val_loss: 0.0118 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0181 - lr: 3.3287e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0180 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0102 - val_loss: 0.0107 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0080 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0093 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0081 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0132 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0094 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0078 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0095 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0086 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0080 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0078 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0078 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0079 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0055 - val_loss: 0.0078 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "The MAPE for the test set is: 2.3888723760091626%\n",
      "Evaluating for NN_depth 9\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 36ms/step - loss: 2.5081 - val_loss: 0.0388 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0209 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0117 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0077 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0088 - lr: 9.0484e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0092 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0095 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0082 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0082 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0130 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0081 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0082 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0086 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0080 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0086 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0076 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0077 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0077 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0076 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 2.4203988776628313%\n",
      "Evaluating for NN_depth 10\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 36ms/step - loss: 0.0331 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0144 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0137 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 2.957735515406041%\n",
      "Evaluating for NN_depth 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "17/17 [==============================] - 3s 35ms/step - loss: 0.0271 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0134 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "The MAPE for the test set is: 2.957724849697029%\n"
     ]
    }
   ],
   "source": [
    "NN_depths = [1,3,5,7,8,9,10,11]\n",
    "\n",
    "# List to store average percentage differences for each depth\n",
    "avg_percentages_diffs_NN_depths = []\n",
    "\n",
    "\n",
    "#Evaluating for Depth 1\n",
    "print(\"Evaluating for NN_depth 1\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_1)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 3\n",
    "print(\"Evaluating for NN_depth 3\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_3)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 5\n",
    "print(\"Evaluating for NN_depth 5\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_5)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 7\n",
    "print(\"Evaluating for NN_depth 7\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_7)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 8\n",
    "print(\"Evaluating for NN_depth 8\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_8)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 9\n",
    "print(\"Evaluating for NN_depth 9\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_9)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 10\n",
    "print(\"Evaluating for NN_depth 10\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_10)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n",
    "#Evaluating for Depth 11\n",
    "print(\"Evaluating for NN_depth 11\")\n",
    "avg_percentages_diffs_NN_depth = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,f=NLP_depth_11)\n",
    "avg_percentages_diffs_NN_depths.append(avg_percentages_diffs_NN_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2f17488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(NN_depths, avg_percentages_diffs_NN_depths, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. NN_depth')\n",
    "plt.xlabel('NN_depth')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "plt.savefig('depth.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac2fe2",
   "metadata": {},
   "source": [
    "### 3 - correlation threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ea97d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for threshold : 0.1\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 36ms/step - loss: 78.8300 - val_loss: 1.1657 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3957 - val_loss: 0.0422 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0267 - val_loss: 0.0205 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0235 - val_loss: 0.0423 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0295 - val_loss: 0.0175 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0428 - val_loss: 0.1297 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0862 - val_loss: 0.1532 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0863 - val_loss: 0.3063 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.2069 - val_loss: 0.0169 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0186 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0213 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0468 - val_loss: 0.0316 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0672 - val_loss: 0.1057 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0306 - val_loss: 0.0204 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1450 - val_loss: 0.3597 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1501 - val_loss: 0.0996 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0617 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0738 - val_loss: 0.0839 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0391 - val_loss: 0.0435 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0174 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0263 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0092 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0090 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0109 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0115 - val_loss: 0.0115 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0089 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0098 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0075 - val_loss: 0.0087 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0092 - val_loss: 0.0087 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.0100 - val_loss: 0.0187 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0106 - val_loss: 0.0100 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0091 - val_loss: 0.0087 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0067 - val_loss: 0.0087 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0068 - val_loss: 0.0087 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.0063 - val_loss: 0.0087 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.0062 - val_loss: 0.0088 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0074 - val_loss: 0.0129 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0085 - val_loss: 0.0108 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0085 - val_loss: 0.0086 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.0065 - val_loss: 0.0111 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0099 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0093 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0088 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0088 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0086 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0086 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0087 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0090 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0086 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0087 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0087 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0085 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0087 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0087 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0086 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0085 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 6.7379e-06\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.559556232369625%\n",
      "Testing performance for threshold : 0.12\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 40.5754 - val_loss: 1.7773 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 2.1835 - val_loss: 0.2626 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4449 - val_loss: 0.0729 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1120 - val_loss: 0.0373 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0239 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0181 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0164 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0085 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0109 - val_loss: 0.0106 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0081 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0078 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0103 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0081 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0090 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0069 - val_loss: 0.0133 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0100 - val_loss: 0.0103 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0110 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0099 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0097 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0076 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0076 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0075 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0076 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0101 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0076 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0084 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0061 - val_loss: 0.0075 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0074 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: 0.0074 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0048 - val_loss: 0.0074 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0049 - val_loss: 0.0075 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0049 - val_loss: 0.0079 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0049 - val_loss: 0.0078 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0077 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0049 - val_loss: 0.0074 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0048 - val_loss: 0.0073 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0048 - val_loss: 0.0074 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0047 - val_loss: 0.0075 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0048 - val_loss: 0.0073 - lr: 1.8316e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0047 - val_loss: 0.0073 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "The MAPE for the test set is: 2.3149362792741472%\n",
      "Testing performance for threshold : 0.14\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 28.9878 - val_loss: 3.4227 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.8612 - val_loss: 0.4775 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1745 - val_loss: 0.0348 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0187 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0161 - val_loss: 0.0372 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0289 - val_loss: 0.0355 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0205 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0465 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0285 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0181 - val_loss: 0.0481 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0259 - val_loss: 0.0210 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0345 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0178 - val_loss: 0.0463 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0280 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1652 - val_loss: 0.3330 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1786 - val_loss: 0.0903 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1058 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0271 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0157 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0090 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0089 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0087 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0083 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0175 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0083 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0091 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0105 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0083 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0118 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0151 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0107 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0099 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0080 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0080 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0093 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0079 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0118 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0089 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0079 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0082 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 5.5023e-05\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0079 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0079 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0080 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0080 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 918us/step\n",
      "The MAPE for the test set is: 2.423836513674953%\n",
      "Testing performance for threshold : 0.16\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 10.3401 - val_loss: 2.0995 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.8135 - val_loss: 0.4254 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1707 - val_loss: 0.1034 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0325 - val_loss: 0.0197 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0171 - val_loss: 0.0152 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0199 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0100 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0127 - val_loss: 0.0305 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0191 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0207 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0239 - val_loss: 0.0327 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0143 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0138 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0094 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0087 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0089 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0177 - val_loss: 0.0200 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0225 - val_loss: 0.0342 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0295 - val_loss: 0.0177 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0144 - val_loss: 0.0101 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0109 - val_loss: 0.0143 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0141 - val_loss: 0.0116 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0082 - val_loss: 0.0084 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0096 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.0124 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0101 - val_loss: 0.0088 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0148 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0084 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0092 - val_loss: 0.0094 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0088 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0091 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0142 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0093 - val_loss: 0.0143 - lr: 1.4957e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0084 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0062 - val_loss: 0.0118 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0063 - val_loss: 0.0087 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0101 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0065 - val_loss: 0.0090 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0089 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0084 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0088 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0088 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0089 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0087 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0059 - val_loss: 0.0084 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0057 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0085 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0083 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0084 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0084 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "The MAPE for the test set is: 2.376625536061758%\n",
      "Testing performance for threshold : 0.2\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 14.5911 - val_loss: 0.4271 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3143 - val_loss: 0.0938 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1068 - val_loss: 0.2411 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0613 - val_loss: 0.0289 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0247 - val_loss: 0.0190 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0431 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0204 - val_loss: 0.0422 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0467 - val_loss: 0.0463 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0513 - val_loss: 0.0678 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0390 - val_loss: 0.0409 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0339 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0176 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0180 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0140 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0192 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0349 - val_loss: 0.0200 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0828 - val_loss: 0.2646 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0792 - val_loss: 0.0177 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0301 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0276 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0098 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0087 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0087 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0105 - val_loss: 0.0141 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0153 - val_loss: 0.0091 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0101 - val_loss: 0.0097 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0092 - lr: 4.4933e-04\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0094 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0089 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0100 - val_loss: 0.0138 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0103 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0088 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.0084 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0072 - val_loss: 0.0085 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0091 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0163 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0122 - val_loss: 0.0144 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0097 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0131 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0085 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0094 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0076 - val_loss: 0.0094 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.0086 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0085 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0074 - val_loss: 0.0082 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0070 - val_loss: 0.0083 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0087 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.656891753495269%\n"
     ]
    }
   ],
   "source": [
    "# List of correlation thresholds to test\n",
    "correlation_thresholds = [0.1, 0.12, 0.14,0.16,0.2]\n",
    "\n",
    "# List to store average percentage differences for each threshold\n",
    "avg_percentages_diffs = []\n",
    "\n",
    "# Loop through each correlation threshold\n",
    "for correlation_threshold in correlation_thresholds:\n",
    "    print(f\"Testing performance for threshold : {correlation_threshold}\")\n",
    "    \n",
    "    # Keep only features with a minimum threshold of correlation with the output\n",
    "    features_kept_test,_ = filter_uncorrelated_features(full_combined_data_quartiles, merged_df_R_D, correlation_threshold=correlation_threshold)\n",
    "\n",
    "    # Create a DataFrame with selected features and additional columns \"ISO\" and \"year\"\n",
    "    combined_data_quartiles_test = full_combined_data_quartiles.loc[:, features_kept_test + [\"ISO\", \"year\"]]\n",
    "\n",
    "    # Merge the selected features with Google Trends data based on \"ISO\" and \"year\"\n",
    "    google_trends_data_test = pd.merge(first_merged, combined_data_quartiles_test, on=['ISO', 'year'], how='inner')\n",
    "\n",
    "    # Drop columns \"ISO\" and \"v-2\" from the merged DataFrame\n",
    "    google_trends_data_test = google_trends_data_test.drop(axis=1, columns=[\"ISO\", \"v-2\"])\n",
    "\n",
    "    # Train and evaluate the model with the selected data and calculate the average percentage difference\n",
    "    avg_percentage_diff = train_and_evaluate_yearly_basis_select_parameters(google_trends_data_test, True)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs.append(avg_percentage_diff)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31894ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(correlation_thresholds, avg_percentages_diffs, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. Correlation Thresholds')\n",
    "plt.xlabel('Correlation Threshold')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "plt.savefig('correlations_plot.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a129b",
   "metadata": {},
   "source": [
    "### 4 - initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdcf3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for initial_rate : 1e-05\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 40ms/step - loss: 0.5246 - val_loss: 0.0511 - lr: 1.0000e-05\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.1064 - val_loss: 0.0376 - lr: 1.0000e-05\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0342 - val_loss: 0.0279 - lr: 1.0000e-05\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0231 - val_loss: 0.0317 - lr: 1.0000e-05\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0176 - val_loss: 0.0190 - lr: 1.0000e-05\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0128 - val_loss: 0.0171 - lr: 1.0000e-05\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0103 - val_loss: 0.0175 - lr: 1.0000e-05\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0167 - lr: 1.0000e-05\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0081 - val_loss: 0.0156 - lr: 1.0000e-05\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0145 - lr: 1.0000e-05\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0063 - val_loss: 0.0149 - lr: 1.0000e-05\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0145 - lr: 1.0000e-05\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0140 - lr: 1.0000e-05\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0133 - lr: 1.0000e-05\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0051 - val_loss: 0.0142 - lr: 1.0000e-05\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0041 - val_loss: 0.0141 - lr: 1.0000e-05\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0132 - lr: 1.0000e-05\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0039 - val_loss: 0.0145 - lr: 1.0000e-05\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0148 - lr: 1.0000e-05\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0032 - val_loss: 0.0131 - lr: 9.0484e-06\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0032 - val_loss: 0.0140 - lr: 8.1873e-06\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0030 - val_loss: 0.0133 - lr: 7.4082e-06\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0029 - val_loss: 0.0128 - lr: 6.7032e-06\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0130 - lr: 6.0653e-06\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0133 - lr: 5.4881e-06\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0124 - lr: 4.9659e-06\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0130 - lr: 4.4933e-06\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0026 - val_loss: 0.0131 - lr: 4.0657e-06\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0127 - lr: 3.6788e-06\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0127 - lr: 3.3287e-06\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0020 - val_loss: 0.0124 - lr: 3.0119e-06\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0125 - lr: 2.7253e-06\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0020 - val_loss: 0.0126 - lr: 2.4660e-06\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0126 - lr: 2.2313e-06\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0020 - val_loss: 0.0127 - lr: 2.0190e-06\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0126 - lr: 1.8268e-06\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0126 - lr: 1.6530e-06\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0126 - lr: 1.4957e-06\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0126 - lr: 1.3534e-06\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0125 - lr: 1.2246e-06\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0125 - lr: 1.1080e-06\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0125 - lr: 1.0026e-06\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0126 - lr: 9.0718e-07\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 8.2085e-07\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0126 - lr: 7.4274e-07\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 6.7206e-07\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0126 - lr: 6.0810e-07\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 5.5023e-07\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 4.9787e-07\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 4.5049e-07\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 4.0762e-07\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 3.6883e-07\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 3.3373e-07\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0125 - lr: 3.0197e-07\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.7324e-07\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.4724e-07\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.2371e-07\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.0242e-07\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.8316e-07\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.6573e-07\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.4996e-07\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.3569e-07\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.2277e-07\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.1109e-07\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 1.0052e-07\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 9.0953e-08\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 8.2297e-08\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 7.4466e-08\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 6.7379e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 6.0967e-08\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 5.5166e-08\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 4.9916e-08\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 4.5166e-08\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 4.0868e-08\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 3.6979e-08\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 3.3460e-08\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 3.0276e-08\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.7394e-08\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0125 - lr: 2.4788e-08\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 3.2138541109656313%\n",
      "Testing performance for initial_rate : 0.001\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 29.9820 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5655 - val_loss: 0.3400 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1772 - val_loss: 0.0204 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0448 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0143 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0145 - val_loss: 0.0179 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0199 - val_loss: 0.0276 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0163 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0155 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0131 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0106 - val_loss: 0.0284 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0198 - val_loss: 0.0329 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0170 - val_loss: 0.0130 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0116 - val_loss: 0.0200 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0241 - val_loss: 0.0317 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.1550 - val_loss: 0.3510 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.1946 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0800 - val_loss: 0.1159 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0314 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0088 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0095 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0093 - val_loss: 0.0084 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0094 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0092 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0081 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0095 - val_loss: 0.0173 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0092 - val_loss: 0.0083 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0084 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0129 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0081 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0128 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0176 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0095 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0094 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0070 - val_loss: 0.0081 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0075 - val_loss: 0.0082 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0082 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0082 - val_loss: 0.0124 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0076 - val_loss: 0.0081 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0073 - val_loss: 0.0085 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0068 - val_loss: 0.0079 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0079 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0087 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0062 - val_loss: 0.0078 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0079 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 2.0242e-05\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0078 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 2.488033064407629%\n",
      "Testing performance for initial_rate : 0.01\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 35ms/step - loss: 986165.9375 - val_loss: 3.0982 - lr: 0.0100\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.7030 - val_loss: 0.2698 - lr: 0.0100\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0684 - val_loss: 0.0246 - lr: 0.0100\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0164 - val_loss: 0.0181 - lr: 0.0100\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0312 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0244 - val_loss: 0.0725 - lr: 0.0100\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0415 - val_loss: 0.0141 - lr: 0.0100\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0220 - val_loss: 0.0123 - lr: 0.0100\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0220 - val_loss: 0.0114 - lr: 0.0100\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0634 - val_loss: 0.4029 - lr: 0.0100\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 30.5686 - val_loss: 7.7439 - lr: 0.0100\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 4.9059 - val_loss: 0.1527 - lr: 0.0100\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.1066 - val_loss: 0.2860 - lr: 0.0100\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0644 - val_loss: 0.0187 - lr: 0.0100\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0140 - val_loss: 0.0136 - lr: 0.0100\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0126 - val_loss: 0.0141 - lr: 0.0100\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0124 - val_loss: 0.0130 - lr: 0.0100\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0119 - val_loss: 0.0154 - lr: 0.0100\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0128 - val_loss: 0.0127 - lr: 0.0100\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0126 - lr: 0.0100\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0117 - val_loss: 0.0152 - lr: 0.0090\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0118 - val_loss: 0.0126 - lr: 0.0082\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0114 - val_loss: 0.0132 - lr: 0.0074\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0117 - val_loss: 0.0141 - lr: 0.0067\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0116 - val_loss: 0.0129 - lr: 0.0061\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0151 - lr: 0.0055\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.0127 - val_loss: 0.0124 - lr: 0.0050\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0111 - val_loss: 0.0130 - lr: 0.0045\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0122 - lr: 0.0041\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0122 - lr: 0.0037\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0107 - val_loss: 0.0122 - lr: 0.0033\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 0.0133 - lr: 0.0030\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0109 - val_loss: 0.0123 - lr: 0.0027\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0109 - val_loss: 0.0123 - lr: 0.0025\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.0123 - lr: 0.0022\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0114 - val_loss: 0.0132 - lr: 0.0020\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0110 - val_loss: 0.0127 - lr: 0.0018\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0110 - val_loss: 0.0124 - lr: 0.0017\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0108 - val_loss: 0.0126 - lr: 0.0015\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0106 - val_loss: 0.0120 - lr: 0.0014\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0108 - val_loss: 0.0120 - lr: 0.0012\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0110 - val_loss: 0.0121 - lr: 0.0011\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0121 - lr: 9.0718e-04\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0121 - lr: 8.2085e-04\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0123 - lr: 7.4274e-04\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 6.7206e-04\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 6.0810e-04\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 5.5023e-04\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 4.9787e-04\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 4.5049e-04\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 4.0762e-04\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 3.6883e-04\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 3.3373e-04\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 3.0197e-04\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0120 - lr: 2.7324e-04\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 2.4724e-04\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 2.2371e-04\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 2.0242e-04\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 1.8316e-04\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 1.6573e-04\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 1.4996e-04\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0120 - lr: 1.3569e-04\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 1.2277e-04\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 1.1109e-04\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 1.0052e-04\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 9.0953e-05\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 8.2298e-05\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 7.4466e-05\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 6.7380e-05\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 6.0968e-05\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 5.5166e-05\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 4.9916e-05\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 4.5166e-05\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 4.0868e-05\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 3.6979e-05\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 3.3460e-05\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 3.0276e-05\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 2.7394e-05\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0119 - lr: 2.4788e-05\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 2.715968706511979%\n",
      "Testing performance for initial_rate : 0.1\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 1230646374563840.0000 - val_loss: 27148208128.0000 - lr: 0.1000\n",
      "Epoch 2/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 92485894144.0000 - val_loss: 2869035520.0000 - lr: 0.1000\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 786039488.0000 - val_loss: 465889472.0000 - lr: 0.1000\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 141296880.0000 - val_loss: 113523264.0000 - lr: 0.1000\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 34618896.0000 - val_loss: 10258892.0000 - lr: 0.1000\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 5201123.5000 - val_loss: 266029.3125 - lr: 0.1000\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 832607.3125 - val_loss: 14434.8350 - lr: 0.1000\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 133184.4219 - val_loss: 30179.0586 - lr: 0.1000\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 24383.6719 - val_loss: 9417.0352 - lr: 0.1000\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 5172.0923 - val_loss: 2625.5789 - lr: 0.1000\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1185.7220 - val_loss: 227.4800 - lr: 0.1000\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 202.7156 - val_loss: 0.4344 - lr: 0.1000\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 36.0942 - val_loss: 6.6906 - lr: 0.1000\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 9.0152 - val_loss: 5.4775 - lr: 0.1000\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.9038 - val_loss: 0.9266 - lr: 0.1000\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3679 - val_loss: 0.0321 - lr: 0.1000\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0931 - val_loss: 0.0600 - lr: 0.1000\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0439 - val_loss: 0.0343 - lr: 0.1000\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0363 - val_loss: 0.0321 - lr: 0.1000\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0360 - val_loss: 0.0328 - lr: 0.1000\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0353 - val_loss: 0.0341 - lr: 0.0905\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0386 - val_loss: 0.0330 - lr: 0.0819\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0381 - val_loss: 0.0338 - lr: 0.0741\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0365 - val_loss: 0.0343 - lr: 0.0670\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0356 - val_loss: 0.0325 - lr: 0.0607\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0354 - val_loss: 0.0321 - lr: 0.0549\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0352 - val_loss: 0.0321 - lr: 0.0497\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0356 - val_loss: 0.0324 - lr: 0.0449\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0355 - val_loss: 0.0325 - lr: 0.0407\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0355 - val_loss: 0.0342 - lr: 0.0368\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0362 - val_loss: 0.0324 - lr: 0.0333\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0362 - val_loss: 0.0333 - lr: 0.0301\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0358 - val_loss: 0.0330 - lr: 0.0273\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0355 - val_loss: 0.0323 - lr: 0.0247\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0358 - val_loss: 0.0332 - lr: 0.0223\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0365 - val_loss: 0.0326 - lr: 0.0202\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0365 - val_loss: 0.0329 - lr: 0.0183\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0354 - val_loss: 0.0321 - lr: 0.0165\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0351 - val_loss: 0.0321 - lr: 0.0150\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0349 - val_loss: 0.0322 - lr: 0.0135\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0350 - val_loss: 0.0321 - lr: 0.0122\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0351 - val_loss: 0.0321 - lr: 0.0111\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0347 - val_loss: 0.0321 - lr: 0.0100\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.0351 - val_loss: 0.0321 - lr: 0.0091\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0082\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0074\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0067\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0061\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 0.0055\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0050\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0045\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0351 - val_loss: 0.0321 - lr: 0.0041\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0348 - val_loss: 0.0322 - lr: 0.0037\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0033\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0351 - val_loss: 0.0321 - lr: 0.0030\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0027\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0025\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0022\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 0.0020\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 0.0018\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0017\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 0.0015\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0014\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0012\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 0.0011\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 0.0010\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 9.0953e-04\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 8.2298e-04\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 7.4466e-04\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0349 - val_loss: 0.0321 - lr: 6.7380e-04\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 6.0968e-04\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 5.5166e-04\n",
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 4.9916e-04\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 4.5166e-04\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 4.0868e-04\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 3.6979e-04\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 3.3460e-04\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 3.0276e-04\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 2.7394e-04\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0348 - val_loss: 0.0321 - lr: 2.4788e-04\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "The MAPE for the test set is: 5.484513775914042%\n"
     ]
    }
   ],
   "source": [
    "# List of initial_rates for NN optimization to test\n",
    "initial_rates = [0.00001,0.001,0.01,0.1]\n",
    "\n",
    "# List to store average percentage differences for each initial_rate\n",
    "avg_percentages_diffs_initial_rates = []\n",
    "\n",
    "# Loop through each initial_rate\n",
    "for initial_rate in initial_rates:\n",
    "    print(f\"Testing performance for initial_rate : {initial_rate}\")\n",
    "    avg_percentages_diffs_initial_rate = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,initial_rate=initial_rate)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_initial_rates.append(avg_percentages_diffs_initial_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f9d17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "203a4e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(initial_rates, avg_percentages_diffs_initial_rates, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. Initial rates')\n",
    "plt.xlabel('Initial rates')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.savefig('learning_rates.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e984d0",
   "metadata": {},
   "source": [
    "### 5 - Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7471c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for batch_size : 7\n",
      "Epoch 1/80\n",
      "47/47 [==============================] - 3s 30ms/step - loss: 17.4959 - val_loss: 0.0328 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0522 - val_loss: 0.0333 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0272 - val_loss: 0.1129 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0538 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0283 - val_loss: 0.2717 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0858 - val_loss: 0.0626 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0769 - val_loss: 0.0753 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0225 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0304 - val_loss: 0.0390 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0276 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0137 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0161 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0178 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0278 - val_loss: 0.0319 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0127 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0198 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0309 - val_loss: 0.0312 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0145 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0125 - val_loss: 0.0335 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0229 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0138 - val_loss: 0.0133 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0110 - val_loss: 0.0089 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0076 - val_loss: 0.0083 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0084 - val_loss: 0.0080 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0072 - val_loss: 0.0082 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0092 - val_loss: 0.0107 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0075 - val_loss: 0.0102 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0096 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0068 - val_loss: 0.0080 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0061 - val_loss: 0.0086 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0063 - val_loss: 0.0078 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0056 - val_loss: 0.0078 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0057 - val_loss: 0.0091 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0059 - val_loss: 0.0086 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0065 - val_loss: 0.0078 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0074 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0054 - val_loss: 0.0095 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0054 - val_loss: 0.0083 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0052 - val_loss: 0.0083 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0053 - val_loss: 0.0084 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0054 - val_loss: 0.0074 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0074 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0075 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0050 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0049 - val_loss: 0.0078 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0078 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0078 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0075 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0075 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0074 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0046 - val_loss: 0.0073 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0046 - val_loss: 0.0074 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0075 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0073 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0046 - val_loss: 0.0075 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.0046 - val_loss: 0.0073 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.0045 - val_loss: 0.0074 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0046 - val_loss: 0.0073 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0074 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0074 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 6.7379e-06\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0074 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "The MAPE for the test set is: 2.315591579437037%\n",
      "Testing performance for batch_size : 8\n",
      "Epoch 1/80\n",
      "41/41 [==============================] - 2s 24ms/step - loss: 16.6457 - val_loss: 3.4366 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.4445 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0250 - val_loss: 0.0568 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0330 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0126 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0191 - val_loss: 0.0132 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0128 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0132 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0199 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0150 - val_loss: 0.0189 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0227 - val_loss: 0.0261 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0287 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0260 - val_loss: 0.0465 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0329 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0213 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0170 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0275 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0085 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0099 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0118 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0145 - val_loss: 0.0087 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0103 - val_loss: 0.0179 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0079 - val_loss: 0.0081 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0102 - val_loss: 0.0098 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0147 - val_loss: 0.0090 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0077 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0082 - val_loss: 0.0087 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0084 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0071 - val_loss: 0.0119 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0076 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0053 - val_loss: 0.0075 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0052 - val_loss: 0.0100 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0057 - val_loss: 0.0093 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0062 - val_loss: 0.0090 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0061 - val_loss: 0.0075 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0051 - val_loss: 0.0104 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0089 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0053 - val_loss: 0.0094 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0075 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0049 - val_loss: 0.0074 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0077 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0081 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0075 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0074 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0074 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0076 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0045 - val_loss: 0.0082 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0074 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0044 - val_loss: 0.0074 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0043 - val_loss: 0.0073 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0086 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0047 - val_loss: 0.0074 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0043 - val_loss: 0.0073 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0043 - val_loss: 0.0076 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 0.0073 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0043 - val_loss: 0.0078 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0044 - val_loss: 0.0073 - lr: 1.8316e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0043 - val_loss: 0.0076 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0073 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0042 - val_loss: 0.0073 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0041 - val_loss: 0.0075 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - val_loss: 0.0073 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0041 - val_loss: 0.0075 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0042 - val_loss: 0.0074 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0041 - val_loss: 0.0074 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0041 - val_loss: 0.0074 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0041 - val_loss: 0.0074 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 2.217493319837462%\n",
      "Testing performance for batch_size : 10\n",
      "Epoch 1/80\n",
      "33/33 [==============================] - 2s 27ms/step - loss: 22.4228 - val_loss: 0.0335 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.2365 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0175 - val_loss: 0.0428 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0157 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0148 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0107 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0093 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0139 - val_loss: 0.0171 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0142 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0134 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0145 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0259 - val_loss: 0.0364 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.0141 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.0156 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0186 - val_loss: 0.0273 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0151 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0145 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0191 - val_loss: 0.0180 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0121 - val_loss: 0.0157 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0175 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0145 - val_loss: 0.0094 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0099 - val_loss: 0.0177 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0100 - val_loss: 0.0126 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0249 - val_loss: 0.0125 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0140 - val_loss: 0.0115 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0155 - val_loss: 0.0087 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0160 - val_loss: 0.0109 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0114 - val_loss: 0.0083 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0073 - val_loss: 0.0079 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0086 - val_loss: 0.0219 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0116 - val_loss: 0.0094 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0094 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0062 - val_loss: 0.0095 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0066 - val_loss: 0.0088 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0070 - val_loss: 0.0109 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0076 - val_loss: 0.0088 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0063 - val_loss: 0.0106 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0060 - val_loss: 0.0095 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0058 - val_loss: 0.0095 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0055 - val_loss: 0.0083 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0055 - val_loss: 0.0083 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.0054 - val_loss: 0.0079 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0056 - val_loss: 0.0079 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0055 - val_loss: 0.0080 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0054 - val_loss: 0.0080 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0077 - lr: 5.5023e-05\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0051 - val_loss: 0.0076 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0059 - val_loss: 0.0087 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0049 - val_loss: 0.0078 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0081 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.0051 - val_loss: 0.0076 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.0050 - val_loss: 0.0078 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0077 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0049 - val_loss: 0.0076 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0049 - val_loss: 0.0077 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.0049 - val_loss: 0.0077 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0049 - val_loss: 0.0077 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0078 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0047 - val_loss: 0.0077 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.0047 - val_loss: 0.0076 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0048 - val_loss: 0.0076 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 2.4011265844828156%\n",
      "Testing performance for batch_size : 15\n",
      "Epoch 1/80\n",
      "22/22 [==============================] - 2s 36ms/step - loss: 35.3656 - val_loss: 1.4487 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.7898 - val_loss: 0.1871 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0496 - val_loss: 0.0567 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0231 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0247 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0131 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0195 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0218 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0110 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0203 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0147 - val_loss: 0.0324 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0464 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0248 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.0404 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0276 - val_loss: 0.0354 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0840 - val_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0282 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0350 - val_loss: 0.0368 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0348 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.0217 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0112 - val_loss: 0.0089 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0127 - val_loss: 0.0250 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0188 - val_loss: 0.0134 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0109 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.0146 - val_loss: 0.0108 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.0113 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0227 - val_loss: 0.0123 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0094 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0071 - val_loss: 0.0131 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0349 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0142 - val_loss: 0.0165 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0173 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.0104 - val_loss: 0.0083 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0119 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0082 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0094 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0111 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0081 - lr: 1.4957e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0082 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0102 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0089 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0110 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0081 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0089 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0086 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0087 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0082 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0092 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0079 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0080 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0079 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The MAPE for the test set is: 2.4082838130626634%\n",
      "Testing performance for batch_size : 25\n",
      "Epoch 1/80\n",
      "14/14 [==============================] - 1s 32ms/step - loss: 55.1643 - val_loss: 1.4518 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.7487 - val_loss: 0.1031 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1080 - val_loss: 0.4023 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1347 - val_loss: 0.1352 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0969 - val_loss: 0.3677 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2210 - val_loss: 0.3321 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1042 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0354 - val_loss: 0.0310 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0218 - val_loss: 0.2333 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6508 - val_loss: 0.0258 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0327 - val_loss: 0.0478 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0183 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0543 - val_loss: 0.1154 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1118 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0487 - val_loss: 0.0484 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0397 - val_loss: 0.0755 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0550 - val_loss: 0.1346 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0795 - val_loss: 0.0709 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0467 - val_loss: 0.0135 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0110 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0095 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0290 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0192 - val_loss: 0.0278 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0090 - lr: 4.4933e-04\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0161 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.0143 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0085 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0122 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0096 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0100 - val_loss: 0.0095 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0087 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0208 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0109 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0094 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0086 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0090 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0070 - val_loss: 0.0100 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0084 - val_loss: 0.0089 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0085 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0085 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0085 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0087 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0114 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0091 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0084 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0092 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0084 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0086 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0089 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0083 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0086 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0085 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0085 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 2.5110972281541124%\n",
      "Testing performance for batch_size : 35\n",
      "Epoch 1/80\n",
      "10/10 [==============================] - 2s 47ms/step - loss: 99.7767 - val_loss: 2.7395 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 1.9067 - val_loss: 0.9900 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.8287 - val_loss: 0.4923 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3132 - val_loss: 0.1812 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0558 - val_loss: 0.0184 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0237 - val_loss: 0.0307 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0207 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0182 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0206 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0178 - val_loss: 0.0200 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0240 - val_loss: 0.0358 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0176 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0149 - val_loss: 0.0153 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0288 - val_loss: 0.1353 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0626 - val_loss: 0.3494 - lr: 0.0010\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1839 - val_loss: 0.1505 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2215 - val_loss: 0.2822 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1229 - val_loss: 0.0380 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0480 - val_loss: 0.0117 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0149 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0108 - val_loss: 0.0098 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0091 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0140 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0137 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0172 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0130 - val_loss: 0.0240 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0255 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0141 - val_loss: 0.0130 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0098 - val_loss: 0.0097 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0106 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0076 - val_loss: 0.0090 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0076 - val_loss: 0.0088 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0088 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0089 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0091 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0099 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0086 - val_loss: 0.0087 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0092 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0108 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0124 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0127 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0107 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0099 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0087 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0072 - val_loss: 0.0089 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0086 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0086 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0087 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0086 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0086 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.618036114430654%\n",
      "Testing performance for batch_size : 45\n",
      "Epoch 1/80\n",
      "8/8 [==============================] - 1s 53ms/step - loss: 147.2787 - val_loss: 0.1299 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 3.1827 - val_loss: 4.6942 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 1.7091 - val_loss: 0.6861 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.6222 - val_loss: 0.0250 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2008 - val_loss: 0.2456 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1223 - val_loss: 0.0202 - lr: 0.0010\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0758 - val_loss: 0.1387 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0664 - val_loss: 0.0300 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0200 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0141 - val_loss: 0.0287 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0166 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0114 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0112 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0097 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0105 - val_loss: 0.0132 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0139 - val_loss: 0.0354 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0177 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0207 - val_loss: 0.0413 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0393 - val_loss: 0.0206 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0109 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0077 - val_loss: 0.0110 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0084 - val_loss: 0.0110 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0075 - val_loss: 0.0149 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0105 - val_loss: 0.0221 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0116 - val_loss: 0.0092 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0072 - val_loss: 0.0097 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0074 - val_loss: 0.0091 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0074 - val_loss: 0.0097 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.0090 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0075 - val_loss: 0.0089 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0094 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0091 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0070 - val_loss: 0.0090 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0091 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0089 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0092 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0070 - val_loss: 0.0089 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0089 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0100 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0072 - val_loss: 0.0097 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0103 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0090 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0088 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0088 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0088 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0088 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0066 - val_loss: 0.0088 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0066 - val_loss: 0.0087 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0088 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0088 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0087 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 3.0276e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "The MAPE for the test set is: 2.416676295094758%\n"
     ]
    }
   ],
   "source": [
    "# List of batch sizes to test\n",
    "batch_sizes = [7,8,10,15,25,35,45]\n",
    "\n",
    "# List to store average percentage differences for each batch size\n",
    "avg_percentages_diffs_batch_sizes = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing performance for batch_size : {batch_size}\")\n",
    "    avg_percentages_diffs_batch_size = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,batch_size=batch_size)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_batch_sizes.append(avg_percentages_diffs_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "206ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(batch_sizes, avg_percentages_diffs_batch_sizes, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. Batch sizes')\n",
    "plt.xlabel('Batch sizes')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "plt.savefig('batch_sizes.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f52712",
   "metadata": {},
   "source": [
    "### 6 - Number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "405e2ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance for epochs : 5\n",
      "Epoch 1/5\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 49.4440 - val_loss: 1.2922 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4747 - val_loss: 0.3035 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1026 - val_loss: 0.0286 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0148 - val_loss: 0.0199 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0200 - val_loss: 0.0109 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "The MAPE for the test set is: 3.0562682304805526%\n",
      "Testing performance for epochs : 10\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 48.7164 - val_loss: 0.0305 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.1391 - val_loss: 0.8793 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6953 - val_loss: 0.6275 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1615 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0191 - val_loss: 0.0167 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0521 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0309 - val_loss: 0.0388 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0317 - val_loss: 0.0457 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0424 - val_loss: 0.2929 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1099 - val_loss: 0.1465 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 14.955589050924129%\n",
      "Testing performance for epochs : 20\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 58.3800 - val_loss: 0.1570 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6817 - val_loss: 0.2022 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1431 - val_loss: 0.0493 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0395 - val_loss: 0.0112 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0299 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1704 - val_loss: 0.3226 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2098 - val_loss: 0.3468 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1411 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0317 - val_loss: 0.1930 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0814 - val_loss: 0.0369 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0319 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0332 - val_loss: 0.0190 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0809 - val_loss: 0.0301 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0260 - val_loss: 0.0151 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0781 - val_loss: 0.1344 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1398 - val_loss: 0.5147 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1182 - val_loss: 0.0146 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0539 - val_loss: 0.0397 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0542 - val_loss: 0.0205 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0331 - val_loss: 0.0283 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "The MAPE for the test set is: 5.593943536998801%\n",
      "Testing performance for epochs : 40\n",
      "Epoch 1/40\n",
      "17/17 [==============================] - 2s 30ms/step - loss: 59.4214 - val_loss: 0.2861 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3249 - val_loss: 0.0384 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1101 - val_loss: 0.0673 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2864 - val_loss: 0.0655 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0366 - val_loss: 0.0816 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1038 - val_loss: 0.0383 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0368 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0500 - val_loss: 0.1515 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0485 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3807 - val_loss: 0.4883 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0863 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0620 - val_loss: 0.0205 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0288 - val_loss: 0.1069 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0293 - val_loss: 0.0211 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0302 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0572 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0761 - lr: 9.0484e-04\n",
      "Epoch 22/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0476 - val_loss: 0.0246 - lr: 8.1873e-04\n",
      "Epoch 23/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0121 - lr: 7.4082e-04\n",
      "Epoch 24/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0085 - lr: 6.7032e-04\n",
      "Epoch 25/40\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0089 - lr: 6.0653e-04\n",
      "Epoch 26/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0081 - lr: 5.4881e-04\n",
      "Epoch 27/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0128 - lr: 4.9659e-04\n",
      "Epoch 28/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0085 - lr: 4.4933e-04\n",
      "Epoch 29/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0092 - lr: 4.0657e-04\n",
      "Epoch 30/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0129 - lr: 3.6788e-04\n",
      "Epoch 31/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0079 - lr: 3.3287e-04\n",
      "Epoch 32/40\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0103 - lr: 3.0119e-04\n",
      "Epoch 33/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0091 - lr: 2.7253e-04\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0080 - lr: 2.4660e-04\n",
      "Epoch 35/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 2.2313e-04\n",
      "Epoch 36/40\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0076 - lr: 2.0190e-04\n",
      "Epoch 37/40\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 1.8268e-04\n",
      "Epoch 38/40\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0146 - lr: 1.6530e-04\n",
      "Epoch 39/40\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0082 - val_loss: 0.0104 - lr: 1.4957e-04\n",
      "Epoch 40/40\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0078 - lr: 1.3534e-04\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "The MAPE for the test set is: 2.5036713094994303%\n",
      "Testing performance for epochs : 60\n",
      "Epoch 1/60\n",
      "17/17 [==============================] - 2s 36ms/step - loss: 43.6861 - val_loss: 2.1561 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 1.4059 - val_loss: 0.0449 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1935 - val_loss: 0.0154 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0258 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0525 - val_loss: 0.1811 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1816 - val_loss: 0.3166 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1301 - val_loss: 0.2184 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0931 - val_loss: 0.0516 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0348 - val_loss: 0.0346 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0220 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0312 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0186 - val_loss: 0.0388 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0205 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0311 - val_loss: 0.0340 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1602 - val_loss: 0.3913 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.2086 - val_loss: 0.1414 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1451 - val_loss: 0.0773 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0475 - val_loss: 0.0411 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0241 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0100 - lr: 9.0484e-04\n",
      "Epoch 22/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0089 - lr: 8.1873e-04\n",
      "Epoch 23/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0093 - lr: 7.4082e-04\n",
      "Epoch 24/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0091 - lr: 6.7032e-04\n",
      "Epoch 25/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0089 - lr: 6.0653e-04\n",
      "Epoch 26/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0166 - lr: 5.4881e-04\n",
      "Epoch 27/60\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0087 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0107 - lr: 4.4933e-04\n",
      "Epoch 29/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0128 - lr: 4.0657e-04\n",
      "Epoch 30/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0084 - lr: 3.6788e-04\n",
      "Epoch 31/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0131 - lr: 3.3287e-04\n",
      "Epoch 32/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0157 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0088 - lr: 2.7253e-04\n",
      "Epoch 34/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0112 - lr: 2.4660e-04\n",
      "Epoch 35/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0083 - lr: 2.2313e-04\n",
      "Epoch 36/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0084 - lr: 2.0190e-04\n",
      "Epoch 37/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0082 - lr: 1.8268e-04\n",
      "Epoch 38/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0084 - lr: 1.6530e-04\n",
      "Epoch 39/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0085 - lr: 1.4957e-04\n",
      "Epoch 40/60\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0128 - lr: 1.3534e-04\n",
      "Epoch 41/60\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0082 - val_loss: 0.0082 - lr: 1.2246e-04\n",
      "Epoch 42/60\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0085 - lr: 1.1080e-04\n",
      "Epoch 43/60\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 1.0026e-04\n",
      "Epoch 44/60\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0069 - val_loss: 0.0081 - lr: 9.0718e-05\n",
      "Epoch 45/60\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0065 - val_loss: 0.0081 - lr: 8.2085e-05\n",
      "Epoch 46/60\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 7.4274e-05\n",
      "Epoch 47/60\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 6.7206e-05\n",
      "Epoch 48/60\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 6.0810e-05\n",
      "Epoch 49/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0089 - lr: 5.5023e-05\n",
      "Epoch 50/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0088 - lr: 4.9787e-05\n",
      "Epoch 51/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0080 - lr: 4.5049e-05\n",
      "Epoch 52/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0086 - lr: 4.0762e-05\n",
      "Epoch 53/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0082 - lr: 3.6883e-05\n",
      "Epoch 54/60\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 3.3373e-05\n",
      "Epoch 55/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 3.0197e-05\n",
      "Epoch 56/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.7324e-05\n",
      "Epoch 57/60\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 2.4724e-05\n",
      "Epoch 58/60\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 2.2371e-05\n",
      "Epoch 59/60\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 2.0242e-05\n",
      "Epoch 60/60\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 1.8316e-05\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.4852029285320305%\n",
      "Testing performance for epochs : 80\n",
      "Epoch 1/80\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 22.2051 - val_loss: 0.5050 - lr: 0.0010\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4131 - val_loss: 0.1174 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0667 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0398 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0301 - val_loss: 0.0485 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0244 - val_loss: 0.0163 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0166 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0356 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0251 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0380 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0480 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0335 - val_loss: 0.0486 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2077 - val_loss: 0.2228 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.1575 - val_loss: 0.0525 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.0324 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0213 - val_loss: 0.0304 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0093 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0095 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0172 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0090 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0088 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0161 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0087 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0069 - val_loss: 0.0099 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0072 - val_loss: 0.0118 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0114 - val_loss: 0.0100 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0115 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0153 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0083 - val_loss: 0.0097 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0090 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0088 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0090 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0087 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0084 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0139 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0091 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0097 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0089 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0086 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0088 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0086 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0083 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0084 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0085 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0082 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0083 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 5.5166e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0082 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0083 - lr: 2.4788e-06\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.435416022005242%\n",
      "Testing performance for epochs : 100\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 99.0021 - val_loss: 1.0168 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.8593 - val_loss: 0.8676 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4143 - val_loss: 0.4378 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0904 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0227 - val_loss: 0.0134 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0514 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0276 - val_loss: 0.0547 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0361 - val_loss: 0.0387 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0204 - val_loss: 0.0162 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0164 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0158 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0308 - val_loss: 0.0292 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0939 - val_loss: 0.1924 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0531 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0633 - val_loss: 0.2347 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1357 - val_loss: 0.1126 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0322 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0160 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0236 - val_loss: 0.0643 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0588 - val_loss: 0.0156 - lr: 9.0484e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0111 - val_loss: 0.0106 - lr: 8.1873e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0085 - val_loss: 0.0088 - lr: 7.4082e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0106 - val_loss: 0.0129 - lr: 6.7032e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0084 - val_loss: 0.0085 - lr: 6.0653e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0110 - val_loss: 0.0088 - lr: 5.4881e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0077 - val_loss: 0.0086 - lr: 4.9659e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0075 - val_loss: 0.0095 - lr: 4.4933e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0102 - lr: 4.0657e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0101 - val_loss: 0.0097 - lr: 3.6788e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0222 - lr: 3.3287e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0105 - lr: 3.0119e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0099 - val_loss: 0.0083 - lr: 2.7253e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 2.4660e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 2.2313e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 2.0190e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 1.8268e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0127 - lr: 1.6530e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0116 - lr: 1.4957e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0093 - lr: 1.3534e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0120 - lr: 1.2246e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0083 - lr: 1.1080e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0106 - lr: 1.0026e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0094 - lr: 9.0718e-05\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0089 - lr: 8.2085e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0083 - lr: 7.4274e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0083 - lr: 6.7206e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 6.0810e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0093 - lr: 5.5023e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0085 - lr: 4.9787e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 4.5049e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 4.0762e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 3.6883e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 3.3373e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 3.0197e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 2.7324e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 2.4724e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 2.2371e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 2.0242e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0082 - lr: 1.8316e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 1.6573e-05\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0083 - lr: 1.4996e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 1.3569e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.2277e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 1.1109e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 1.0052e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 9.0953e-06\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 8.2298e-06\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 7.4466e-06\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0082 - lr: 6.7379e-06\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 6.0967e-06\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 5.5166e-06\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.9916e-06\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.5166e-06\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.0868e-06\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 3.6979e-06\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 3.3460e-06\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 3.0276e-06\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 2.7394e-06\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 2.4788e-06\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 2.2429e-06\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 2.0294e-06\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.8363e-06\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.6616e-06\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.5034e-06\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.3604e-06\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.2309e-06\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.1138e-06\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 1.0078e-06\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 9.1188e-07\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 8.2511e-07\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 7.4659e-07\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 6.7554e-07\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 6.1125e-07\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 5.5308e-07\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 5.0045e-07\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.5283e-07\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.0974e-07\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 3.7074e-07\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 3.3546e-07\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The MAPE for the test set is: 2.499574857529858%\n",
      "Testing performance for epochs : 120\n",
      "Epoch 1/120\n",
      "17/17 [==============================] - 2s 39ms/step - loss: 29.8518 - val_loss: 0.0460 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.5259 - val_loss: 0.2688 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.1369 - val_loss: 0.0556 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0932 - val_loss: 0.0731 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0344 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.0412 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0254 - val_loss: 0.0393 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0265 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0196 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0166 - val_loss: 0.0207 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0177 - val_loss: 0.0127 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0177 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0200 - val_loss: 0.1220 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0962 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0377 - val_loss: 0.0189 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0441 - val_loss: 0.0533 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0268 - val_loss: 0.0165 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0114 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0101 - lr: 9.0484e-04\n",
      "Epoch 22/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0248 - lr: 8.1873e-04\n",
      "Epoch 23/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0095 - val_loss: 0.0087 - lr: 7.4082e-04\n",
      "Epoch 24/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0120 - lr: 6.7032e-04\n",
      "Epoch 25/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0087 - lr: 6.0653e-04\n",
      "Epoch 26/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0091 - lr: 5.4881e-04\n",
      "Epoch 27/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0092 - lr: 4.9659e-04\n",
      "Epoch 28/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0097 - lr: 4.4933e-04\n",
      "Epoch 29/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0098 - lr: 4.0657e-04\n",
      "Epoch 30/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0111 - val_loss: 0.0111 - lr: 3.6788e-04\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0199 - lr: 3.3287e-04\n",
      "Epoch 32/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 0.0106 - lr: 3.0119e-04\n",
      "Epoch 33/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 0.0081 - lr: 2.7253e-04\n",
      "Epoch 34/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 2.4660e-04\n",
      "Epoch 35/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0082 - lr: 2.2313e-04\n",
      "Epoch 36/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 2.0190e-04\n",
      "Epoch 37/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 1.8268e-04\n",
      "Epoch 38/120\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0071 - val_loss: 0.0111 - lr: 1.6530e-04\n",
      "Epoch 39/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0102 - lr: 1.4957e-04\n",
      "Epoch 40/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0096 - lr: 1.3534e-04\n",
      "Epoch 41/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0112 - lr: 1.2246e-04\n",
      "Epoch 42/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 1.1080e-04\n",
      "Epoch 43/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0106 - lr: 1.0026e-04\n",
      "Epoch 44/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0071 - val_loss: 0.0091 - lr: 9.0718e-05\n",
      "Epoch 45/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0087 - lr: 8.2085e-05\n",
      "Epoch 46/120\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 7.4274e-05\n",
      "Epoch 47/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0081 - lr: 6.7206e-05\n",
      "Epoch 48/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 6.0810e-05\n",
      "Epoch 49/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0092 - lr: 5.5023e-05\n",
      "Epoch 50/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0086 - lr: 4.9787e-05\n",
      "Epoch 51/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0082 - lr: 4.5049e-05\n",
      "Epoch 52/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0082 - lr: 4.0762e-05\n",
      "Epoch 53/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 3.6883e-05\n",
      "Epoch 54/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0081 - lr: 3.3373e-05\n",
      "Epoch 55/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0081 - lr: 3.0197e-05\n",
      "Epoch 56/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 2.7324e-05\n",
      "Epoch 57/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0082 - lr: 2.4724e-05\n",
      "Epoch 58/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 2.2371e-05\n",
      "Epoch 59/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0085 - lr: 2.0242e-05\n",
      "Epoch 60/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0080 - lr: 1.8316e-05\n",
      "Epoch 61/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 1.6573e-05\n",
      "Epoch 62/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0082 - lr: 1.4996e-05\n",
      "Epoch 63/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 1.3569e-05\n",
      "Epoch 64/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.2277e-05\n",
      "Epoch 65/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0080 - lr: 1.1109e-05\n",
      "Epoch 66/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 1.0052e-05\n",
      "Epoch 67/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 9.0953e-06\n",
      "Epoch 68/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0081 - lr: 8.2298e-06\n",
      "Epoch 69/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 7.4466e-06\n",
      "Epoch 70/120\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 6.7379e-06\n",
      "Epoch 71/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 6.0967e-06\n",
      "Epoch 72/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 5.5166e-06\n",
      "Epoch 73/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 4.9916e-06\n",
      "Epoch 74/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 4.5166e-06\n",
      "Epoch 75/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 4.0868e-06\n",
      "Epoch 76/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.6979e-06\n",
      "Epoch 77/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 3.3460e-06\n",
      "Epoch 78/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.0276e-06\n",
      "Epoch 79/120\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.7394e-06\n",
      "Epoch 80/120\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 2.4788e-06\n",
      "Epoch 81/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.2429e-06\n",
      "Epoch 82/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.0294e-06\n",
      "Epoch 83/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.8363e-06\n",
      "Epoch 84/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.6616e-06\n",
      "Epoch 85/120\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.5034e-06\n",
      "Epoch 86/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.3604e-06\n",
      "Epoch 87/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.2309e-06\n",
      "Epoch 88/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.1138e-06\n",
      "Epoch 89/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 1.0078e-06\n",
      "Epoch 90/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 9.1188e-07\n",
      "Epoch 91/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 8.2511e-07\n",
      "Epoch 92/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 7.4659e-07\n",
      "Epoch 93/120\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0058 - val_loss: 0.0081 - lr: 6.7554e-07\n",
      "Epoch 94/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 6.1125e-07\n",
      "Epoch 95/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 5.5308e-07\n",
      "Epoch 96/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 5.0045e-07\n",
      "Epoch 97/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 4.5283e-07\n",
      "Epoch 98/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 4.0974e-07\n",
      "Epoch 99/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.7074e-07\n",
      "Epoch 100/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.3546e-07\n",
      "Epoch 101/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 3.0354e-07\n",
      "Epoch 102/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.7465e-07\n",
      "Epoch 103/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.4852e-07\n",
      "Epoch 104/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.2487e-07\n",
      "Epoch 105/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 2.0347e-07\n",
      "Epoch 106/120\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.8411e-07\n",
      "Epoch 107/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.6659e-07\n",
      "Epoch 108/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.5073e-07\n",
      "Epoch 109/120\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.3639e-07\n",
      "Epoch 110/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.2341e-07\n",
      "Epoch 111/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.1167e-07\n",
      "Epoch 112/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 1.0104e-07\n",
      "Epoch 113/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 9.1424e-08\n",
      "Epoch 114/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 8.2724e-08\n",
      "Epoch 115/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 7.4852e-08\n",
      "Epoch 116/120\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 6.7729e-08\n",
      "Epoch 117/120\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 6.1284e-08\n",
      "Epoch 118/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 5.5452e-08\n",
      "Epoch 119/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 5.0175e-08\n",
      "Epoch 120/120\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0080 - lr: 4.5400e-08\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "The MAPE for the test set is: 2.5232107027645614%\n",
      "Testing performance for epochs : 140\n",
      "Epoch 1/140\n",
      "17/17 [==============================] - 2s 28ms/step - loss: 67.2019 - val_loss: 2.6006 - lr: 0.0010\n",
      "Epoch 2/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6937 - val_loss: 0.0582 - lr: 0.0010\n",
      "Epoch 3/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0955 - val_loss: 0.0393 - lr: 0.0010\n",
      "Epoch 4/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0229 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 5/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 6/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 7/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0260 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 8/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0261 - val_loss: 0.0191 - lr: 0.0010\n",
      "Epoch 9/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0238 - val_loss: 0.1840 - lr: 0.0010\n",
      "Epoch 10/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0674 - val_loss: 0.0716 - lr: 0.0010\n",
      "Epoch 11/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0436 - val_loss: 0.0365 - lr: 0.0010\n",
      "Epoch 12/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0474 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 13/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0743 - val_loss: 0.0153 - lr: 0.0010\n",
      "Epoch 14/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0176 - val_loss: 0.0413 - lr: 0.0010\n",
      "Epoch 15/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0244 - val_loss: 0.0201 - lr: 0.0010\n",
      "Epoch 16/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1835 - val_loss: 0.4619 - lr: 0.0010\n",
      "Epoch 17/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.2299 - val_loss: 0.0144 - lr: 0.0010\n",
      "Epoch 18/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.1215 - val_loss: 0.0382 - lr: 0.0010\n",
      "Epoch 19/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0498 - val_loss: 0.0576 - lr: 0.0010\n",
      "Epoch 20/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0309 - val_loss: 0.0193 - lr: 0.0010\n",
      "Epoch 21/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0209 - val_loss: 0.0104 - lr: 9.0484e-04\n",
      "Epoch 22/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0092 - val_loss: 0.0094 - lr: 8.1873e-04\n",
      "Epoch 23/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0107 - lr: 7.4082e-04\n",
      "Epoch 24/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0088 - lr: 6.7032e-04\n",
      "Epoch 25/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0088 - lr: 6.0653e-04\n",
      "Epoch 26/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0150 - lr: 5.4881e-04\n",
      "Epoch 27/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0090 - val_loss: 0.0088 - lr: 4.9659e-04\n",
      "Epoch 28/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0118 - lr: 4.4933e-04\n",
      "Epoch 29/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0117 - lr: 4.0657e-04\n",
      "Epoch 30/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0128 - val_loss: 0.0086 - lr: 3.6788e-04\n",
      "Epoch 31/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0112 - lr: 3.3287e-04\n",
      "Epoch 32/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0144 - lr: 3.0119e-04\n",
      "Epoch 33/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.0097 - lr: 2.7253e-04\n",
      "Epoch 34/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0118 - lr: 2.4660e-04\n",
      "Epoch 35/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0087 - lr: 2.2313e-04\n",
      "Epoch 36/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 2.0190e-04\n",
      "Epoch 37/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0065 - val_loss: 0.0085 - lr: 1.8268e-04\n",
      "Epoch 38/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0086 - lr: 1.6530e-04\n",
      "Epoch 39/140\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0080 - val_loss: 0.0089 - lr: 1.4957e-04\n",
      "Epoch 40/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0084 - val_loss: 0.0138 - lr: 1.3534e-04\n",
      "Epoch 41/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0085 - lr: 1.2246e-04\n",
      "Epoch 42/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0090 - lr: 1.1080e-04\n",
      "Epoch 43/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0086 - lr: 1.0026e-04\n",
      "Epoch 44/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0084 - lr: 9.0718e-05\n",
      "Epoch 45/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0084 - lr: 8.2085e-05\n",
      "Epoch 46/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 7.4274e-05\n",
      "Epoch 47/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 6.7206e-05\n",
      "Epoch 48/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0063 - val_loss: 0.0084 - lr: 6.0810e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0092 - lr: 5.5023e-05\n",
      "Epoch 50/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0093 - lr: 4.9787e-05\n",
      "Epoch 51/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 4.5049e-05\n",
      "Epoch 52/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0087 - lr: 4.0762e-05\n",
      "Epoch 53/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0085 - lr: 3.6883e-05\n",
      "Epoch 54/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 3.3373e-05\n",
      "Epoch 55/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 3.0197e-05\n",
      "Epoch 56/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 2.7324e-05\n",
      "Epoch 57/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0085 - lr: 2.4724e-05\n",
      "Epoch 58/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 2.2371e-05\n",
      "Epoch 59/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0086 - lr: 2.0242e-05\n",
      "Epoch 60/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0062 - val_loss: 0.0084 - lr: 1.8316e-05\n",
      "Epoch 61/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.6573e-05\n",
      "Epoch 62/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.4996e-05\n",
      "Epoch 63/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 1.3569e-05\n",
      "Epoch 64/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.2277e-05\n",
      "Epoch 65/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 1.1109e-05\n",
      "Epoch 66/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0084 - lr: 1.0052e-05\n",
      "Epoch 67/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 9.0953e-06\n",
      "Epoch 68/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 8.2298e-06\n",
      "Epoch 69/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 7.4466e-06\n",
      "Epoch 70/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0084 - lr: 6.7379e-06\n",
      "Epoch 71/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 6.0967e-06\n",
      "Epoch 72/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 5.5166e-06\n",
      "Epoch 73/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 4.9916e-06\n",
      "Epoch 74/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 4.5166e-06\n",
      "Epoch 75/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 4.0868e-06\n",
      "Epoch 76/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 3.6979e-06\n",
      "Epoch 77/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 3.3460e-06\n",
      "Epoch 78/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 3.0276e-06\n",
      "Epoch 79/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 2.7394e-06\n",
      "Epoch 80/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 2.4788e-06\n",
      "Epoch 81/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 2.2429e-06\n",
      "Epoch 82/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.0294e-06\n",
      "Epoch 83/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.8363e-06\n",
      "Epoch 84/140\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.6616e-06\n",
      "Epoch 85/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.5034e-06\n",
      "Epoch 86/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.3604e-06\n",
      "Epoch 87/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.2309e-06\n",
      "Epoch 88/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.1138e-06\n",
      "Epoch 89/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.0078e-06\n",
      "Epoch 90/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 9.1188e-07\n",
      "Epoch 91/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 8.2511e-07\n",
      "Epoch 92/140\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 7.4659e-07\n",
      "Epoch 93/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.7554e-07\n",
      "Epoch 94/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.1125e-07\n",
      "Epoch 95/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 5.5308e-07\n",
      "Epoch 96/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 5.0045e-07\n",
      "Epoch 97/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 4.5283e-07\n",
      "Epoch 98/140\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 4.0974e-07\n",
      "Epoch 99/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.7074e-07\n",
      "Epoch 100/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.3546e-07\n",
      "Epoch 101/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.0354e-07\n",
      "Epoch 102/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.7465e-07\n",
      "Epoch 103/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.4852e-07\n",
      "Epoch 104/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.2487e-07\n",
      "Epoch 105/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.0347e-07\n",
      "Epoch 106/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.8411e-07\n",
      "Epoch 107/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.6659e-07\n",
      "Epoch 108/140\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.5073e-07\n",
      "Epoch 109/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.3639e-07\n",
      "Epoch 110/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.2341e-07\n",
      "Epoch 111/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.1167e-07\n",
      "Epoch 112/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.0104e-07\n",
      "Epoch 113/140\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 9.1424e-08\n",
      "Epoch 114/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 8.2724e-08\n",
      "Epoch 115/140\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 7.4852e-08\n",
      "Epoch 116/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.7729e-08\n",
      "Epoch 117/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.1284e-08\n",
      "Epoch 118/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 5.5452e-08\n",
      "Epoch 119/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 5.0175e-08\n",
      "Epoch 120/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 4.5400e-08\n",
      "Epoch 121/140\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 4.1080e-08\n",
      "Epoch 122/140\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.7170e-08\n",
      "Epoch 123/140\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.3633e-08\n",
      "Epoch 124/140\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 3.0433e-08\n",
      "Epoch 125/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.7536e-08\n",
      "Epoch 126/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.4916e-08\n",
      "Epoch 127/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.2545e-08\n",
      "Epoch 128/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 2.0400e-08\n",
      "Epoch 129/140\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.8458e-08\n",
      "Epoch 130/140\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.6702e-08\n",
      "Epoch 131/140\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.5112e-08\n",
      "Epoch 132/140\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.3674e-08\n",
      "Epoch 133/140\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.2373e-08\n",
      "Epoch 134/140\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.1195e-08\n",
      "Epoch 135/140\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 1.0130e-08\n",
      "Epoch 136/140\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 9.1661e-09\n",
      "Epoch 137/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 8.2938e-09\n",
      "Epoch 138/140\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 7.5046e-09\n",
      "Epoch 139/140\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.7904e-09\n",
      "Epoch 140/140\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0059 - val_loss: 0.0083 - lr: 6.1442e-09\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "The MAPE for the test set is: 2.4338180848358255%\n"
     ]
    }
   ],
   "source": [
    "# List of number of epochs to test\n",
    "epochs = [5,10,20,40,60,80,100,120,140]\n",
    "\n",
    "# List to store average percentage differences for each number of epochs\n",
    "avg_percentages_diffs_epochs = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(f\"Testing performance for epochs : {epoch}\")\n",
    "    avg_percentages_diffs_epoch = train_and_evaluate_yearly_basis_select_parameters(google_trends_data, True,epochs=epoch)\n",
    "\n",
    "    # Append the average percentage difference to the list\n",
    "    avg_percentages_diffs_epochs.append(avg_percentages_diffs_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f068762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(epochs, avg_percentages_diffs_epochs, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average MAPE vs. Number of epochs')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Average MAPE')\n",
    "plt.grid(True)\n",
    "plt.savefig('epochs.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fe764",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092bfbfc",
   "metadata": {},
   "source": [
    "### R&D ESTIMATION ON A QUARTERLY BASIS (GOOGLE TRENDS DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b84f8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracts_google_trends_quarterly_data(merged_data_google_trends, features_kept):\n",
    "    \"\"\"\n",
    "    Extract quarterly Google Trends data from a merged DataFrame.\n",
    "\n",
    "    This function extracts quarterly Google Trends data (specified by quartiles) from the merged DataFrame\n",
    "    'merged_data_google_trends'. It also calculates the sum of features for each quarter and returns separate\n",
    "    DataFrames for each quarter (quarter1, quarter2, quarter3, quarter4) and the sum across all quarters (quartersum).\n",
    "\n",
    "    Parameters:\n",
    "        merged_data_google_trends (pandas.DataFrame): The merged DataFrame containing Google Trends data.\n",
    "        features_kept (list of str): List of feature column names to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple of DataFrames: A tuple containing the following DataFrames:\n",
    "            - quarter1: DataFrame containing data for the first quartile.\n",
    "            - quarter2: DataFrame containing data for the second quartile.\n",
    "            - quarter3: DataFrame containing data for the third quartile.\n",
    "            - quarter4: DataFrame containing data for the fourth quartile.\n",
    "            - quartersum: DataFrame containing the sum of features across all quarters.\n",
    "    \"\"\"\n",
    "    # Keep only relevant columns and reset the index\n",
    "    df = merged_data_google_trends.loc[:, features_kept + [\"ISO\", \"year\", \"quartile\"]].reset_index(drop=True)\n",
    "    \n",
    "    # Extracting quartile 1\n",
    "    quarter1 = df[df[\"quartile\"] == 1]\n",
    "    quarter1 = quarter1.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter1.columns = [col + \"_1\" if col != \"ISO\" and col != \"year\" else col for col in quarter1.columns ]\n",
    "\n",
    "    # Extracting quartile 2\n",
    "    quarter2 = df[df[\"quartile\"] == 2]\n",
    "    quarter2 = quarter2.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter2.columns = [col + \"_2\" if col != \"ISO\" and col != \"year\" else col for col in quarter2.columns ]\n",
    "\n",
    "    # Extracting quartile 3\n",
    "    quarter3 = df[df[\"quartile\"] == 3]\n",
    "    quarter3 = quarter3.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter3.columns = [col + \"_3\" if col != \"ISO\" and col != \"year\" else col for col in quarter3.columns ]\n",
    "\n",
    "    # Extracting quartile 4\n",
    "    quarter4 = df[df[\"quartile\"] == 4]\n",
    "    quarter4 = quarter4.drop(axis=1, columns=[\"quartile\"])\n",
    "    # Renaming the columns to reflect which quarter this dataframe represents\n",
    "    quarter4.columns = [col + \"_4\" if col != \"ISO\" and col != \"year\" else col for col in quarter4.columns ]\n",
    "\n",
    "    # Calculate the sum of features for each quarter and reset the index\n",
    "    quartersum = df.groupby([\"ISO\", \"year\"]).sum()\n",
    "    quartersum = quartersum.drop(axis=1, columns=[\"quartile\"])\n",
    "    quartersum = quartersum.reset_index()\n",
    "    quartersum.columns = [col + \"_sum\" if col != \"ISO\" and col != \"year\" else col for col in quartersum.columns ]\n",
    "\n",
    "    return quarter1, quarter2, quarter3, quarter4, quartersum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39242303",
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter1,quarter2,quarter3,quarter4,quartersum = extracts_google_trends_quarterly_data(merged_data_google_trends,features_kept) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0f69a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web Apps &amp; Online Tools_1</th>\n",
       "      <th>Business Finance_1</th>\n",
       "      <th>Pharmaceutical Manufacturing_1</th>\n",
       "      <th>Data Management_y_1</th>\n",
       "      <th>Venture Capital_1</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech_1</th>\n",
       "      <th>Genetics_1</th>\n",
       "      <th>Automotive Industry_1</th>\n",
       "      <th>Nanobiotechnology_1</th>\n",
       "      <th>Software Utilities_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Genetics_sum</th>\n",
       "      <th>Automotive Industry_sum</th>\n",
       "      <th>Nanobiotechnology_sum</th>\n",
       "      <th>Software Utilities_sum</th>\n",
       "      <th>Oil &amp; Gas_sum</th>\n",
       "      <th>Renewable Energy_sum</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)_sum</th>\n",
       "      <th>Risk Management_sum</th>\n",
       "      <th>Environmental Science_sum</th>\n",
       "      <th>Artificial Intelligence_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>305.666667</td>\n",
       "      <td>325.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>332.666667</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>334.666667</td>\n",
       "      <td>317.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>314.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>336.666667</td>\n",
       "      <td>316.333333</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.333333</td>\n",
       "      <td>326.333333</td>\n",
       "      <td>321.666667</td>\n",
       "      <td>328.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.333333</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>90.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.666667</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>350.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>311.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>343.666667</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>266.666667</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>273.666667</td>\n",
       "      <td>334.333333</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>311.333333</td>\n",
       "      <td>334.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.333333</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>325.333333</td>\n",
       "      <td>330.666667</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>279.333333</td>\n",
       "      <td>269.666667</td>\n",
       "      <td>268.666667</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>330.333333</td>\n",
       "      <td>244.333333</td>\n",
       "      <td>311.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>158.666667</td>\n",
       "      <td>174.333333</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>257.333333</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>103.666667</td>\n",
       "      <td>174.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>146.666667</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>127.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>75.666667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>181.666667</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>166.333333</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>40.666667</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>123.666667</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>192.666667</td>\n",
       "      <td>367.333333</td>\n",
       "      <td>324.666667</td>\n",
       "      <td>324.666667</td>\n",
       "      <td>323.666667</td>\n",
       "      <td>369.666667</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>55.333333</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>177.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Web Apps & Online Tools_1  Business Finance_1  \\\n",
       "0                    68.333333           94.666667   \n",
       "1                    84.000000           81.000000   \n",
       "2                    53.333333           78.666667   \n",
       "3                    68.000000           93.333333   \n",
       "4                    49.333333           84.333333   \n",
       "..                         ...                 ...   \n",
       "139                  68.000000           69.333333   \n",
       "140                  42.000000            0.000000   \n",
       "141                  75.666667           54.000000   \n",
       "142                  40.666667           67.666667   \n",
       "143                  55.333333           65.333333   \n",
       "\n",
       "     Pharmaceutical Manufacturing_1  Data Management_y_1  Venture Capital_1  \\\n",
       "0                         94.000000            85.000000          51.666667   \n",
       "1                         89.000000            89.333333          26.000000   \n",
       "2                         83.666667            74.333333          36.000000   \n",
       "3                         77.333333            91.666667          36.000000   \n",
       "4                         63.000000            92.666667          15.333333   \n",
       "..                              ...                  ...                ...   \n",
       "139                       88.333333            64.333333           7.333333   \n",
       "140                        0.000000            50.333333          19.333333   \n",
       "141                       77.666667            33.000000           6.000000   \n",
       "142                       62.333333             0.000000          60.333333   \n",
       "143                       61.666667            53.000000          18.000000   \n",
       "\n",
       "     Pharmaceuticals & Biotech_1  Genetics_1  Automotive Industry_1  \\\n",
       "0                      96.333333   86.333333              82.333333   \n",
       "1                      92.000000   95.000000              79.000000   \n",
       "2                      74.000000    0.000000              83.666667   \n",
       "3                      94.666667   87.666667              91.666667   \n",
       "4                      91.333333   95.333333              94.666667   \n",
       "..                           ...         ...                    ...   \n",
       "139                    68.666667   42.000000              38.333333   \n",
       "140                    29.666667   27.000000              39.666667   \n",
       "141                    40.000000   41.666667              47.666667   \n",
       "142                    57.666667   29.333333              25.666667   \n",
       "143                    27.000000   37.000000              30.666667   \n",
       "\n",
       "     Nanobiotechnology_1  Software Utilities_1  ...  Genetics_sum  \\\n",
       "0              97.333333             95.000000  ...    305.666667   \n",
       "1              95.333333             82.333333  ...    336.666667   \n",
       "2              75.333333             90.666667  ...      0.000000   \n",
       "3              94.666667             72.333333  ...    307.000000   \n",
       "4              98.000000             84.333333  ...    325.333333   \n",
       "..                   ...                   ...  ...           ...   \n",
       "139            45.333333             32.000000  ...    172.000000   \n",
       "140            27.666667             46.000000  ...    100.000000   \n",
       "141            39.666667             38.666667  ...    181.666667   \n",
       "142            43.666667             90.000000  ...    123.666667   \n",
       "143            34.333333             53.666667  ...    124.666667   \n",
       "\n",
       "     Automotive Industry_sum  Nanobiotechnology_sum  Software Utilities_sum  \\\n",
       "0                 325.666667             336.000000              332.666667   \n",
       "1                 316.333333             346.000000              278.666667   \n",
       "2                 318.666667             307.666667              335.000000   \n",
       "3                 343.666667             344.000000              266.666667   \n",
       "4                 330.666667             345.000000              279.333333   \n",
       "..                       ...                    ...                     ...   \n",
       "139               158.666667             174.333333              124.666667   \n",
       "140               141.000000             103.666667              174.666667   \n",
       "141               190.000000             174.000000              166.333333   \n",
       "142                96.000000             192.666667              367.333333   \n",
       "143               108.000000             149.333333              204.333333   \n",
       "\n",
       "     Oil & Gas_sum  Renewable Energy_sum  \\\n",
       "0       337.000000            335.000000   \n",
       "1       327.000000            326.000000   \n",
       "2       335.000000            350.666667   \n",
       "3       268.000000            273.666667   \n",
       "4       269.666667            268.666667   \n",
       "..             ...                   ...   \n",
       "139     162.000000            162.000000   \n",
       "140     146.666667            146.666667   \n",
       "141      61.000000             61.666667   \n",
       "142     324.666667            324.666667   \n",
       "143     146.000000            146.000000   \n",
       "\n",
       "    Renewable Energy (Subcategory of Energy & Utilities)_sum  \\\n",
       "0                                           334.666667         \n",
       "1                                           326.333333         \n",
       "2                                           336.000000         \n",
       "3                                           334.333333         \n",
       "4                                           268.333333         \n",
       "..                                                 ...         \n",
       "139                                         163.000000         \n",
       "140                                         146.666667         \n",
       "141                                          61.333333         \n",
       "142                                         323.666667         \n",
       "143                                         147.333333         \n",
       "\n",
       "     Risk Management_sum  Environmental Science_sum  \\\n",
       "0             317.333333                 192.333333   \n",
       "1             326.333333                 321.666667   \n",
       "2             327.666667                 264.000000   \n",
       "3             365.000000                 311.333333   \n",
       "4             330.333333                 244.333333   \n",
       "..                   ...                        ...   \n",
       "139            97.666667                 257.333333   \n",
       "140           150.000000                 246.000000   \n",
       "141             0.000000                 249.000000   \n",
       "142           369.666667                 293.000000   \n",
       "143           116.333333                 195.000000   \n",
       "\n",
       "     Artificial Intelligence_sum  \n",
       "0                     314.333333  \n",
       "1                     328.333333  \n",
       "2                     311.333333  \n",
       "3                     334.666667  \n",
       "4                     311.666667  \n",
       "..                           ...  \n",
       "139                    92.000000  \n",
       "140                   127.333333  \n",
       "141                    93.000000  \n",
       "142                   215.000000  \n",
       "143                   177.333333  \n",
       "\n",
       "[144 rows x 82 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grouping all the quartiles dataframe together , this will be useful to train the model , and evaluate it later\n",
    "merged_quartiles = pd.merge(quarter1, quarter2, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quarter3, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quarter4, on=[\"ISO\", \"year\"], how='inner')\n",
    "merged_quartiles = pd.merge(merged_quartiles, quartersum, on=[\"ISO\", \"year\"], how='inner')\n",
    "\n",
    "merged_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "830e248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v-1</th>\n",
       "      <th>v</th>\n",
       "      <th>Web Apps &amp; Online Tools_sum</th>\n",
       "      <th>Business Finance_sum</th>\n",
       "      <th>Pharmaceutical Manufacturing_sum</th>\n",
       "      <th>Data Management_y_sum</th>\n",
       "      <th>Venture Capital_sum</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech_sum</th>\n",
       "      <th>Genetics_sum</th>\n",
       "      <th>Automotive Industry_sum</th>\n",
       "      <th>Nanobiotechnology_sum</th>\n",
       "      <th>Software Utilities_sum</th>\n",
       "      <th>Oil &amp; Gas_sum</th>\n",
       "      <th>Renewable Energy_sum</th>\n",
       "      <th>Renewable Energy (Subcategory of Energy &amp; Utilities)_sum</th>\n",
       "      <th>Risk Management_sum</th>\n",
       "      <th>Environmental Science_sum</th>\n",
       "      <th>Artificial Intelligence_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.971243</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>326.666667</td>\n",
       "      <td>327.333333</td>\n",
       "      <td>304.666667</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>340.666667</td>\n",
       "      <td>305.666667</td>\n",
       "      <td>325.666667</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>332.666667</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>334.666667</td>\n",
       "      <td>317.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>314.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.942999</td>\n",
       "      <td>-0.039421</td>\n",
       "      <td>306.666667</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>308.333333</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>295.333333</td>\n",
       "      <td>276.666667</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>309.666667</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>307.333333</td>\n",
       "      <td>271.333333</td>\n",
       "      <td>176.333333</td>\n",
       "      <td>245.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.903578</td>\n",
       "      <td>-0.047800</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>288.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>278.333333</td>\n",
       "      <td>271.666667</td>\n",
       "      <td>233.666667</td>\n",
       "      <td>221.666667</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>308.666667</td>\n",
       "      <td>312.333333</td>\n",
       "      <td>311.666667</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>196.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.855778</td>\n",
       "      <td>0.061638</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>249.666667</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>105.333333</td>\n",
       "      <td>221.333333</td>\n",
       "      <td>237.333333</td>\n",
       "      <td>233.666667</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>272.666667</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>274.666667</td>\n",
       "      <td>180.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>135.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.917415</td>\n",
       "      <td>-0.092138</td>\n",
       "      <td>303.333333</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>195.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>206.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>226.333333</td>\n",
       "      <td>234.666667</td>\n",
       "      <td>236.333333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2.853501</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>236.666667</td>\n",
       "      <td>201.666667</td>\n",
       "      <td>225.666667</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>153.333333</td>\n",
       "      <td>153.666667</td>\n",
       "      <td>153.333333</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>157.333333</td>\n",
       "      <td>168.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2.904324</td>\n",
       "      <td>0.105778</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>243.666667</td>\n",
       "      <td>225.666667</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>106.666667</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>102.666667</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>175.333333</td>\n",
       "      <td>203.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3.010102</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>224.666667</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>101.666667</td>\n",
       "      <td>148.666667</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>199.333333</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>205.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3.170487</td>\n",
       "      <td>0.297284</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>232.333333</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>134.666667</td>\n",
       "      <td>140.333333</td>\n",
       "      <td>200.666667</td>\n",
       "      <td>147.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>144.333333</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>165.666667</td>\n",
       "      <td>193.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3.467771</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>212.333333</td>\n",
       "      <td>274.333333</td>\n",
       "      <td>220.333333</td>\n",
       "      <td>208.333333</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>117.666667</td>\n",
       "      <td>124.666667</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>204.333333</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>116.333333</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>177.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          v-1         v  Web Apps & Online Tools_sum  Business Finance_sum  \\\n",
       "0    1.971243 -0.028245                   278.666667            326.666667   \n",
       "1    1.942999 -0.039421                   306.666667            293.000000   \n",
       "2    1.903578 -0.047800                   336.000000            288.666667   \n",
       "3    1.855778  0.061638                   302.000000            249.666667   \n",
       "4    1.917415 -0.092138                   303.333333            247.000000   \n",
       "..        ...       ...                          ...                   ...   \n",
       "123  2.853501  0.050823                   236.666667            201.666667   \n",
       "124  2.904324  0.105778                   235.000000            231.333333   \n",
       "125  3.010102  0.160385                   235.000000            224.666667   \n",
       "126  3.170487  0.297284                   228.000000            234.000000   \n",
       "127  3.467771 -0.010725                   212.333333            274.333333   \n",
       "\n",
       "     Pharmaceutical Manufacturing_sum  Data Management_y_sum  \\\n",
       "0                          327.333333             304.666667   \n",
       "1                          308.333333             327.666667   \n",
       "2                          277.333333             302.000000   \n",
       "3                          227.000000             232.666667   \n",
       "4                          232.666667             195.666667   \n",
       "..                                ...                    ...   \n",
       "123                        225.666667             215.000000   \n",
       "124                        243.666667             225.666667   \n",
       "125                        238.000000             216.000000   \n",
       "126                        232.333333             207.000000   \n",
       "127                        220.333333             208.333333   \n",
       "\n",
       "     Venture Capital_sum  Pharmaceuticals & Biotech_sum  Genetics_sum  \\\n",
       "0             179.000000                     340.666667    305.666667   \n",
       "1             155.333333                     297.000000    295.333333   \n",
       "2             135.000000                     278.333333    271.666667   \n",
       "3             105.333333                     221.333333    237.333333   \n",
       "4              86.666667                     206.333333    204.333333   \n",
       "..                   ...                            ...           ...   \n",
       "123            75.333333                     106.000000    147.333333   \n",
       "124            78.000000                     106.666667    155.000000   \n",
       "125            71.000000                     101.666667    148.666667   \n",
       "126            72.000000                     102.000000    137.000000   \n",
       "127            63.000000                     117.666667    124.666667   \n",
       "\n",
       "     Automotive Industry_sum  Nanobiotechnology_sum  Software Utilities_sum  \\\n",
       "0                 325.666667             336.000000              332.666667   \n",
       "1                 276.666667             272.000000              293.000000   \n",
       "2                 233.666667             221.666667              290.000000   \n",
       "3                 233.666667             168.333333              236.000000   \n",
       "4                 199.000000             139.000000              210.000000   \n",
       "..                       ...                    ...                     ...   \n",
       "123                98.333333             149.333333              200.000000   \n",
       "124               102.666667             152.000000              207.000000   \n",
       "125               110.000000             144.000000              199.333333   \n",
       "126               134.666667             140.333333              200.666667   \n",
       "127               108.000000             149.333333              204.333333   \n",
       "\n",
       "     Oil & Gas_sum  Renewable Energy_sum  \\\n",
       "0       337.000000            335.000000   \n",
       "1       309.666667            307.666667   \n",
       "2       308.666667            312.333333   \n",
       "3       272.666667            272.000000   \n",
       "4       226.333333            234.666667   \n",
       "..             ...                   ...   \n",
       "123     153.333333            153.666667   \n",
       "124     154.333333            154.000000   \n",
       "125     144.666667            144.666667   \n",
       "126     147.666667            147.000000   \n",
       "127     146.000000            146.000000   \n",
       "\n",
       "     Renewable Energy (Subcategory of Energy & Utilities)_sum  \\\n",
       "0                                           334.666667          \n",
       "1                                           307.333333          \n",
       "2                                           311.666667          \n",
       "3                                           274.666667          \n",
       "4                                           236.333333          \n",
       "..                                                 ...          \n",
       "123                                         153.333333          \n",
       "124                                         154.000000          \n",
       "125                                         145.000000          \n",
       "126                                         144.333333          \n",
       "127                                         147.333333          \n",
       "\n",
       "     Risk Management_sum  Environmental Science_sum  \\\n",
       "0             317.333333                 192.333333   \n",
       "1             271.333333                 176.333333   \n",
       "2             246.666667                 154.333333   \n",
       "3             180.333333                 120.000000   \n",
       "4             154.000000                 112.000000   \n",
       "..                   ...                        ...   \n",
       "123           126.666667                 157.333333   \n",
       "124           132.333333                 175.333333   \n",
       "125           129.000000                 172.000000   \n",
       "126           126.666667                 165.666667   \n",
       "127           116.333333                 195.000000   \n",
       "\n",
       "     Artificial Intelligence_sum  \n",
       "0                     314.333333  \n",
       "1                     245.666667  \n",
       "2                     196.333333  \n",
       "3                     135.666667  \n",
       "4                     112.666667  \n",
       "..                           ...  \n",
       "123                   168.666667  \n",
       "124                   203.666667  \n",
       "125                   205.333333  \n",
       "126                   193.666667  \n",
       "127                   177.333333  \n",
       "\n",
       "[128 rows x 18 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging google trends data with R&D expanditures \n",
    "google_trends_R_D = pd.merge(first_merged, merged_quartiles, on=['ISO', 'year'], how='inner')\n",
    "google_trends_R_D = google_trends_R_D.drop(axis =1 ,columns=[\"ISO\",\"year\",\"v-2\"])\n",
    "\n",
    "#Keep  a copy of this dataframe with quarterly basis data, this will be useful to evaluate our model on a quarterly basis\n",
    "quartiles_data_frame = google_trends_R_D.copy()\n",
    "\n",
    "# columns to keep that we will be using to train our model(only columns that represents sums of google trends data),\n",
    "# also v-1, and v which will be used to evaluate our models \n",
    "cols_to_keep = []\n",
    "for col in google_trends_R_D.columns :\n",
    "    if col ==\"v-1\" or col==\"v\" or col.split(\"_\")[-1]==\"sum\":\n",
    "        cols_to_keep.append(col)\n",
    "\n",
    "google_trends_R_D = google_trends_R_D.loc[:,cols_to_keep]\n",
    "google_trends_R_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78829714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarterly_based_dataframes(X_test, merged_quartiles):\n",
    "    \"\"\"\n",
    "    Extract quarterly-based DataFrames from a merged quartiles DataFrame.\n",
    "\n",
    "    This function takes the testing data X_test and extracts separate DataFrames for each quarter (1, 2, 3, 4) based on the\n",
    "    provided merged quartiles DataFrame. The DataFrames are filtered to include only columns corresponding to the respective\n",
    "    quarters.\n",
    "\n",
    "    Parameters:\n",
    "        X_test (pandas.DataFrame): The testing data for which quarterly-based DataFrames are extracted.\n",
    "        merged_quartiles (pandas.DataFrame): The merged quartiles DataFrame containing features for all quarters.\n",
    "\n",
    "    Returns:\n",
    "        tuple of DataFrames: A tuple containing the following DataFrames:\n",
    "            - X_test_quarter1: DataFrame containing data for the first quarter.\n",
    "            - X_test_quarter2: DataFrame containing data for the second quarter.\n",
    "            - X_test_quarter3: DataFrame containing data for the third quarter.\n",
    "            - X_test_quarter4: DataFrame containing data for the fourth quarter.\n",
    "    \"\"\"\n",
    "    # Extracting data for quarter 1\n",
    "    X_test_quarter1 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep1 = [col for col in X_test_quarter1.columns if col.split(\"_\")[-1] == \"1\"]\n",
    "    X_test_quarter1 = X_test_quarter1.loc[:, cols_to_keep1]\n",
    "\n",
    "    # Extracting data for quarter 2\n",
    "    X_test_quarter2 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep2 = [col for col in X_test_quarter2.columns if col.split(\"_\")[-1] == \"2\"]\n",
    "    X_test_quarter2 = X_test_quarter2.loc[:, cols_to_keep2]\n",
    "\n",
    "    # Extracting data for quarter 3\n",
    "    X_test_quarter3 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep3 = [col for col in X_test_quarter3.columns if col.split(\"_\")[-1] == \"3\"]\n",
    "    X_test_quarter3 = X_test_quarter3.loc[:, cols_to_keep3]\n",
    "\n",
    "    # Extracting data for quarter 4\n",
    "    X_test_quarter4 = merged_quartiles.loc[X_test.index.values]\n",
    "    cols_to_keep4 = [col for col in X_test_quarter4.columns if col.split(\"_\")[-1] == \"4\"]\n",
    "    X_test_quarter4 = X_test_quarter4.loc[:, cols_to_keep4]\n",
    "\n",
    "    return X_test_quarter1, X_test_quarter2, X_test_quarter3, X_test_quarter4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e823c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_quarterly_basis(df, n_folds, merged_quartiles):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model on a quarterly basis using cross-validation.\n",
    "\n",
    "    This function performs training and evaluation on a given DataFrame `df` with quarterly data using cross-validation.\n",
    "    It splits the data into `n_folds` folds and calculates the average percentage difference between true and predicted\n",
    "    R&D expenditure values for each fold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing R&D expenditure data with quarterly features.\n",
    "        n_folds (int): The number of folds for cross-validation.\n",
    "        merged_quartiles (pandas.DataFrame): The DataFrame containing merged quartile-based features.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fold = 0\n",
    "    avg_percentages_diffs = []\n",
    "\n",
    "    # Loop through each fold of cross-validation\n",
    "    for (train_index, test_index) in cross_validation_indices(df, n_folds):\n",
    "        \n",
    "        # Split the data into training and test sets for the current fold\n",
    "        train_df = df.iloc[train_index]\n",
    "        train_df = train_df[:]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # Prepare input data and target data\n",
    "        X_train = train_df.drop(['v', 'v-1'], axis=1)\n",
    "        y_train = train_df['v']\n",
    "        previous_R_D_values = test_df[\"v-1\"]\n",
    "        X_test = test_df.drop(['v', 'v-1'], axis=1)\n",
    "        y_test = test_df['v']\n",
    "        input_shape = X_train.shape[1]\n",
    "        \n",
    "        # Train an NLP model\n",
    "        model,_ = NN_optimized(X_train, y_train, input_shape)\n",
    "        \n",
    "        # Extract quarterly-based DataFrames for testing data\n",
    "        X_test_quarter1, X_test_quarter2, X_test_quarter3, X_test_quarter4 = extract_quarterly_based_dataframes(X_test, merged_quartiles)\n",
    "        \n",
    "        # Make predictions for each quarter\n",
    "        y_pred_quarter1 = model.predict(X_test_quarter1)\n",
    "        y_pred_quarter2 = model.predict(X_test_quarter2)\n",
    "        y_pred_quarter3 = model.predict(X_test_quarter3)\n",
    "        y_pred_quarter4 = model.predict(X_test_quarter4)\n",
    "        \n",
    "        # Calculate true and predicted R&D expenditure values for the entire year\n",
    "        R_D_true_values = previous_R_D_values + y_test\n",
    "        R_D_predicted_values = previous_R_D_values + y_pred_quarter1.flatten() + y_pred_quarter2.flatten() + y_pred_quarter3.flatten() + y_pred_quarter4.flatten()\n",
    "        \n",
    "        # Calculate the average percentage difference for the current fold\n",
    "        avg_percentage_diff = np.mean((np.abs(R_D_true_values - R_D_predicted_values) / R_D_true_values * 100))\n",
    "        print(f\"the MAPE for the {fold}th fold is : {avg_percentage_diff}%\")\n",
    "        \n",
    "        # Store the average percentage difference for this fold\n",
    "        avg_percentages_diffs.append(avg_percentage_diff)\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate the overall average percentage difference across all folds\n",
    "    avg_percentage_diff_folds = sum(avg_percentages_diffs) / n_folds \n",
    "    print(f\"the MAPE for this training is : {avg_percentage_diff_folds}%\")\n",
    "    return avg_percentage_diff_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e196838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 44ms/step - loss: 864.7054 - val_loss: 47.3431 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 155.5013 - val_loss: 102.7061 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 42.1786 - val_loss: 52.1107 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 14.2153 - val_loss: 12.4679 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 7.4291 - val_loss: 1.2390 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.7344 - val_loss: 0.7219 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4126 - val_loss: 0.3110 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.1062 - val_loss: 0.3985 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.2203 - val_loss: 0.2755 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.2748 - val_loss: 0.3017 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0823 - val_loss: 0.1542 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0415 - val_loss: 0.1472 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.1176 - val_loss: 0.3056 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.1690 - val_loss: 0.3884 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2538 - val_loss: 0.2440 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0734 - val_loss: 0.3241 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0522 - val_loss: 0.2992 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0379 - val_loss: 0.2419 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1584 - val_loss: 0.1592 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1151 - val_loss: 0.8184 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.1224 - val_loss: 0.4446 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0376 - val_loss: 0.1625 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0292 - val_loss: 0.1812 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0181 - val_loss: 0.2179 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0177 - val_loss: 0.0974 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0290 - val_loss: 0.0806 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0301 - val_loss: 0.1670 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0908 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0238 - val_loss: 0.2481 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0191 - val_loss: 0.0868 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0314 - val_loss: 0.2346 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0236 - val_loss: 0.1174 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0135 - val_loss: 0.1214 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0146 - val_loss: 0.0842 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0169 - val_loss: 0.1471 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0327 - val_loss: 0.2276 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0258 - val_loss: 0.1533 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0152 - val_loss: 0.1103 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0983 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0127 - val_loss: 0.0808 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0174 - val_loss: 0.0793 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0153 - val_loss: 0.1046 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0102 - val_loss: 0.1175 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0105 - val_loss: 0.0811 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.1068 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.1003 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0098 - val_loss: 0.0983 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0098 - val_loss: 0.1042 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0963 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.1121 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.1024 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.1017 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0098 - val_loss: 0.0934 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.1117 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0909 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0991 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0098 - val_loss: 0.0923 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0105 - val_loss: 0.0990 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0096 - val_loss: 0.0993 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0097 - val_loss: 0.1027 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0094 - val_loss: 0.0955 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0922 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0098 - val_loss: 0.1055 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0097 - val_loss: 0.0969 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0098 - val_loss: 0.0924 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.1018 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.1009 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.1024 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0995 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.1015 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0946 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0094 - val_loss: 0.1020 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0094 - val_loss: 0.1000 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0100 - val_loss: 0.0902 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0096 - val_loss: 0.0947 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0093 - val_loss: 0.0991 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0093 - val_loss: 0.0949 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0094 - val_loss: 0.0965 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0093 - val_loss: 0.0982 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0986 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "the MAPE for the 0th fold is : 4.180335887110452%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 37ms/step - loss: 861.9108 - val_loss: 57.3462 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 56.0710 - val_loss: 0.1476 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 10.5924 - val_loss: 1.7897 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 1.1434 - val_loss: 3.0134 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.0603 - val_loss: 0.3538 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.6693 - val_loss: 0.7665 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.8151 - val_loss: 2.6047 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 1.3002 - val_loss: 0.2356 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6970 - val_loss: 0.8380 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2622 - val_loss: 0.1955 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1811 - val_loss: 0.1253 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0685 - val_loss: 0.8511 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.4434 - val_loss: 0.1473 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0959 - val_loss: 0.2478 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2643 - val_loss: 6.9744 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 3.2358 - val_loss: 0.0438 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.7771 - val_loss: 5.2889 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.1790 - val_loss: 1.6015 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.8820 - val_loss: 10.4871 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 3.4378 - val_loss: 7.3297 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 2.7628 - val_loss: 0.5055 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.8201 - val_loss: 0.0821 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2018 - val_loss: 0.2183 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4748 - val_loss: 7.0351 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 3.3793 - val_loss: 8.8950 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 4.3766 - val_loss: 8.5371 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 2.4507 - val_loss: 1.4736 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.8052 - val_loss: 0.3248 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.6442 - val_loss: 0.2798 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3362 - val_loss: 0.9963 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2114 - val_loss: 0.0676 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0731 - val_loss: 0.2609 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0616 - val_loss: 0.2354 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0570 - val_loss: 0.0545 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0195 - val_loss: 0.1101 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0241 - val_loss: 0.1367 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0189 - val_loss: 0.1324 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0291 - val_loss: 0.1508 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0274 - val_loss: 0.1159 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0158 - val_loss: 0.0543 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0184 - val_loss: 0.0543 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0142 - val_loss: 0.0637 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0752 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0655 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0152 - val_loss: 0.0866 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.0128 - val_loss: 0.0749 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0124 - val_loss: 0.0831 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0128 - val_loss: 0.0473 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0149 - val_loss: 0.0702 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0127 - val_loss: 0.0755 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0609 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0115 - val_loss: 0.0741 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0735 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0123 - val_loss: 0.0650 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0119 - val_loss: 0.0613 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0690 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0648 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0126 - val_loss: 0.0598 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0124 - val_loss: 0.0686 - lr: 2.0242e-05\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0116 - val_loss: 0.0649 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0115 - val_loss: 0.0659 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0113 - val_loss: 0.0709 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0653 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0114 - val_loss: 0.0646 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0111 - val_loss: 0.0747 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0117 - val_loss: 0.0692 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0113 - val_loss: 0.0648 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0113 - val_loss: 0.0581 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0125 - val_loss: 0.0592 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0112 - val_loss: 0.0761 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0118 - val_loss: 0.0708 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0114 - val_loss: 0.0665 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0117 - val_loss: 0.0584 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0114 - val_loss: 0.0633 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0110 - val_loss: 0.0662 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0112 - val_loss: 0.0694 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 0.0683 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0111 - val_loss: 0.0660 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0112 - val_loss: 0.0637 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0652 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "the MAPE for the 1th fold is : 6.108182655819217%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 49ms/step - loss: 1280.5430 - val_loss: 22.3737 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 101.3585 - val_loss: 1.2324 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 10.3765 - val_loss: 0.6116 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 3.2547 - val_loss: 1.3788 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 3.7843 - val_loss: 8.6632 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 2.1745 - val_loss: 5.2081 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 1.2120 - val_loss: 2.6448 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 1.6570 - val_loss: 0.2213 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3225 - val_loss: 0.5594 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.5581 - val_loss: 0.2346 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.6874 - val_loss: 0.8847 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.6928 - val_loss: 0.6908 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5219 - val_loss: 0.0531 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0957 - val_loss: 0.1165 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1759 - val_loss: 0.2303 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2333 - val_loss: 0.9083 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3082 - val_loss: 0.0863 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1077 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1671 - val_loss: 0.3051 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0921 - val_loss: 0.1301 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2218 - val_loss: 0.7058 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.3516 - val_loss: 0.0418 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1007 - val_loss: 0.2579 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1156 - val_loss: 0.6262 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.5304 - val_loss: 0.4430 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3255 - val_loss: 0.1076 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3762 - val_loss: 0.1454 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1954 - val_loss: 0.0220 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1253 - val_loss: 0.0193 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0293 - val_loss: 0.0212 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0253 - val_loss: 0.0825 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0360 - val_loss: 0.0299 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0185 - val_loss: 0.0259 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0315 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0159 - val_loss: 0.0197 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0376 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0155 - val_loss: 0.0246 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0205 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0222 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0197 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0099 - val_loss: 0.0193 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0130 - val_loss: 0.0196 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0264 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0095 - val_loss: 0.0203 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0087 - val_loss: 0.0187 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0094 - val_loss: 0.0184 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0109 - val_loss: 0.0205 - lr: 6.7206e-05\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0153 - val_loss: 0.0225 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0094 - val_loss: 0.0202 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0082 - val_loss: 0.0185 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0190 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0092 - val_loss: 0.0217 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0079 - val_loss: 0.0189 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0085 - val_loss: 0.0182 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0202 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.0181 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0187 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0191 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 0.0179 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0184 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0183 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0183 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0190 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0185 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0198 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0086 - val_loss: 0.0177 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0192 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0195 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0183 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0183 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0187 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.0186 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0184 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0186 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0186 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0187 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0181 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0179 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0181 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0183 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "the MAPE for the 2th fold is : 4.368977668265533%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 1s 39ms/step - loss: 1255.1848 - val_loss: 25.7658 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 24.6131 - val_loss: 39.1963 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 16.6783 - val_loss: 18.5126 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 7.3516 - val_loss: 0.2495 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.6775 - val_loss: 4.8358 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.9196 - val_loss: 1.1188 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2704 - val_loss: 0.2118 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0619 - val_loss: 0.2674 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3784 - val_loss: 0.5017 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.0866 - val_loss: 3.6141 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.5521 - val_loss: 0.5009 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.1311 - val_loss: 0.8191 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6759 - val_loss: 0.2194 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2168 - val_loss: 0.0625 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0611 - val_loss: 0.0570 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0793 - val_loss: 0.3742 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0813 - val_loss: 0.3202 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0443 - val_loss: 0.0752 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0370 - val_loss: 0.0770 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0205 - val_loss: 0.0600 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0356 - val_loss: 0.0599 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0490 - val_loss: 0.1708 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0477 - val_loss: 0.0852 - lr: 7.4082e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0658 - val_loss: 0.0547 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.1059 - val_loss: 0.0870 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1015 - val_loss: 0.0762 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.0781 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0201 - val_loss: 0.1645 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0187 - val_loss: 0.1459 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0193 - val_loss: 0.0520 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0328 - val_loss: 0.0910 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0115 - val_loss: 0.0493 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0241 - val_loss: 0.0787 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.1711 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0209 - val_loss: 0.0654 - lr: 2.2313e-04\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.0625 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0117 - val_loss: 0.1117 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0193 - val_loss: 0.0549 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0723 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0585 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0944 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0785 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0786 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.1036 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0841 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0896 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0750 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0828 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0909 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0900 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0816 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0726 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0909 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0721 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0836 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0801 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0777 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0860 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0754 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0815 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0846 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0800 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0817 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0776 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0853 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0855 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0756 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0082 - val_loss: 0.0850 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0805 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0814 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0856 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0767 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0827 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0839 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0852 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0833 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0810 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0813 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0816 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0852 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the MAPE for the 3th fold is : 4.546132305399918%\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 2s 41ms/step - loss: 1221.3264 - val_loss: 93.0464 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 17.3760 - val_loss: 1.3114 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.3241 - val_loss: 2.3814 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.5223 - val_loss: 1.2790 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.7660 - val_loss: 9.2893 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 9.0325 - val_loss: 3.6509 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 3.0751 - val_loss: 7.0742 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 7.4978 - val_loss: 0.9198 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 5.8005 - val_loss: 3.2033 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 3.2600 - val_loss: 18.1406 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 15.3723 - val_loss: 0.0903 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 4.0869 - val_loss: 0.0934 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.5364 - val_loss: 0.1000 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2418 - val_loss: 0.0611 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1552 - val_loss: 0.2079 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2679 - val_loss: 0.0954 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.1979 - val_loss: 0.3529 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2504 - val_loss: 1.2862 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3710 - val_loss: 0.5313 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1403 - val_loss: 0.0659 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0313 - val_loss: 0.0457 - lr: 9.0484e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0202 - val_loss: 0.0693 - lr: 8.1873e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0231 - val_loss: 0.0264 - lr: 7.4082e-04\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0299 - val_loss: 0.0202 - lr: 6.7032e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0180 - val_loss: 0.0297 - lr: 6.0653e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0216 - val_loss: 0.0249 - lr: 5.4881e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0239 - lr: 4.9659e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0157 - val_loss: 0.0227 - lr: 4.4933e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.0222 - lr: 4.0657e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0186 - val_loss: 0.0300 - lr: 3.6788e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0201 - lr: 3.3287e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0114 - val_loss: 0.0197 - lr: 3.0119e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0192 - val_loss: 0.0265 - lr: 2.7253e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0147 - val_loss: 0.0215 - lr: 2.4660e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0112 - val_loss: 0.0212 - lr: 2.2313e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0199 - lr: 2.0190e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0208 - lr: 1.8268e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0276 - lr: 1.6530e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0264 - lr: 1.4957e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 0.0223 - lr: 1.3534e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0279 - lr: 1.2246e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0110 - val_loss: 0.0221 - lr: 1.1080e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 0.0241 - lr: 1.0026e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0250 - lr: 9.0718e-05\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0195 - lr: 8.2085e-05\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0226 - lr: 7.4274e-05\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0202 - lr: 6.7206e-05\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0221 - lr: 6.0810e-05\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0203 - lr: 5.5023e-05\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0203 - lr: 4.9787e-05\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0094 - val_loss: 0.0202 - lr: 4.5049e-05\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0215 - lr: 4.0762e-05\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0204 - lr: 3.6883e-05\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0197 - lr: 3.3373e-05\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0206 - lr: 3.0197e-05\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0097 - val_loss: 0.0202 - lr: 2.7324e-05\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0215 - lr: 2.4724e-05\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0202 - lr: 2.2371e-05\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0215 - lr: 2.0242e-05\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0091 - val_loss: 0.0201 - lr: 1.8316e-05\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0090 - val_loss: 0.0213 - lr: 1.6573e-05\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0204 - lr: 1.4996e-05\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0090 - val_loss: 0.0208 - lr: 1.3569e-05\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0206 - lr: 1.2277e-05\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0094 - val_loss: 0.0200 - lr: 1.1109e-05\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0093 - val_loss: 0.0212 - lr: 1.0052e-05\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0200 - lr: 9.0953e-06\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0202 - lr: 8.2298e-06\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0207 - lr: 7.4466e-06\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0212 - lr: 6.7379e-06\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0202 - lr: 6.0967e-06\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0203 - lr: 5.5166e-06\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0205 - lr: 4.9916e-06\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0203 - lr: 4.5166e-06\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0208 - lr: 4.0868e-06\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0203 - lr: 3.6979e-06\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0199 - lr: 3.3460e-06\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0203 - lr: 3.0276e-06\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0202 - lr: 2.7394e-06\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0205 - lr: 2.4788e-06\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the MAPE for the 4th fold is : 3.825812992984323%\n",
      "the MAPE for this training is : 4.605888301915888%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.605888301915888"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_quarterly_basis(google_trends_R_D,5,merged_quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eac89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1260ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c939ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06290ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
